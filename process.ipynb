{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://mirrors.bfsu.edu.cn/pypi/web/simple\n",
      "Requirement already satisfied: scikit-learn in /home/wode/公共/wode/.venv/lib/python3.11/site-packages (1.6.0)\n",
      "Requirement already satisfied: pyaml in /home/wode/公共/wode/.venv/lib/python3.11/site-packages (24.9.0)\n",
      "Requirement already satisfied: tensorboardX in /home/wode/公共/wode/.venv/lib/python3.11/site-packages (2.6.2.2)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /home/wode/公共/wode/.venv/lib/python3.11/site-packages (from scikit-learn) (2.2.0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /home/wode/公共/wode/.venv/lib/python3.11/site-packages (from scikit-learn) (1.14.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/wode/公共/wode/.venv/lib/python3.11/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/wode/公共/wode/.venv/lib/python3.11/site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: PyYAML in /home/wode/公共/wode/.venv/lib/python3.11/site-packages (from pyaml) (6.0.2)\n",
      "Requirement already satisfied: packaging in /home/wode/公共/wode/.venv/lib/python3.11/site-packages (from tensorboardX) (24.2)\n",
      "Requirement already satisfied: protobuf>=3.20 in /home/wode/公共/wode/.venv/lib/python3.11/site-packages (from tensorboardX) (5.29.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn pyaml tensorboardX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "split data to train/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 读取数据\n",
    "with open('data/data.pkl', 'rb') as file:\n",
    "    data = pickle.load(file)\n",
    "\n",
    "# 训练集，测试集索引\n",
    "train_idx, test_idx = train_test_split(range(len(data[0])), test_size=0.2, random_state=42)\n",
    "\n",
    "train = [[] for _ in data]\n",
    "test = [[] for _ in data]\n",
    "\n",
    "for i,snr in enumerate(data):\n",
    "    for j in range(len(snr)):\n",
    "        if j in train_idx:\n",
    "            train[i].append(snr[j])\n",
    "        elif j in test_idx:\n",
    "            test[i].append(snr[j])\n",
    "\n",
    "with open('data/train.pkl', 'wb') as f:\n",
    "    pickle.dump(train, f)\n",
    "with open('data/test.pkl', 'wb') as f:\n",
    "    pickle.dump(test, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_snr(模态判断)\n",
    "\n",
    "`BEST ACC@1：99.65`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters:\n",
      "{'work_dir': './work_dir/snr', 'config': 'config/train_snr.yaml', 'phase': 'train', 'save_score': False, 'seed': 1, 'feeder': 'feeder.Feeder_snr', 'num_worker': 8, 'train_feeder_args': {'data_path': './data/train.pkl'}, 'test_feeder_args': {'data_path': './data/test.pkl'}, 'model': 'net.CNN', 'model_args': {'channels': 13, 'num_classes': 3}, 'weights': None, 'ignore_weights': [], 'base_lr': 0.001, 'step': [10, 50], 'device': 0, 'optimizer': 'Adam', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 80, 'weight_decay': 1e-05}\n",
      "\n",
      "Epoch:[1/80]\n",
      "Train Acc@1: 87.50607006854992 Mean loss: 0.325864827183224 LR: [0.00095]\n",
      "Eval Acc@1: 92.43433219522977\n",
      "Eval Best Acc@1: 92.43433219522977\n",
      "Epoch:[2/80]\n",
      "Train Acc@1: 93.99005665571266 Mean loss: 0.16738173133313392 LR: [0.0009025]\n",
      "Eval Acc@1: 94.65408805031447\n",
      "Eval Best Acc@1: 94.65408805031447\n",
      "Epoch:[3/80]\n",
      "Train Acc@1: 95.386749915049 Mean loss: 0.1295156116327326 LR: [0.000857375]\n",
      "Eval Acc@1: 95.56973732889382\n",
      "Eval Best Acc@1: 95.56973732889382\n",
      "Epoch:[4/80]\n",
      "Train Acc@1: 96.12440745388652 Mean loss: 0.10997911921796008 LR: [0.0008145062499999999]\n",
      "Eval Acc@1: 97.57676655567887\n",
      "Eval Best Acc@1: 97.57676655567887\n",
      "Epoch:[5/80]\n",
      "Train Acc@1: 96.7718811502676 Mean loss: 0.09489183195800514 LR: [0.0007737809374999998]\n",
      "Eval Acc@1: 96.45763964552461\n",
      "Eval Best Acc@1: 97.57676655567887\n",
      "Epoch:[6/80]\n",
      "Train Acc@1: 97.09561799845815 Mean loss: 0.08608267114004506 LR: [0.0007350918906249997]\n",
      "Eval Acc@1: 97.41028484043879\n",
      "Eval Best Acc@1: 97.57676655567887\n",
      "Epoch:[7/80]\n",
      "Train Acc@1: 97.46791537387728 Mean loss: 0.07733133856411031 LR: [0.0006983372960937497]\n",
      "Eval Acc@1: 97.54901957961748\n",
      "Eval Best Acc@1: 97.57676655567887\n",
      "Epoch:[8/80]\n",
      "Train Acc@1: 97.7731529683071 Mean loss: 0.06801962940306155 LR: [0.0006634204312890621]\n",
      "Eval Acc@1: 97.68775431879617\n",
      "Eval Best Acc@1: 97.68775431879617\n",
      "Epoch:[9/80]\n",
      "Train Acc@1: 97.98358192580575 Mean loss: 0.06301505352403505 LR: [0.000630249409724609]\n",
      "Eval Acc@1: 97.9929707449893\n",
      "Eval Best Acc@1: 97.9929707449893\n",
      "Epoch:[10/80]\n",
      "Train Acc@1: 98.08070297320602 Mean loss: 0.0593391442740303 LR: [0.0005987369392383785]\n",
      "Eval Acc@1: 98.20569737328894\n",
      "Eval Best Acc@1: 98.20569737328894\n",
      "Epoch:[11/80]\n",
      "Train Acc@1: 98.06682853685498 Mean loss: 0.05867914288489357 LR: [0.0005688000922764595]\n",
      "Eval Acc@1: 98.2981871711824\n",
      "Eval Best Acc@1: 98.2981871711824\n",
      "Epoch:[12/80]\n",
      "Train Acc@1: 98.29806914976228 Mean loss: 0.05360983597829706 LR: [0.0005403600876626365]\n",
      "Eval Acc@1: 98.64039952782318\n",
      "Eval Best Acc@1: 98.64039952782318\n",
      "Epoch:[13/80]\n",
      "Train Acc@1: 98.34200485781695 Mean loss: 0.05077919067185339 LR: [0.0005133420832795047]\n",
      "Eval Acc@1: 98.04846464066077\n",
      "Eval Best Acc@1: 98.64039952782318\n",
      "Epoch:[14/80]\n",
      "Train Acc@1: 98.45068794962353 Mean loss: 0.04881327101456542 LR: [0.00048767497911552944]\n",
      "Eval Acc@1: 98.52941173648023\n",
      "Eval Best Acc@1: 98.64039952782318\n",
      "Epoch:[15/80]\n",
      "Train Acc@1: 98.61255637283669 Mean loss: 0.04401166508915922 LR: [0.00046329123015975297]\n",
      "Eval Acc@1: 97.62301146873844\n",
      "Eval Best Acc@1: 98.64039952782318\n",
      "Epoch:[16/80]\n",
      "Train Acc@1: 98.60099434254417 Mean loss: 0.04482011403750694 LR: [0.0004401266686517653]\n",
      "Eval Acc@1: 99.07510171058307\n",
      "Eval Best Acc@1: 99.07510171058307\n",
      "Epoch:[17/80]\n",
      "Train Acc@1: 98.66111689389048 Mean loss: 0.042222796620376764 LR: [0.00041812033521917703]\n",
      "Eval Acc@1: 98.52941173648023\n",
      "Eval Best Acc@1: 99.07510171058307\n",
      "Epoch:[18/80]\n",
      "Train Acc@1: 98.64493005765574 Mean loss: 0.041714940898288484 LR: [0.00039721431845821814]\n",
      "Eval Acc@1: 98.84387714528526\n",
      "Eval Best Acc@1: 99.07510171058307\n",
      "Epoch:[19/80]\n",
      "Train Acc@1: 98.75823795540455 Mean loss: 0.039387042040057677 LR: [0.0003773536025353072]\n",
      "Eval Acc@1: 99.0196078149116\n",
      "Eval Best Acc@1: 99.07510171058307\n",
      "Epoch:[20/80]\n",
      "Train Acc@1: 98.88310788168164 Mean loss: 0.03638063989732602 LR: [0.0003584859224085418]\n",
      "Eval Acc@1: 99.10284865841881\n",
      "Eval Best Acc@1: 99.10284865841881\n",
      "Epoch:[21/80]\n",
      "Train Acc@1: 98.80217366963402 Mean loss: 0.03672044244322777 LR: [0.0003405616262881147]\n",
      "Eval Acc@1: 98.26119126896042\n",
      "Eval Best Acc@1: 99.10284865841881\n",
      "Epoch:[22/80]\n",
      "Train Acc@1: 98.90391953709029 Mean loss: 0.03514756190679422 LR: [0.00032353354497370894]\n",
      "Eval Acc@1: 98.45541987558492\n",
      "Eval Best Acc@1: 99.10284865841881\n",
      "Epoch:[23/80]\n",
      "Train Acc@1: 98.95710487643588 Mean loss: 0.03314985953648189 LR: [0.00030735686772502346]\n",
      "Eval Acc@1: 98.75138731916613\n",
      "Eval Best Acc@1: 99.10284865841881\n",
      "Epoch:[24/80]\n",
      "Train Acc@1: 98.92704359679323 Mean loss: 0.03350019551222571 LR: [0.00029198902433877225]\n",
      "Eval Acc@1: 99.08435069319499\n",
      "Eval Best Acc@1: 99.10284865841881\n",
      "Epoch:[25/80]\n",
      "Train Acc@1: 99.07734999059598 Mean loss: 0.03141295124525921 LR: [0.00027738957312183364]\n",
      "Eval Acc@1: 98.99186086707586\n",
      "Eval Best Acc@1: 99.10284865841881\n",
      "Epoch:[26/80]\n",
      "Train Acc@1: 99.01491502701637 Mean loss: 0.031296753940398436 LR: [0.0002635200944657419]\n",
      "Eval Acc@1: 99.05660377358491\n",
      "Eval Best Acc@1: 99.10284865841881\n",
      "Epoch:[27/80]\n",
      "Train Acc@1: 99.10509886329801 Mean loss: 0.02899452245106422 LR: [0.0002503440897424548]\n",
      "Eval Acc@1: 99.12134662364264\n",
      "Eval Best Acc@1: 99.12134662364264\n",
      "Epoch:[28/80]\n",
      "Train Acc@1: 99.08197480271298 Mean loss: 0.029364128083200058 LR: [0.00023782688525533205]\n",
      "Eval Acc@1: 98.79763226045135\n",
      "Eval Best Acc@1: 99.12134662364264\n",
      "Epoch:[29/80]\n",
      "Train Acc@1: 99.16290901476061 Mean loss: 0.02769743419888143 LR: [0.00022593554099256544]\n",
      "Eval Acc@1: 99.26933034543325\n",
      "Eval Best Acc@1: 99.26933034543325\n",
      "Epoch:[30/80]\n",
      "Train Acc@1: 99.19759510563817 Mean loss: 0.026696398036076395 LR: [0.00021463876394293716]\n",
      "Eval Acc@1: 99.09359970403256\n",
      "Eval Best Acc@1: 99.26933034543325\n",
      "Epoch:[31/80]\n",
      "Train Acc@1: 99.19990751169668 Mean loss: 0.026244558622652785 LR: [0.0002039068257457903]\n",
      "Eval Acc@1: 98.93636697140438\n",
      "Eval Best Acc@1: 99.26933034543325\n",
      "Epoch:[32/80]\n",
      "Train Acc@1: 99.1513469853502 Mean loss: 0.026650284017097292 LR: [0.00019371148445850077]\n",
      "Eval Acc@1: 98.91786900618057\n",
      "Eval Best Acc@1: 99.26933034543325\n",
      "Epoch:[33/80]\n",
      "Train Acc@1: 99.20221991775519 Mean loss: 0.025721863549534707 LR: [0.00018402591023557573]\n",
      "Eval Acc@1: 99.3155752584928\n",
      "Eval Best Acc@1: 99.3155752584928\n",
      "Epoch:[34/80]\n",
      "Train Acc@1: 99.26234247527628 Mean loss: 0.024824552666967648 LR: [0.00017482461472379692]\n",
      "Eval Acc@1: 99.1583425540903\n",
      "Eval Best Acc@1: 99.3155752584928\n",
      "Epoch:[35/80]\n",
      "Train Acc@1: 99.29471616009533 Mean loss: 0.02387946793255355 LR: [0.00016608338398760707]\n",
      "Eval Acc@1: 98.97336290185204\n",
      "Eval Best Acc@1: 99.3155752584928\n",
      "Epoch:[36/80]\n",
      "Train Acc@1: 99.27852931768581 Mean loss: 0.024236811090056844 LR: [0.0001577792147882267]\n",
      "Eval Acc@1: 99.17684051931411\n",
      "Eval Best Acc@1: 99.3155752584928\n",
      "Epoch:[37/80]\n",
      "Train Acc@1: 99.30396578432935 Mean loss: 0.023628759600780768 LR: [0.00014989025404881537]\n",
      "Eval Acc@1: 99.32482424110472\n",
      "Eval Best Acc@1: 99.32482424110472\n",
      "Epoch:[38/80]\n",
      "Train Acc@1: 99.32246503279738 Mean loss: 0.022827486596692776 LR: [0.00014239574134637458]\n",
      "Eval Acc@1: 99.26933034543325\n",
      "Eval Best Acc@1: 99.32482424110472\n",
      "Epoch:[39/80]\n",
      "Train Acc@1: 99.35252631155794 Mean loss: 0.02190145512801022 LR: [0.00013527595427905584]\n",
      "Eval Acc@1: 99.06585272797116\n",
      "Eval Best Acc@1: 99.32482424110472\n",
      "Epoch:[40/80]\n",
      "Train Acc@1: 99.36871315396746 Mean loss: 0.021306204407740406 LR: [0.00012851215656510304]\n",
      "Eval Acc@1: 99.1675915367022\n",
      "Eval Best Acc@1: 99.32482424110472\n",
      "Epoch:[41/80]\n",
      "Train Acc@1: 99.3918372145525 Mean loss: 0.020558504380245098 LR: [0.00012208654873684788]\n",
      "Eval Acc@1: 99.13059560625456\n",
      "Eval Best Acc@1: 99.32482424110472\n",
      "Epoch:[42/80]\n",
      "Train Acc@1: 99.40108683878651 Mean loss: 0.020985756897847666 LR: [0.00011598222130000548]\n",
      "Eval Acc@1: 99.3155752584928\n",
      "Eval Best Acc@1: 99.32482424110472\n",
      "Epoch:[43/80]\n",
      "Train Acc@1: 99.40339924484502 Mean loss: 0.020001001694544836 LR: [0.00011018311023500519]\n",
      "Eval Acc@1: 99.12134662364264\n",
      "Eval Best Acc@1: 99.32482424110472\n",
      "Epoch:[44/80]\n",
      "Train Acc@1: 99.44502255389808 Mean loss: 0.020011383408443596 LR: [0.00010467395472325493]\n",
      "Eval Acc@1: 99.30632627588089\n",
      "Eval Best Acc@1: 99.32482424110472\n",
      "Epoch:[45/80]\n",
      "Train Acc@1: 99.40802405696202 Mean loss: 0.019381093814057716 LR: [9.944025698709218e-05]\n",
      "Eval Acc@1: 99.0935996758069\n",
      "Eval Best Acc@1: 99.32482424110472\n",
      "Epoch:[46/80]\n",
      "Train Acc@1: 99.45658458419061 Mean loss: 0.019137633139265496 LR: [9.446824413773756e-05]\n",
      "Eval Acc@1: 99.33407322371663\n",
      "Eval Best Acc@1: 99.33407322371663\n",
      "Epoch:[47/80]\n",
      "Train Acc@1: 99.44271014783958 Mean loss: 0.01915882816214456 LR: [8.974483193085068e-05]\n",
      "Eval Acc@1: 99.22308543237368\n",
      "Eval Best Acc@1: 99.33407322371663\n",
      "Epoch:[48/80]\n",
      "Train Acc@1: 99.47739623871713 Mean loss: 0.018906397872213335 LR: [8.525759033430814e-05]\n",
      "Eval Acc@1: 99.34332220632854\n",
      "Eval Best Acc@1: 99.34332220632854\n",
      "Epoch:[49/80]\n",
      "Train Acc@1: 99.5120823295947 Mean loss: 0.017777513313371022 LR: [8.099471081759274e-05]\n",
      "Eval Acc@1: 99.26008136282132\n",
      "Eval Best Acc@1: 99.34332220632854\n",
      "Epoch:[50/80]\n",
      "Train Acc@1: 99.53983120317886 Mean loss: 0.01770958038552915 LR: [7.69449752767131e-05]\n",
      "Eval Acc@1: 99.27857932804515\n",
      "Eval Best Acc@1: 99.34332220632854\n",
      "Epoch:[51/80]\n",
      "Train Acc@1: 99.5167071417117 Mean loss: 0.017646452765560504 LR: [7.309772651287744e-05]\n",
      "Eval Acc@1: 99.23233441498559\n",
      "Eval Best Acc@1: 99.34332220632854\n",
      "Epoch:[52/80]\n",
      "Train Acc@1: 99.50745751747769 Mean loss: 0.01774468571479782 LR: [6.944284018723356e-05]\n",
      "Eval Acc@1: 99.26933034543325\n",
      "Eval Best Acc@1: 99.34332220632854\n",
      "Epoch:[53/80]\n",
      "Train Acc@1: 99.47970864477564 Mean loss: 0.017621501771219628 LR: [6.597069817787189e-05]\n",
      "Eval Acc@1: 99.22308546059934\n",
      "Eval Best Acc@1: 99.34332220632854\n",
      "Epoch:[54/80]\n",
      "Train Acc@1: 99.53520639017974 Mean loss: 0.017156182790034554 LR: [6.267216326897829e-05]\n",
      "Eval Acc@1: 99.25083238020942\n",
      "Eval Best Acc@1: 99.34332220632854\n",
      "Epoch:[55/80]\n",
      "Train Acc@1: 99.54445601441375 Mean loss: 0.016818923962785733 LR: [5.953855510552937e-05]\n",
      "Eval Acc@1: 99.30632627588089\n",
      "Eval Best Acc@1: 99.34332220632854\n",
      "Epoch:[56/80]\n",
      "Train Acc@1: 99.53983120317886 Mean loss: 0.01651055100404922 LR: [5.65616273502529e-05]\n",
      "Eval Acc@1: 99.35257118894046\n",
      "Eval Best Acc@1: 99.35257118894046\n",
      "Epoch:[57/80]\n",
      "Train Acc@1: 99.55601804470628 Mean loss: 0.016544288042216346 LR: [5.373354598274025e-05]\n",
      "Eval Acc@1: 99.26008139104698\n",
      "Eval Best Acc@1: 99.35257118894046\n",
      "Epoch:[58/80]\n",
      "Train Acc@1: 99.58607932346682 Mean loss: 0.01600121824465521 LR: [5.104686868360323e-05]\n",
      "Eval Acc@1: 99.29707729326898\n",
      "Eval Best Acc@1: 99.35257118894046\n",
      "Epoch:[59/80]\n",
      "Train Acc@1: 99.5698924810573 Mean loss: 0.016066098339547755 LR: [4.849452524942307e-05]\n",
      "Eval Acc@1: 99.27857932804515\n",
      "Eval Best Acc@1: 99.35257118894046\n",
      "Epoch:[60/80]\n",
      "Train Acc@1: 99.54676842047226 Mean loss: 0.016067998038867305 LR: [4.606979898695191e-05]\n",
      "Eval Acc@1: 99.3895671193881\n",
      "Eval Best Acc@1: 99.3895671193881\n",
      "Epoch:[61/80]\n",
      "Train Acc@1: 99.57914210529131 Mean loss: 0.01587759923166113 LR: [4.376630903760431e-05]\n",
      "Eval Acc@1: 99.29707729326898\n",
      "Eval Best Acc@1: 99.3895671193881\n",
      "Epoch:[62/80]\n",
      "Train Acc@1: 99.57451729317431 Mean loss: 0.015794165154029382 LR: [4.157799358572409e-05]\n",
      "Eval Acc@1: 99.25083238020942\n",
      "Eval Best Acc@1: 99.3895671193881\n",
      "Epoch:[63/80]\n",
      "Train Acc@1: 99.58839172952533 Mean loss: 0.01545401399400803 LR: [3.9499093906437885e-05]\n",
      "Eval Acc@1: 99.34332220632854\n",
      "Eval Best Acc@1: 99.3895671193881\n",
      "Epoch:[64/80]\n",
      "Train Acc@1: 99.58376691740833 Mean loss: 0.01542536442250891 LR: [3.752413921111599e-05]\n",
      "Eval Acc@1: 99.26933034543325\n",
      "Eval Best Acc@1: 99.3895671193881\n",
      "Epoch:[65/80]\n",
      "Train Acc@1: 99.58145451134982 Mean loss: 0.015555218416006104 LR: [3.564793225056019e-05]\n",
      "Eval Acc@1: 99.33407322371663\n",
      "Eval Best Acc@1: 99.3895671193881\n",
      "Epoch:[66/80]\n",
      "Train Acc@1: 99.61151579011036 Mean loss: 0.015148581509180808 LR: [3.3865535638032174e-05]\n",
      "Eval Acc@1: 99.30632627588089\n",
      "Eval Best Acc@1: 99.3895671193881\n",
      "Epoch:[67/80]\n",
      "Train Acc@1: 99.61382819705098 Mean loss: 0.015185757791638973 LR: [3.2172258856130564e-05]\n",
      "Eval Acc@1: 99.3155752584928\n",
      "Eval Best Acc@1: 99.3895671193881\n",
      "Epoch:[68/80]\n",
      "Train Acc@1: 99.60689097799336 Mean loss: 0.015014084736214187 LR: [3.056364591332403e-05]\n",
      "Eval Acc@1: 99.29707729326898\n",
      "Eval Best Acc@1: 99.3895671193881\n",
      "Epoch:[69/80]\n",
      "Train Acc@1: 99.61382819616887 Mean loss: 0.014791011820506296 LR: [2.903546361765783e-05]\n",
      "Eval Acc@1: 99.35257118894046\n",
      "Eval Best Acc@1: 99.3895671193881\n",
      "Epoch:[70/80]\n",
      "Train Acc@1: 99.6277026325199 Mean loss: 0.014747542393927327 LR: [2.758369043677494e-05]\n",
      "Eval Acc@1: 99.29707729326898\n",
      "Eval Best Acc@1: 99.3895671193881\n",
      "Epoch:[71/80]\n",
      "Train Acc@1: 99.61151579011036 Mean loss: 0.014692556922078255 LR: [2.620450591493619e-05]\n",
      "Eval Acc@1: 99.33407322371663\n",
      "Eval Best Acc@1: 99.3895671193881\n",
      "Epoch:[72/80]\n",
      "Train Acc@1: 99.6277026263451 Mean loss: 0.014648486379151351 LR: [2.489428061918938e-05]\n",
      "Eval Acc@1: 99.30632627588089\n",
      "Eval Best Acc@1: 99.3895671193881\n",
      "Epoch:[73/80]\n",
      "Train Acc@1: 99.64620188098792 Mean loss: 0.01457612830141529 LR: [2.364956658822991e-05]\n",
      "Eval Acc@1: 99.32482424110472\n",
      "Eval Best Acc@1: 99.3895671193881\n",
      "Epoch:[74/80]\n",
      "Train Acc@1: 99.6300150394605 Mean loss: 0.014557391682797464 LR: [2.2467088258818413e-05]\n",
      "Eval Acc@1: 99.32482424110472\n",
      "Eval Best Acc@1: 99.3895671193881\n",
      "Epoch:[75/80]\n",
      "Train Acc@1: 99.65313909916344 Mean loss: 0.014364610688299176 LR: [2.134373384587749e-05]\n",
      "Eval Acc@1: 99.34332220632854\n",
      "Eval Best Acc@1: 99.3895671193881\n",
      "Epoch:[76/80]\n",
      "Train Acc@1: 99.65082669398704 Mean loss: 0.014449276391493595 LR: [2.0276547153583614e-05]\n",
      "Eval Acc@1: 99.33407322371663\n",
      "Eval Best Acc@1: 99.3895671193881\n",
      "Epoch:[77/80]\n",
      "Train Acc@1: 99.65313909916344 Mean loss: 0.014303314040568947 LR: [1.9262719795904432e-05]\n",
      "Eval Acc@1: 99.34332220632854\n",
      "Eval Best Acc@1: 99.3895671193881\n",
      "Epoch:[78/80]\n",
      "Train Acc@1: 99.65545150522193 Mean loss: 0.01412995395427308 LR: [1.829958380610921e-05]\n",
      "Eval Acc@1: 99.33407322371663\n",
      "Eval Best Acc@1: 99.3895671193881\n",
      "Epoch:[79/80]\n",
      "Train Acc@1: 99.63695225675391 Mean loss: 0.014210609624871142 LR: [1.738460461580375e-05]\n",
      "Eval Acc@1: 99.33407322371663\n",
      "Eval Best Acc@1: 99.3895671193881\n",
      "Epoch:[80/80]\n",
      "Train Acc@1: 99.64851428704642 Mean loss: 0.014181032623693047 LR: [1.6515374385013564e-05]\n",
      "Eval Acc@1: 99.34332220632854\n",
      "Eval Best Acc@1: 99.3895671193881\n",
      "Best Train Acc@1: 99.65545150522193\n"
     ]
    }
   ],
   "source": [
    "!python main.py --config config/train_snr.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_device(设备判断)\n",
    "\n",
    "`BEST ACC@1：88.67`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters:\n",
      "{'work_dir': './work_dir/device', 'config': 'config/train_device.yaml', 'phase': 'train', 'save_score': False, 'seed': 1, 'feeder': 'feeder.Feeder_device', 'num_worker': 8, 'train_feeder_args': {'data_path': './data/train.pkl', 'snr': 0}, 'test_feeder_args': {'data_path': './data/test.pkl', 'snr': 0}, 'model': 'net.CNN', 'model_args': {'channels': 13, 'num_classes': 4}, 'weights': None, 'ignore_weights': [], 'base_lr': 0.001, 'step': [10, 50], 'device': 0, 'optimizer': 'Adam', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 80, 'weight_decay': 1e-05}\n",
      "\n",
      "Epoch:[1/80]\n",
      "Train Acc@1: 81.24869926894576 Mean loss: 0.49249914961051094 LR: [0.00095]\n",
      "Eval Acc@1: 81.2708102108768\n",
      "Eval Best Acc@1: 81.2708102108768\n",
      "Epoch:[2/80]\n",
      "Train Acc@1: 81.79673950481117 Mean loss: 0.4623432752832902 LR: [0.0009025]\n",
      "Eval Acc@1: 81.24306326304107\n",
      "Eval Best Acc@1: 81.2708102108768\n",
      "Epoch:[3/80]\n",
      "Train Acc@1: 82.1990981563445 Mean loss: 0.450233753803557 LR: [0.000857375]\n",
      "Eval Acc@1: 81.88124306326304\n",
      "Eval Best Acc@1: 81.88124306326304\n",
      "Epoch:[4/80]\n",
      "Train Acc@1: 83.27436697354881 Mean loss: 0.4380154895835218 LR: [0.0008145062499999999]\n",
      "Eval Acc@1: 83.3795782463929\n",
      "Eval Best Acc@1: 83.3795782463929\n",
      "Epoch:[5/80]\n",
      "Train Acc@1: 84.07214706373264 Mean loss: 0.4192144897131793 LR: [0.0007737809374999998]\n",
      "Eval Acc@1: 84.37846836847947\n",
      "Eval Best Acc@1: 84.37846836847947\n",
      "Epoch:[6/80]\n",
      "Train Acc@1: 84.75893166575463 Mean loss: 0.4070517110217989 LR: [0.0007350918906249997]\n",
      "Eval Acc@1: 84.71143174250832\n",
      "Eval Best Acc@1: 84.71143174250832\n",
      "Epoch:[7/80]\n",
      "Train Acc@1: 85.16822754075616 Mean loss: 0.40029577007599637 LR: [0.0006983372960937497]\n",
      "Eval Acc@1: 84.79467258601554\n",
      "Eval Best Acc@1: 84.79467258601554\n",
      "Epoch:[8/80]\n",
      "Train Acc@1: 85.48040235600784 Mean loss: 0.3939259645026342 LR: [0.0006634204312890621]\n",
      "Eval Acc@1: 84.62819089900111\n",
      "Eval Best Acc@1: 84.79467258601554\n",
      "Epoch:[9/80]\n",
      "Train Acc@1: 85.55671175329213 Mean loss: 0.389473271778727 LR: [0.000630249409724609]\n",
      "Eval Acc@1: 85.29411764705883\n",
      "Eval Best Acc@1: 85.29411764705883\n",
      "Epoch:[10/80]\n",
      "Train Acc@1: 86.07700311910185 Mean loss: 0.3789747799787901 LR: [0.0005987369392383785]\n",
      "Eval Acc@1: 85.65482796892341\n",
      "Eval Best Acc@1: 85.65482796892341\n",
      "Epoch:[11/80]\n",
      "Train Acc@1: 86.20881026179022 Mean loss: 0.37373644364091146 LR: [0.0005688000922764595]\n",
      "Eval Acc@1: 85.76581576026638\n",
      "Eval Best Acc@1: 85.76581576026638\n",
      "Epoch:[12/80]\n",
      "Train Acc@1: 86.47936177328151 Mean loss: 0.37088162550884013 LR: [0.0005403600876626365]\n",
      "Eval Acc@1: 83.65704772475027\n",
      "Eval Best Acc@1: 85.76581576026638\n",
      "Epoch:[13/80]\n",
      "Train Acc@1: 86.37530350064884 Mean loss: 0.3689296378762321 LR: [0.0005133420832795047]\n",
      "Eval Acc@1: 86.04328523862375\n",
      "Eval Best Acc@1: 86.04328523862375\n",
      "Epoch:[14/80]\n",
      "Train Acc@1: 86.75685050294832 Mean loss: 0.36207091102821637 LR: [0.00048767497911552944]\n",
      "Eval Acc@1: 86.18201997780244\n",
      "Eval Best Acc@1: 86.18201997780244\n",
      "Epoch:[15/80]\n",
      "Train Acc@1: 86.8262226820571 Mean loss: 0.3600301302771653 LR: [0.00046329123015975297]\n",
      "Eval Acc@1: 86.12652608213097\n",
      "Eval Best Acc@1: 86.18201997780244\n",
      "Epoch:[16/80]\n",
      "Train Acc@1: 86.9233437391606 Mean loss: 0.3552332042460948 LR: [0.0004401266686517653]\n",
      "Eval Acc@1: 85.96004439511654\n",
      "Eval Best Acc@1: 86.18201997780244\n",
      "Epoch:[17/80]\n",
      "Train Acc@1: 86.8678459937565 Mean loss: 0.3558836665037459 LR: [0.00041812033521917703]\n",
      "Eval Acc@1: 86.26526082130965\n",
      "Eval Best Acc@1: 86.26526082130965\n",
      "Epoch:[18/80]\n",
      "Train Acc@1: 86.98577870009386 Mean loss: 0.3515028209812873 LR: [0.00039721431845821814]\n",
      "Eval Acc@1: 86.26526082130965\n",
      "Eval Best Acc@1: 86.26526082130965\n",
      "Epoch:[19/80]\n",
      "Train Acc@1: 87.11758584542858 Mean loss: 0.3500408199904239 LR: [0.0003773536025353072]\n",
      "Eval Acc@1: 86.04328523862375\n",
      "Eval Best Acc@1: 86.26526082130965\n",
      "Epoch:[20/80]\n",
      "Train Acc@1: 87.15227193895248 Mean loss: 0.3426892404667044 LR: [0.0003584859224085418]\n",
      "Eval Acc@1: 86.34850166481687\n",
      "Eval Best Acc@1: 86.34850166481687\n",
      "Epoch:[21/80]\n",
      "Train Acc@1: 87.27714186346535 Mean loss: 0.3407315723927675 LR: [0.0003405616262881147]\n",
      "Eval Acc@1: 86.32075471698113\n",
      "Eval Best Acc@1: 86.34850166481687\n",
      "Epoch:[22/80]\n",
      "Train Acc@1: 87.25633021158515 Mean loss: 0.3404736766113644 LR: [0.00032353354497370894]\n",
      "Eval Acc@1: 86.04328523862375\n",
      "Eval Best Acc@1: 86.34850166481687\n",
      "Epoch:[23/80]\n",
      "Train Acc@1: 87.32570239069393 Mean loss: 0.3361866291513485 LR: [0.00030735686772502346]\n",
      "Eval Acc@1: 86.26526082130965\n",
      "Eval Best Acc@1: 86.34850166481687\n",
      "Epoch:[24/80]\n",
      "Train Acc@1: 87.58931668136337 Mean loss: 0.33259424204583715 LR: [0.00029198902433877225]\n",
      "Eval Acc@1: 86.3762486126526\n",
      "Eval Best Acc@1: 86.3762486126526\n",
      "Epoch:[25/80]\n",
      "Train Acc@1: 87.5130072787864 Mean loss: 0.33164014469469544 LR: [0.00027738957312183364]\n",
      "Eval Acc@1: 86.43174250832408\n",
      "Eval Best Acc@1: 86.43174250832408\n",
      "Epoch:[26/80]\n",
      "Train Acc@1: 87.58931668400972 Mean loss: 0.3302824046232004 LR: [0.0002635200944657419]\n",
      "Eval Acc@1: 86.3762486126526\n",
      "Eval Best Acc@1: 86.43174250832408\n",
      "Epoch:[27/80]\n",
      "Train Acc@1: 87.41588622697559 Mean loss: 0.3262297802530559 LR: [0.0002503440897424548]\n",
      "Eval Acc@1: 86.18201997780244\n",
      "Eval Best Acc@1: 86.43174250832408\n",
      "Epoch:[28/80]\n",
      "Train Acc@1: 87.55463058783948 Mean loss: 0.32439565513513785 LR: [0.00023782688525533205]\n",
      "Eval Acc@1: 86.45948945615983\n",
      "Eval Best Acc@1: 86.45948945615983\n",
      "Epoch:[29/80]\n",
      "Train Acc@1: 87.66562608394034 Mean loss: 0.32173956099864653 LR: [0.00022593554099256544]\n",
      "Eval Acc@1: 86.57047724750278\n",
      "Eval Best Acc@1: 86.57047724750278\n",
      "Epoch:[30/80]\n",
      "Train Acc@1: 87.65868886311848 Mean loss: 0.32199103695101444 LR: [0.00021463876394293716]\n",
      "Eval Acc@1: 86.29300776914539\n",
      "Eval Best Acc@1: 86.57047724750278\n",
      "Epoch:[31/80]\n",
      "Train Acc@1: 87.49219562425988 Mean loss: 0.32117627270981275 LR: [0.0002039068257457903]\n",
      "Eval Acc@1: 86.70921198668147\n",
      "Eval Best Acc@1: 86.70921198668147\n",
      "Epoch:[32/80]\n",
      "Train Acc@1: 87.58237946318786 Mean loss: 0.31924740970134735 LR: [0.00019371148445850077]\n",
      "Eval Acc@1: 86.43174250832408\n",
      "Eval Best Acc@1: 86.70921198668147\n",
      "Epoch:[33/80]\n",
      "Train Acc@1: 87.59625389689255 Mean loss: 0.31523594741536454 LR: [0.00018402591023557573]\n",
      "Eval Acc@1: 86.59822419533852\n",
      "Eval Best Acc@1: 86.70921198668147\n",
      "Epoch:[34/80]\n",
      "Train Acc@1: 87.83905653568179 Mean loss: 0.31482283616092355 LR: [0.00017482461472379692]\n",
      "Eval Acc@1: 86.48723640399557\n",
      "Eval Best Acc@1: 86.70921198668147\n",
      "Epoch:[35/80]\n",
      "Train Acc@1: 87.82518209668443 Mean loss: 0.3115538881547683 LR: [0.00016608338398760707]\n",
      "Eval Acc@1: 86.98668146503884\n",
      "Eval Best Acc@1: 86.98668146503884\n",
      "Epoch:[36/80]\n",
      "Train Acc@1: 87.90149149661505 Mean loss: 0.3115532455586754 LR: [0.0001577792147882267]\n",
      "Eval Acc@1: 86.98668146503884\n",
      "Eval Best Acc@1: 86.98668146503884\n",
      "Epoch:[37/80]\n",
      "Train Acc@1: 87.67950052029137 Mean loss: 0.3096728954563099 LR: [0.00014989025404881537]\n",
      "Eval Acc@1: 86.62597114317425\n",
      "Eval Best Acc@1: 86.98668146503884\n",
      "Epoch:[38/80]\n",
      "Train Acc@1: 87.97780089919202 Mean loss: 0.3076515038852143 LR: [0.00014239574134637458]\n",
      "Eval Acc@1: 86.76470588235294\n",
      "Eval Best Acc@1: 86.98668146503884\n",
      "Epoch:[39/80]\n",
      "Train Acc@1: 87.99861255107221 Mean loss: 0.30730396561918005 LR: [0.00013527595427905584]\n",
      "Eval Acc@1: 86.9589345172031\n",
      "Eval Best Acc@1: 86.98668146503884\n",
      "Epoch:[40/80]\n",
      "Train Acc@1: 87.9916753328967 Mean loss: 0.30521126836538315 LR: [0.00012851215656510304]\n",
      "Eval Acc@1: 87.04217536071032\n",
      "Eval Best Acc@1: 87.04217536071032\n",
      "Epoch:[41/80]\n",
      "Train Acc@1: 88.01942421089143 Mean loss: 0.3037434926470824 LR: [0.00012208654873684788]\n",
      "Eval Acc@1: 86.7369589345172\n",
      "Eval Best Acc@1: 87.04217536071032\n",
      "Epoch:[42/80]\n",
      "Train Acc@1: 88.00554977189407 Mean loss: 0.30349411927493275 LR: [0.00011598222130000548]\n",
      "Eval Acc@1: 86.93118756936737\n",
      "Eval Best Acc@1: 87.04217536071032\n",
      "Epoch:[43/80]\n",
      "Train Acc@1: 88.06104751465182 Mean loss: 0.30097537547086195 LR: [0.00011018311023500519]\n",
      "Eval Acc@1: 87.06992230854605\n",
      "Eval Best Acc@1: 87.06992230854605\n",
      "Epoch:[44/80]\n",
      "Train Acc@1: 88.15816857440167 Mean loss: 0.3006496446256616 LR: [0.00010467395472325493]\n",
      "Eval Acc@1: 87.12541620421753\n",
      "Eval Best Acc@1: 87.12541620421753\n",
      "Epoch:[45/80]\n",
      "Train Acc@1: 88.23447797168595 Mean loss: 0.2998940736319112 LR: [9.944025698709218e-05]\n",
      "Eval Acc@1: 86.93118756936737\n",
      "Eval Best Acc@1: 87.12541620421753\n",
      "Epoch:[46/80]\n",
      "Train Acc@1: 88.24141518986147 Mean loss: 0.2983624389213798 LR: [9.446824413773756e-05]\n",
      "Eval Acc@1: 87.01442841287458\n",
      "Eval Best Acc@1: 87.12541620421753\n",
      "Epoch:[47/80]\n",
      "Train Acc@1: 88.2414151925078 Mean loss: 0.2974705837205448 LR: [8.974483193085068e-05]\n",
      "Eval Acc@1: 87.20865704772476\n",
      "Eval Best Acc@1: 87.20865704772476\n",
      "Epoch:[48/80]\n",
      "Train Acc@1: 88.24835240803698 Mean loss: 0.2963507944239979 LR: [8.525759033430814e-05]\n",
      "Eval Acc@1: 87.15316315205328\n",
      "Eval Best Acc@1: 87.20865704772476\n",
      "Epoch:[49/80]\n",
      "Train Acc@1: 88.42178285977843 Mean loss: 0.29711760204713955 LR: [8.099471081759274e-05]\n",
      "Eval Acc@1: 87.40288568257492\n",
      "Eval Best Acc@1: 87.40288568257492\n",
      "Epoch:[50/80]\n",
      "Train Acc@1: 88.262226844388 Mean loss: 0.29546299217417177 LR: [7.69449752767131e-05]\n",
      "Eval Acc@1: 87.43063263041066\n",
      "Eval Best Acc@1: 87.43063263041066\n",
      "Epoch:[51/80]\n",
      "Train Acc@1: 88.36628511437434 Mean loss: 0.29429007460058265 LR: [7.309772651287744e-05]\n",
      "Eval Acc@1: 87.12541620421753\n",
      "Eval Best Acc@1: 87.43063263041066\n",
      "Epoch:[52/80]\n",
      "Train Acc@1: 88.51890391688192 Mean loss: 0.2932593568632033 LR: [6.944284018723356e-05]\n",
      "Eval Acc@1: 87.26415094339623\n",
      "Eval Best Acc@1: 87.43063263041066\n",
      "Epoch:[53/80]\n",
      "Train Acc@1: 88.33853624167229 Mean loss: 0.2927842460638654 LR: [6.597069817787189e-05]\n",
      "Eval Acc@1: 86.93118756936737\n",
      "Eval Best Acc@1: 87.43063263041066\n",
      "Epoch:[54/80]\n",
      "Train Acc@1: 88.38709676890088 Mean loss: 0.2922097249368651 LR: [6.267216326897829e-05]\n",
      "Eval Acc@1: 87.29189789123197\n",
      "Eval Best Acc@1: 87.43063263041066\n",
      "Epoch:[55/80]\n",
      "Train Acc@1: 88.36628511966701 Mean loss: 0.29161644113802276 LR: [5.953855510552937e-05]\n",
      "Eval Acc@1: 86.9589345172031\n",
      "Eval Best Acc@1: 87.43063263041066\n",
      "Epoch:[56/80]\n",
      "Train Acc@1: 88.33159902614311 Mean loss: 0.2919152935851464 LR: [5.65616273502529e-05]\n",
      "Eval Acc@1: 87.09766925638179\n",
      "Eval Best Acc@1: 87.43063263041066\n",
      "Epoch:[57/80]\n",
      "Train Acc@1: 88.49809226500173 Mean loss: 0.2913007118401274 LR: [5.373354598274025e-05]\n",
      "Eval Acc@1: 87.43063263041066\n",
      "Eval Best Acc@1: 87.43063263041066\n",
      "Epoch:[58/80]\n",
      "Train Acc@1: 88.42178286242476 Mean loss: 0.2899326603628893 LR: [5.104686868360323e-05]\n",
      "Eval Acc@1: 87.18091009988902\n",
      "Eval Best Acc@1: 87.43063263041066\n",
      "Epoch:[59/80]\n",
      "Train Acc@1: 88.56052722858134 Mean loss: 0.290094612347605 LR: [4.849452524942307e-05]\n",
      "Eval Acc@1: 87.15316315205328\n",
      "Eval Best Acc@1: 87.43063263041066\n",
      "Epoch:[60/80]\n",
      "Train Acc@1: 88.48421782865071 Mean loss: 0.28889861333686695 LR: [4.606979898695191e-05]\n",
      "Eval Acc@1: 87.34739178690344\n",
      "Eval Best Acc@1: 87.43063263041066\n",
      "Epoch:[61/80]\n",
      "Train Acc@1: 88.44953173512681 Mean loss: 0.28900184785634014 LR: [4.376630903760431e-05]\n",
      "Eval Acc@1: 87.2364039955605\n",
      "Eval Best Acc@1: 87.43063263041066\n",
      "Epoch:[62/80]\n",
      "Train Acc@1: 88.54665279223032 Mean loss: 0.28818530108021423 LR: [4.157799358572409e-05]\n",
      "Eval Acc@1: 87.2364039955605\n",
      "Eval Best Acc@1: 87.43063263041066\n",
      "Epoch:[63/80]\n",
      "Train Acc@1: 88.51196670135276 Mean loss: 0.28732663271042097 LR: [3.9499093906437885e-05]\n",
      "Eval Acc@1: 87.34739178690344\n",
      "Eval Best Acc@1: 87.43063263041066\n",
      "Epoch:[64/80]\n",
      "Train Acc@1: 88.53971557405481 Mean loss: 0.28813681856984585 LR: [3.752413921111599e-05]\n",
      "Eval Acc@1: 87.20865704772476\n",
      "Eval Best Acc@1: 87.43063263041066\n",
      "Epoch:[65/80]\n",
      "Train Acc@1: 88.56746444146417 Mean loss: 0.28787060352289573 LR: [3.564793225056019e-05]\n",
      "Eval Acc@1: 87.20865704772476\n",
      "Eval Best Acc@1: 87.43063263041066\n",
      "Epoch:[66/80]\n",
      "Train Acc@1: 88.56052722858134 Mean loss: 0.28738452461177266 LR: [3.3865535638032174e-05]\n",
      "Eval Acc@1: 87.2364039955605\n",
      "Eval Best Acc@1: 87.43063263041066\n",
      "Epoch:[67/80]\n",
      "Train Acc@1: 88.5258411324111 Mean loss: 0.28647833004330114 LR: [3.2172258856130564e-05]\n",
      "Eval Acc@1: 87.40288568257492\n",
      "Eval Best Acc@1: 87.43063263041066\n",
      "Epoch:[68/80]\n",
      "Train Acc@1: 88.57440165963969 Mean loss: 0.28599908545745156 LR: [3.056364591332403e-05]\n",
      "Eval Acc@1: 87.43063263041066\n",
      "Eval Best Acc@1: 87.43063263041066\n",
      "Epoch:[69/80]\n",
      "Train Acc@1: 88.61602496869276 Mean loss: 0.2855192784187013 LR: [2.903546361765783e-05]\n",
      "Eval Acc@1: 87.26415094339623\n",
      "Eval Best Acc@1: 87.43063263041066\n",
      "Epoch:[70/80]\n",
      "Train Acc@1: 88.53277835323296 Mean loss: 0.2858111640784593 LR: [2.758369043677494e-05]\n",
      "Eval Acc@1: 87.37513873473918\n",
      "Eval Best Acc@1: 87.43063263041066\n",
      "Epoch:[71/80]\n",
      "Train Acc@1: 88.50502947788456 Mean loss: 0.2849824201084871 LR: [2.620450591493619e-05]\n",
      "Eval Acc@1: 87.29189789123197\n",
      "Eval Best Acc@1: 87.43063263041066\n",
      "Epoch:[72/80]\n",
      "Train Acc@1: 88.58133888310788 Mean loss: 0.2853736501615659 LR: [2.489428061918938e-05]\n",
      "Eval Acc@1: 87.3196448390677\n",
      "Eval Best Acc@1: 87.43063263041066\n",
      "Epoch:[73/80]\n",
      "Train Acc@1: 88.55359000775948 Mean loss: 0.2849678529047333 LR: [2.364956658822991e-05]\n",
      "Eval Acc@1: 87.34739178690344\n",
      "Eval Best Acc@1: 87.43063263041066\n",
      "Epoch:[74/80]\n",
      "Train Acc@1: 88.56746444146417 Mean loss: 0.28408644453877896 LR: [2.2467088258818413e-05]\n",
      "Eval Acc@1: 87.34739178690344\n",
      "Eval Best Acc@1: 87.43063263041066\n",
      "Epoch:[75/80]\n",
      "Train Acc@1: 88.67152271938953 Mean loss: 0.28344475688923776 LR: [2.134373384587749e-05]\n",
      "Eval Acc@1: 87.3196448390677\n",
      "Eval Best Acc@1: 87.43063263041066\n",
      "Epoch:[76/80]\n",
      "Train Acc@1: 88.67152271674318 Mean loss: 0.28375859571769174 LR: [2.0276547153583614e-05]\n",
      "Eval Acc@1: 87.40288568257492\n",
      "Eval Best Acc@1: 87.43063263041066\n",
      "Epoch:[77/80]\n",
      "Train Acc@1: 88.65764827774582 Mean loss: 0.28369737100020975 LR: [1.9262719795904432e-05]\n",
      "Eval Acc@1: 87.4583795782464\n",
      "Eval Best Acc@1: 87.4583795782464\n",
      "Epoch:[78/80]\n",
      "Train Acc@1: 88.59521331416622 Mean loss: 0.283546256412447 LR: [1.829958380610921e-05]\n",
      "Eval Acc@1: 87.2364039955605\n",
      "Eval Best Acc@1: 87.4583795782464\n",
      "Epoch:[79/80]\n",
      "Train Acc@1: 88.61602497398543 Mean loss: 0.28291802170925434 LR: [1.738460461580375e-05]\n",
      "Eval Acc@1: 87.37513873473918\n",
      "Eval Best Acc@1: 87.4583795782464\n",
      "Epoch:[80/80]\n",
      "Train Acc@1: 88.58827609863705 Mean loss: 0.2830694711775379 LR: [1.6515374385013564e-05]\n",
      "Eval Acc@1: 87.3196448390677\n",
      "Eval Best Acc@1: 87.4583795782464\n",
      "Best Train Acc@1: 88.67152271938953\n"
     ]
    }
   ],
   "source": [
    "!python main.py --config config/train_device.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_label(label判断)\n",
    "\n",
    "`BEST ACC@1：88.82`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters:\n",
      "{'work_dir': './work_dir/label', 'config': 'config/train_label.yaml', 'phase': 'train', 'save_score': False, 'seed': 1, 'feeder': 'feeder.Feeder_label', 'num_worker': 8, 'train_feeder_args': {'data_path': './data/train.pkl', 'snr': 0}, 'test_feeder_args': {'data_path': './data/test.pkl', 'snr': 0}, 'model': 'net.CNN', 'model_args': {'channels': 13, 'num_classes': 2}, 'weights': None, 'ignore_weights': [], 'base_lr': 0.001, 'step': [10, 50], 'device': 0, 'optimizer': 'Adam', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 80, 'weight_decay': 1e-05}\n",
      "\n",
      "Epoch:[1/80]\n",
      "Train Acc@1: 81.51231355696885 Mean loss: 0.47089475037249845 LR: [0.00095]\n",
      "Eval Acc@1: 81.2708102108768\n",
      "Eval Best Acc@1: 81.2708102108768\n",
      "Epoch:[2/80]\n",
      "Train Acc@1: 81.81755116198404 Mean loss: 0.45791645704117495 LR: [0.0009025]\n",
      "Eval Acc@1: 81.52053274139844\n",
      "Eval Best Acc@1: 81.52053274139844\n",
      "Epoch:[3/80]\n",
      "Train Acc@1: 83.35067637347943 Mean loss: 0.4349096530174787 LR: [0.000857375]\n",
      "Eval Acc@1: 84.07325194228635\n",
      "Eval Best Acc@1: 84.07325194228635\n",
      "Epoch:[4/80]\n",
      "Train Acc@1: 84.38432188163067 Mean loss: 0.4165718596329731 LR: [0.0008145062499999999]\n",
      "Eval Acc@1: 84.15649278579356\n",
      "Eval Best Acc@1: 84.15649278579356\n",
      "Epoch:[5/80]\n",
      "Train Acc@1: 84.66874783211932 Mean loss: 0.41065890941999655 LR: [0.0007737809374999998]\n",
      "Eval Acc@1: 84.73917869034406\n",
      "Eval Best Acc@1: 84.73917869034406\n",
      "Epoch:[6/80]\n",
      "Train Acc@1: 84.98785986290018 Mean loss: 0.4023784818375005 LR: [0.0007350918906249997]\n",
      "Eval Acc@1: 84.82241953385127\n",
      "Eval Best Acc@1: 84.82241953385127\n",
      "Epoch:[7/80]\n",
      "Train Acc@1: 85.20985084451655 Mean loss: 0.39854820705620586 LR: [0.0006983372960937497]\n",
      "Eval Acc@1: 84.82241953385127\n",
      "Eval Best Acc@1: 84.82241953385127\n",
      "Epoch:[8/80]\n",
      "Train Acc@1: 85.52896288323642 Mean loss: 0.3925992945390465 LR: [0.0006634204312890621]\n",
      "Eval Acc@1: 85.3496115427303\n",
      "Eval Best Acc@1: 85.3496115427303\n",
      "Epoch:[9/80]\n",
      "Train Acc@1: 85.79257717390587 Mean loss: 0.3878356276360233 LR: [0.000630249409724609]\n",
      "Eval Acc@1: 84.68368479467259\n",
      "Eval Best Acc@1: 85.3496115427303\n",
      "Epoch:[10/80]\n",
      "Train Acc@1: 86.08394033727735 Mean loss: 0.38405109170527585 LR: [0.0005987369392383785]\n",
      "Eval Acc@1: 85.68257491675915\n",
      "Eval Best Acc@1: 85.68257491675915\n",
      "Epoch:[11/80]\n",
      "Train Acc@1: 86.24349635531412 Mean loss: 0.37889836214284983 LR: [0.0005688000922764595]\n",
      "Eval Acc@1: 85.71032186459489\n",
      "Eval Best Acc@1: 85.71032186459489\n",
      "Epoch:[12/80]\n",
      "Train Acc@1: 86.47936177063518 Mean loss: 0.37631402909755707 LR: [0.0005403600876626365]\n",
      "Eval Acc@1: 85.87680355160933\n",
      "Eval Best Acc@1: 85.87680355160933\n",
      "Epoch:[13/80]\n",
      "Train Acc@1: 86.42386402523108 Mean loss: 0.3737244319863024 LR: [0.0005133420832795047]\n",
      "Eval Acc@1: 85.79356270810212\n",
      "Eval Best Acc@1: 85.87680355160933\n",
      "Epoch:[14/80]\n",
      "Train Acc@1: 86.65279223031564 Mean loss: 0.3719493558844634 LR: [0.00048767497911552944]\n",
      "Eval Acc@1: 86.07103218645949\n",
      "Eval Best Acc@1: 86.07103218645949\n",
      "Epoch:[15/80]\n",
      "Train Acc@1: 86.54873395768297 Mean loss: 0.36808262818155035 LR: [0.00046329123015975297]\n",
      "Eval Acc@1: 85.90455049944507\n",
      "Eval Best Acc@1: 86.07103218645949\n",
      "Epoch:[16/80]\n",
      "Train Acc@1: 86.87478320663934 Mean loss: 0.3628053264280336 LR: [0.0004401266686517653]\n",
      "Eval Acc@1: 86.40399556048834\n",
      "Eval Best Acc@1: 86.40399556048834\n",
      "Epoch:[17/80]\n",
      "Train Acc@1: 87.02740200914693 Mean loss: 0.3607013636326368 LR: [0.00041812033521917703]\n",
      "Eval Acc@1: 86.09877913429523\n",
      "Eval Best Acc@1: 86.40399556048834\n",
      "Epoch:[18/80]\n",
      "Train Acc@1: 87.13146027913326 Mean loss: 0.35659388070349146 LR: [0.00039721431845821814]\n",
      "Eval Acc@1: 86.32075471698113\n",
      "Eval Best Acc@1: 86.40399556048834\n",
      "Epoch:[19/80]\n",
      "Train Acc@1: 87.20083246618105 Mean loss: 0.3542911026593858 LR: [0.0003773536025353072]\n",
      "Eval Acc@1: 86.43174250832408\n",
      "Eval Best Acc@1: 86.43174250832408\n",
      "Epoch:[20/80]\n",
      "Train Acc@1: 87.35345126604231 Mean loss: 0.3525277396614573 LR: [0.0003584859224085418]\n",
      "Eval Acc@1: 86.54273029966704\n",
      "Eval Best Acc@1: 86.54273029966704\n",
      "Epoch:[21/80]\n",
      "Train Acc@1: 87.31876516987208 Mean loss: 0.3490910420639325 LR: [0.0003405616262881147]\n",
      "Eval Acc@1: 86.23751387347392\n",
      "Eval Best Acc@1: 86.54273029966704\n",
      "Epoch:[22/80]\n",
      "Train Acc@1: 87.5130072787864 Mean loss: 0.34618833456682946 LR: [0.00032353354497370894]\n",
      "Eval Acc@1: 86.93118756936737\n",
      "Eval Best Acc@1: 86.93118756936737\n",
      "Epoch:[23/80]\n",
      "Train Acc@1: 87.33263960886944 Mean loss: 0.34718208456725147 LR: [0.00030735686772502346]\n",
      "Eval Acc@1: 86.70921198668147\n",
      "Eval Best Acc@1: 86.93118756936737\n",
      "Epoch:[24/80]\n",
      "Train Acc@1: 87.5130072787864 Mean loss: 0.3448230709913558 LR: [0.00029198902433877225]\n",
      "Eval Acc@1: 86.59822419533852\n",
      "Eval Best Acc@1: 86.93118756936737\n",
      "Epoch:[25/80]\n",
      "Train Acc@1: 87.56850502683683 Mean loss: 0.3410566776859022 LR: [0.00027738957312183364]\n",
      "Eval Acc@1: 86.48723640399557\n",
      "Eval Best Acc@1: 86.93118756936737\n",
      "Epoch:[26/80]\n",
      "Train Acc@1: 87.65175164494298 Mean loss: 0.33720119917287233 LR: [0.0002635200944657419]\n",
      "Eval Acc@1: 86.87569367369589\n",
      "Eval Best Acc@1: 86.93118756936737\n",
      "Epoch:[27/80]\n",
      "Train Acc@1: 87.74887269940014 Mean loss: 0.33464672854911964 LR: [0.0002503440897424548]\n",
      "Eval Acc@1: 87.09766925638179\n",
      "Eval Best Acc@1: 87.09766925638179\n",
      "Epoch:[28/80]\n",
      "Train Acc@1: 87.88067984208853 Mean loss: 0.33228472415852334 LR: [0.00023782688525533205]\n",
      "Eval Acc@1: 87.04217536071032\n",
      "Eval Best Acc@1: 87.09766925638179\n",
      "Epoch:[29/80]\n",
      "Train Acc@1: 87.97086368101651 Mean loss: 0.3322091812053613 LR: [0.00022593554099256544]\n",
      "Eval Acc@1: 87.04217536071032\n",
      "Eval Best Acc@1: 87.09766925638179\n",
      "Epoch:[30/80]\n",
      "Train Acc@1: 87.83905653832814 Mean loss: 0.32892893874539736 LR: [0.00021463876394293716]\n",
      "Eval Acc@1: 86.93118756936737\n",
      "Eval Best Acc@1: 87.09766925638179\n",
      "Epoch:[31/80]\n",
      "Train Acc@1: 87.95005202384364 Mean loss: 0.32831778733339984 LR: [0.0002039068257457903]\n",
      "Eval Acc@1: 87.26415094339623\n",
      "Eval Best Acc@1: 87.26415094339623\n",
      "Epoch:[32/80]\n",
      "Train Acc@1: 87.99861255371856 Mean loss: 0.32639683697339705 LR: [0.00019371148445850077]\n",
      "Eval Acc@1: 87.29189789123197\n",
      "Eval Best Acc@1: 87.29189789123197\n",
      "Epoch:[33/80]\n",
      "Train Acc@1: 88.00554976924774 Mean loss: 0.3239582149987727 LR: [0.00018402591023557573]\n",
      "Eval Acc@1: 87.65260821309656\n",
      "Eval Best Acc@1: 87.65260821309656\n",
      "Epoch:[34/80]\n",
      "Train Acc@1: 88.19979187816206 Mean loss: 0.32200886856401917 LR: [0.00017482461472379692]\n",
      "Eval Acc@1: 87.01442841287458\n",
      "Eval Best Acc@1: 87.65260821309656\n",
      "Epoch:[35/80]\n",
      "Train Acc@1: 88.13735691722879 Mean loss: 0.3211795842621179 LR: [0.00016608338398760707]\n",
      "Eval Acc@1: 87.48612652608213\n",
      "Eval Best Acc@1: 87.65260821309656\n",
      "Epoch:[36/80]\n",
      "Train Acc@1: 88.1234824835241 Mean loss: 0.31924319432108805 LR: [0.0001577792147882267]\n",
      "Eval Acc@1: 87.62486126526082\n",
      "Eval Best Acc@1: 87.65260821309656\n",
      "Epoch:[37/80]\n",
      "Train Acc@1: 88.23447796903962 Mean loss: 0.31976750928216274 LR: [0.00014989025404881537]\n",
      "Eval Acc@1: 87.59711431742508\n",
      "Eval Best Acc@1: 87.65260821309656\n",
      "Epoch:[38/80]\n",
      "Train Acc@1: 88.11654526534859 Mean loss: 0.3183726005058373 LR: [0.00014239574134637458]\n",
      "Eval Acc@1: 87.34739178690344\n",
      "Eval Best Acc@1: 87.65260821309656\n",
      "Epoch:[39/80]\n",
      "Train Acc@1: 88.17204301075269 Mean loss: 0.3152671486666772 LR: [0.00013527595427905584]\n",
      "Eval Acc@1: 87.51387347391787\n",
      "Eval Best Acc@1: 87.65260821309656\n",
      "Epoch:[40/80]\n",
      "Train Acc@1: 88.31772458714576 Mean loss: 0.3142395535137801 LR: [0.00012851215656510304]\n",
      "Eval Acc@1: 87.20865704772476\n",
      "Eval Best Acc@1: 87.65260821309656\n",
      "Epoch:[41/80]\n",
      "Train Acc@1: 88.30385015344108 Mean loss: 0.3138983389445111 LR: [0.00012208654873684788]\n",
      "Eval Acc@1: 87.79134295227524\n",
      "Eval Best Acc@1: 87.79134295227524\n",
      "Epoch:[42/80]\n",
      "Train Acc@1: 88.26222684174166 Mean loss: 0.31323036492134615 LR: [0.00011598222130000548]\n",
      "Eval Acc@1: 87.51387347391787\n",
      "Eval Best Acc@1: 87.79134295227524\n",
      "Epoch:[43/80]\n",
      "Train Acc@1: 88.31078737161658 Mean loss: 0.3115014462212546 LR: [0.00011018311023500519]\n",
      "Eval Acc@1: 87.40288568257492\n",
      "Eval Best Acc@1: 87.79134295227524\n",
      "Epoch:[44/80]\n",
      "Train Acc@1: 88.42178286507111 Mean loss: 0.31002375523073483 LR: [0.00010467395472325493]\n",
      "Eval Acc@1: 87.51387347391787\n",
      "Eval Best Acc@1: 87.79134295227524\n",
      "Epoch:[45/80]\n",
      "Train Acc@1: 88.32466181061395 Mean loss: 0.30951773348899014 LR: [9.944025698709218e-05]\n",
      "Eval Acc@1: 87.59711431742508\n",
      "Eval Best Acc@1: 87.79134295227524\n",
      "Epoch:[46/80]\n",
      "Train Acc@1: 88.3870967715472 Mean loss: 0.309294335675978 LR: [9.446824413773756e-05]\n",
      "Eval Acc@1: 87.5416204217536\n",
      "Eval Best Acc@1: 87.79134295227524\n",
      "Epoch:[47/80]\n",
      "Train Acc@1: 88.49115504153355 Mean loss: 0.30834857064538296 LR: [8.974483193085068e-05]\n",
      "Eval Acc@1: 87.93007769145395\n",
      "Eval Best Acc@1: 87.93007769145395\n",
      "Epoch:[48/80]\n",
      "Train Acc@1: 88.50502947788456 Mean loss: 0.3068401272845479 LR: [8.525759033430814e-05]\n",
      "Eval Acc@1: 87.84683684794672\n",
      "Eval Best Acc@1: 87.93007769145395\n",
      "Epoch:[49/80]\n",
      "Train Acc@1: 88.51890391952827 Mean loss: 0.30569108651406995 LR: [8.099471081759274e-05]\n",
      "Eval Acc@1: 87.73584905660377\n",
      "Eval Best Acc@1: 87.93007769145395\n",
      "Epoch:[50/80]\n",
      "Train Acc@1: 88.48421782600437 Mean loss: 0.30644841439428583 LR: [7.69449752767131e-05]\n",
      "Eval Acc@1: 87.87458379578247\n",
      "Eval Best Acc@1: 87.93007769145395\n",
      "Epoch:[51/80]\n",
      "Train Acc@1: 88.61602497133909 Mean loss: 0.30461068352503057 LR: [7.309772651287744e-05]\n",
      "Eval Acc@1: 87.56936736958934\n",
      "Eval Best Acc@1: 87.93007769145395\n",
      "Epoch:[52/80]\n",
      "Train Acc@1: 88.62296219216094 Mean loss: 0.30402752051574994 LR: [6.944284018723356e-05]\n",
      "Eval Acc@1: 87.6803551609323\n",
      "Eval Best Acc@1: 87.93007769145395\n",
      "Epoch:[53/80]\n",
      "Train Acc@1: 88.42178286242476 Mean loss: 0.30418491719570834 LR: [6.597069817787189e-05]\n",
      "Eval Acc@1: 88.06881243063263\n",
      "Eval Best Acc@1: 88.06881243063263\n",
      "Epoch:[54/80]\n",
      "Train Acc@1: 88.51890391688192 Mean loss: 0.30323103360370196 LR: [6.267216326897829e-05]\n",
      "Eval Acc@1: 87.6803551609323\n",
      "Eval Best Acc@1: 88.06881243063263\n",
      "Epoch:[55/80]\n",
      "Train Acc@1: 88.58133888310788 Mean loss: 0.30275552640710257 LR: [5.953855510552937e-05]\n",
      "Eval Acc@1: 87.65260821309656\n",
      "Eval Best Acc@1: 88.06881243063263\n",
      "Epoch:[56/80]\n",
      "Train Acc@1: 88.59521331945889 Mean loss: 0.30199982245675233 LR: [5.65616273502529e-05]\n",
      "Eval Acc@1: 87.79134295227524\n",
      "Eval Best Acc@1: 88.06881243063263\n",
      "Epoch:[57/80]\n",
      "Train Acc@1: 88.69233436862338 Mean loss: 0.30117787882290054 LR: [5.373354598274025e-05]\n",
      "Eval Acc@1: 87.93007769145395\n",
      "Eval Best Acc@1: 88.06881243063263\n",
      "Epoch:[58/80]\n",
      "Train Acc@1: 88.65764828039217 Mean loss: 0.30059717760413096 LR: [5.104686868360323e-05]\n",
      "Eval Acc@1: 87.65260821309656\n",
      "Eval Best Acc@1: 88.06881243063263\n",
      "Epoch:[59/80]\n",
      "Train Acc@1: 88.68539715044787 Mean loss: 0.3002235083057817 LR: [4.849452524942307e-05]\n",
      "Eval Acc@1: 87.95782463928968\n",
      "Eval Best Acc@1: 88.06881243063263\n",
      "Epoch:[60/80]\n",
      "Train Acc@1: 88.65071106221666 Mean loss: 0.2999025875356345 LR: [4.606979898695191e-05]\n",
      "Eval Acc@1: 87.70810210876803\n",
      "Eval Best Acc@1: 88.06881243063263\n",
      "Epoch:[61/80]\n",
      "Train Acc@1: 88.60908775580992 Mean loss: 0.2985945793643462 LR: [4.376630903760431e-05]\n",
      "Eval Acc@1: 87.87458379578247\n",
      "Eval Best Acc@1: 88.06881243063263\n",
      "Epoch:[62/80]\n",
      "Train Acc@1: 88.62989941033645 Mean loss: 0.29949165353205354 LR: [4.157799358572409e-05]\n",
      "Eval Acc@1: 88.12430632630411\n",
      "Eval Best Acc@1: 88.12430632630411\n",
      "Epoch:[63/80]\n",
      "Train Acc@1: 88.74783211932015 Mean loss: 0.2978821423860778 LR: [3.9499093906437885e-05]\n",
      "Eval Acc@1: 87.93007769145395\n",
      "Eval Best Acc@1: 88.12430632630411\n",
      "Epoch:[64/80]\n",
      "Train Acc@1: 88.62989940769012 Mean loss: 0.29895933341663494 LR: [3.752413921111599e-05]\n",
      "Eval Acc@1: 88.01331853496116\n",
      "Eval Best Acc@1: 88.12430632630411\n",
      "Epoch:[65/80]\n",
      "Train Acc@1: 88.75476933484933 Mean loss: 0.2979261354930633 LR: [3.564793225056019e-05]\n",
      "Eval Acc@1: 87.93007769145395\n",
      "Eval Best Acc@1: 88.12430632630411\n",
      "Epoch:[66/80]\n",
      "Train Acc@1: 88.78251820755138 Mean loss: 0.29753451880100557 LR: [3.3865535638032174e-05]\n",
      "Eval Acc@1: 88.09655937846837\n",
      "Eval Best Acc@1: 88.12430632630411\n",
      "Epoch:[67/80]\n",
      "Train Acc@1: 88.76864376855401 Mean loss: 0.2969698342865547 LR: [3.2172258856130564e-05]\n",
      "Eval Acc@1: 88.01331853496116\n",
      "Eval Best Acc@1: 88.12430632630411\n",
      "Epoch:[68/80]\n",
      "Train Acc@1: 88.75476933749566 Mean loss: 0.29793762283778824 LR: [3.056364591332403e-05]\n",
      "Eval Acc@1: 88.09655937846837\n",
      "Eval Best Acc@1: 88.12430632630411\n",
      "Epoch:[69/80]\n",
      "Train Acc@1: 88.82414151925079 Mean loss: 0.2967143919220013 LR: [2.903546361765783e-05]\n",
      "Eval Acc@1: 87.95782463928968\n",
      "Eval Best Acc@1: 88.12430632630411\n",
      "Epoch:[70/80]\n",
      "Train Acc@1: 88.81026708025342 Mean loss: 0.29635530960770834 LR: [2.758369043677494e-05]\n",
      "Eval Acc@1: 88.06881243063263\n",
      "Eval Best Acc@1: 88.12430632630411\n",
      "Epoch:[71/80]\n",
      "Train Acc@1: 88.71314602314992 Mean loss: 0.295754608986652 LR: [2.620450591493619e-05]\n",
      "Eval Acc@1: 87.95782463928968\n",
      "Eval Best Acc@1: 88.12430632630411\n",
      "Epoch:[72/80]\n",
      "Train Acc@1: 88.8033298620779 Mean loss: 0.2959142732145512 LR: [2.489428061918938e-05]\n",
      "Eval Acc@1: 87.87458379578247\n",
      "Eval Best Acc@1: 88.12430632630411\n",
      "Epoch:[73/80]\n",
      "Train Acc@1: 88.80332986472425 Mean loss: 0.2959802630728325 LR: [2.364956658822991e-05]\n",
      "Eval Acc@1: 88.12430632630411\n",
      "Eval Best Acc@1: 88.12430632630411\n",
      "Epoch:[74/80]\n",
      "Train Acc@1: 88.76170655037849 Mean loss: 0.2949933041777231 LR: [2.2467088258818413e-05]\n",
      "Eval Acc@1: 87.95782463928968\n",
      "Eval Best Acc@1: 88.12430632630411\n",
      "Epoch:[75/80]\n",
      "Train Acc@1: 88.77558098672952 Mean loss: 0.29458089060751735 LR: [2.134373384587749e-05]\n",
      "Eval Acc@1: 88.01331853496116\n",
      "Eval Best Acc@1: 88.12430632630411\n",
      "Epoch:[76/80]\n",
      "Train Acc@1: 88.72702046214728 Mean loss: 0.2946125359925549 LR: [2.0276547153583614e-05]\n",
      "Eval Acc@1: 88.09655937846837\n",
      "Eval Best Acc@1: 88.12430632630411\n",
      "Epoch:[77/80]\n",
      "Train Acc@1: 88.81026707760708 Mean loss: 0.2947311458730065 LR: [1.9262719795904432e-05]\n",
      "Eval Acc@1: 87.84683684794672\n",
      "Eval Best Acc@1: 88.12430632630411\n",
      "Epoch:[78/80]\n",
      "Train Acc@1: 88.78945542308054 Mean loss: 0.29425890265708476 LR: [1.829958380610921e-05]\n",
      "Eval Acc@1: 88.17980022197558\n",
      "Eval Best Acc@1: 88.17980022197558\n",
      "Epoch:[79/80]\n",
      "Train Acc@1: 88.81026707760708 Mean loss: 0.2942250377572743 LR: [1.738460461580375e-05]\n",
      "Eval Acc@1: 88.01331853496116\n",
      "Eval Best Acc@1: 88.17980022197558\n",
      "Epoch:[80/80]\n",
      "Train Acc@1: 88.80332985943157 Mean loss: 0.2940367449042016 LR: [1.6515374385013564e-05]\n",
      "Eval Acc@1: 88.0410654827969\n",
      "Eval Best Acc@1: 88.17980022197558\n",
      "Best Train Acc@1: 88.82414151925079\n"
     ]
    }
   ],
   "source": [
    "!python main.py --config config/train_label.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_snr(snr无监督判断)\n",
    "\n",
    "best mse：61.24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters:\n",
      "{'work_dir': './work_dir/us_snr', 'config': 'config/us_train_snr.yaml', 'phase': 'train', 'save_score': False, 'seed': 1, 'feeder': 'feeder.Us_Feeder_snr', 'num_worker': 8, 'train_feeder_args': {'data_path': './data/train.pkl'}, 'test_feeder_args': {'data_path': './data/test.pkl'}, 'model': 'net.Us_CNN', 'model_args': {'channels': 13, 'num_classes': 3}, 'weights': None, 'ignore_weights': [], 'base_lr': 0.001, 'step': [10, 50], 'device': 0, 'optimizer': 'Adam', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 80, 'weight_decay': 1e-05}\n",
      "\n",
      "Epoch:[1/80]\n",
      "Train MSE: 74.76676536910257 Mean loss: 74.76683204696023 LR: [0.00095]\n",
      "Eval MSE: 73.99404423438837\n",
      "Eval Best MSE: 73.99404423438837\n",
      "Epoch:[2/80]\n",
      "Train MSE: 68.6622575937854 Mean loss: 68.66290148898695 LR: [0.0009025]\n",
      "Eval MSE: 68.6757048403295\n",
      "Eval Best MSE: 68.6757048403295\n",
      "Epoch:[3/80]\n",
      "Train MSE: 68.59749100837615 Mean loss: 68.59746722497884 LR: [0.000857375]\n",
      "Eval MSE: 68.67159920430298\n",
      "Eval Best MSE: 68.67159920430298\n",
      "Epoch:[4/80]\n",
      "Train MSE: 68.59507053537112 Mean loss: 68.59707580656695 LR: [0.0008145062499999999]\n",
      "Eval MSE: 68.67121942529315\n",
      "Eval Best MSE: 68.67121942529315\n",
      "Epoch:[5/80]\n",
      "Train MSE: 68.5905994531281 Mean loss: 68.58990083502594 LR: [0.0007737809374999998]\n",
      "Eval MSE: 68.66335824732863\n",
      "Eval Best MSE: 68.66335824732863\n",
      "Epoch:[6/80]\n",
      "Train MSE: 68.58483660509717 Mean loss: 68.58479206378644 LR: [0.0007350918906249997]\n",
      "Eval MSE: 68.65934994747319\n",
      "Eval Best MSE: 68.65934994747319\n",
      "Epoch:[7/80]\n",
      "Train MSE: 68.58338590796828 Mean loss: 68.58198163072034 LR: [0.0006983372960937497]\n",
      "Eval MSE: 68.65887625888679\n",
      "Eval Best MSE: 68.65887625888679\n",
      "Epoch:[8/80]\n",
      "Train MSE: 68.58265620247175 Mean loss: 68.5825773272994 LR: [0.0006634204312890621]\n",
      "Eval MSE: 68.65844714143212\n",
      "Eval Best MSE: 68.65844714143212\n",
      "Epoch:[9/80]\n",
      "Train MSE: 68.58200007365996 Mean loss: 68.58120425636247 LR: [0.000630249409724609]\n",
      "Eval MSE: 68.65769362934775\n",
      "Eval Best MSE: 68.65769362934775\n",
      "Epoch:[10/80]\n",
      "Train MSE: 68.58159028916762 Mean loss: 68.58369577847995 LR: [0.0005987369392383785]\n",
      "Eval MSE: 68.65643727722055\n",
      "Eval Best MSE: 68.65643727722055\n",
      "Epoch:[11/80]\n",
      "Train MSE: 68.57943525011105 Mean loss: 68.57746969031159 LR: [0.0005688000922764595]\n",
      "Eval MSE: 68.65357557685562\n",
      "Eval Best MSE: 68.65357557685562\n",
      "Epoch:[12/80]\n",
      "Train MSE: 68.57632108845591 Mean loss: 68.57911137010925 LR: [0.0005403600876626365]\n",
      "Eval MSE: 68.65220456082778\n",
      "Eval Best MSE: 68.65220456082778\n",
      "Epoch:[13/80]\n",
      "Train MSE: 68.57489564075044 Mean loss: 68.57434053816034 LR: [0.0005133420832795047]\n",
      "Eval MSE: 68.65038740163021\n",
      "Eval Best MSE: 68.65038740163021\n",
      "Epoch:[14/80]\n",
      "Train MSE: 68.57193831488884 Mean loss: 68.57129325528116 LR: [0.00048767497911552944]\n",
      "Eval MSE: 68.64625621574083\n",
      "Eval Best MSE: 68.64625621574083\n",
      "Epoch:[15/80]\n",
      "Train MSE: 68.56971986197036 Mean loss: 68.56805981404682 LR: [0.00046329123015975297]\n",
      "Eval MSE: 68.64605040273268\n",
      "Eval Best MSE: 68.64605040273268\n",
      "Epoch:[16/80]\n",
      "Train MSE: 68.56908686251182 Mean loss: 68.57171604337071 LR: [0.0004401266686517653]\n",
      "Eval MSE: 68.64516787400213\n",
      "Eval Best MSE: 68.64516787400213\n",
      "Epoch:[17/80]\n",
      "Train MSE: 68.5686999882559 Mean loss: 68.5702155468732 LR: [0.00041812033521917703]\n",
      "Eval MSE: 68.64503276061447\n",
      "Eval Best MSE: 68.64503276061447\n",
      "Epoch:[18/80]\n",
      "Train MSE: 68.5681932016885 Mean loss: 68.57013052313991 LR: [0.00039721431845821814]\n",
      "Eval MSE: 68.64232277314485\n",
      "Eval Best MSE: 68.64232277314485\n",
      "Epoch:[19/80]\n",
      "Train MSE: 68.5660921181264 Mean loss: 68.5649795193644 LR: [0.0003773536025353072]\n",
      "Eval MSE: 68.64206128220977\n",
      "Eval Best MSE: 68.64206128220977\n",
      "Epoch:[20/80]\n",
      "Train MSE: 68.56584818673859 Mean loss: 68.56233126171948 LR: [0.0003584859224085418]\n",
      "Eval MSE: 68.64195401060815\n",
      "Eval Best MSE: 68.64195401060815\n",
      "Epoch:[21/80]\n",
      "Train MSE: 65.97288776529581 Mean loss: 65.96907835176005 LR: [0.0003405616262881147]\n",
      "Eval MSE: 61.31664109309426\n",
      "Eval Best MSE: 61.31664109309426\n",
      "Epoch:[22/80]\n",
      "Train MSE: 61.258766428982405 Mean loss: 61.25794364432611 LR: [0.00032353354497370894]\n",
      "Eval MSE: 61.313959128054876\n",
      "Eval Best MSE: 61.313959128054876\n",
      "Epoch:[23/80]\n",
      "Train MSE: 61.25692039478279 Mean loss: 61.25646508233787 LR: [0.00030735686772502346]\n",
      "Eval MSE: 61.312128643525604\n",
      "Eval Best MSE: 61.312128643525604\n",
      "Epoch:[24/80]\n",
      "Train MSE: 61.25483502667961 Mean loss: 61.25485167983015 LR: [0.00029198902433877225]\n",
      "Eval MSE: 61.31084489840029\n",
      "Eval Best MSE: 61.31084489840029\n",
      "Epoch:[25/80]\n",
      "Train MSE: 61.25405895062465 Mean loss: 61.25312967695428 LR: [0.00027738957312183364]\n",
      "Eval MSE: 61.31046534801826\n",
      "Eval Best MSE: 61.31046534801826\n",
      "Epoch:[26/80]\n",
      "Train MSE: 61.25390424116428 Mean loss: 61.25471591949463 LR: [0.0002635200944657419]\n",
      "Eval MSE: 61.31021847514986\n",
      "Eval Best MSE: 61.31021847514986\n",
      "Epoch:[27/80]\n",
      "Train MSE: 61.253800650411485 Mean loss: 61.25364088024613 LR: [0.0002503440897424548]\n",
      "Eval MSE: 61.3099893251702\n",
      "Eval Best MSE: 61.3099893251702\n",
      "Epoch:[28/80]\n",
      "Train MSE: 61.25371213091055 Mean loss: 61.25437851629314 LR: [0.00023782688525533205]\n",
      "Eval MSE: 61.30956537583295\n",
      "Eval Best MSE: 61.30956537583295\n",
      "Epoch:[29/80]\n",
      "Train MSE: 61.25349661123271 Mean loss: 61.25411225493843 LR: [0.00022593554099256544]\n",
      "Eval MSE: 61.309648726192\n",
      "Eval Best MSE: 61.30956537583295\n",
      "Epoch:[30/80]\n",
      "Train MSE: 61.25339547778185 Mean loss: 61.25417905728492 LR: [0.00021463876394293716]\n",
      "Eval MSE: 61.30955300452839\n",
      "Eval Best MSE: 61.30955300452839\n",
      "Epoch:[31/80]\n",
      "Train MSE: 61.25338641116076 Mean loss: 61.25114297584669 LR: [0.0002039068257457903]\n",
      "Eval MSE: 61.30974070513376\n",
      "Eval Best MSE: 61.30955300452839\n",
      "Epoch:[32/80]\n",
      "Train MSE: 61.253323833718305 Mean loss: 61.25608844305636 LR: [0.00019371148445850077]\n",
      "Eval MSE: 61.3093692555147\n",
      "Eval Best MSE: 61.3093692555147\n",
      "Epoch:[33/80]\n",
      "Train MSE: 61.25307903150862 Mean loss: 61.255276679992676 LR: [0.00018402591023557573]\n",
      "Eval MSE: 61.30856718401357\n",
      "Eval Best MSE: 61.30856718401357\n",
      "Epoch:[34/80]\n",
      "Train MSE: 61.25167980752028 Mean loss: 61.2518077094174 LR: [0.00017482461472379692]\n",
      "Eval MSE: 61.30782271542904\n",
      "Eval Best MSE: 61.30782271542904\n",
      "Epoch:[35/80]\n",
      "Train MSE: 61.25138371670807 Mean loss: 61.25218029699382 LR: [0.00016608338398760707]\n",
      "Eval MSE: 61.30752304929563\n",
      "Eval Best MSE: 61.30752304929563\n",
      "Epoch:[36/80]\n",
      "Train MSE: 61.251013971496995 Mean loss: 61.24865340057915 LR: [0.0001577792147882267]\n",
      "Eval MSE: 61.30689199986036\n",
      "Eval Best MSE: 61.30689199986036\n",
      "Epoch:[37/80]\n",
      "Train MSE: 61.242926512758004 Mean loss: 61.24183436399381 LR: [0.00014989025404881537]\n",
      "Eval MSE: 61.29231414061055\n",
      "Eval Best MSE: 61.29231414061055\n",
      "Epoch:[38/80]\n",
      "Train MSE: 61.23534164569849 Mean loss: 61.23507871007073 LR: [0.00014239574134637458]\n",
      "Eval MSE: 61.29160350329603\n",
      "Eval Best MSE: 61.29160350329603\n",
      "Epoch:[39/80]\n",
      "Train MSE: 61.23259178397145 Mean loss: 61.23349916582277 LR: [0.00013527595427905584]\n",
      "Eval MSE: 61.28686535292275\n",
      "Eval Best MSE: 61.28686535292275\n",
      "Epoch:[40/80]\n",
      "Train MSE: 61.23012657117011 Mean loss: 61.23109218777989 LR: [0.00012851215656510304]\n",
      "Eval MSE: 61.28565591465664\n",
      "Eval Best MSE: 61.28565591465664\n",
      "Epoch:[41/80]\n",
      "Train MSE: 61.229332237406844 Mean loss: 61.22946273645706 LR: [0.00012208654873684788]\n",
      "Eval MSE: 61.285411886934256\n",
      "Eval Best MSE: 61.285411886934256\n",
      "Epoch:[42/80]\n",
      "Train MSE: 61.228803423774465 Mean loss: 61.22990556863638 LR: [0.00011598222130000548]\n",
      "Eval MSE: 61.28451042725693\n",
      "Eval Best MSE: 61.28451042725693\n",
      "Epoch:[43/80]\n",
      "Train MSE: 61.227289288172706 Mean loss: 61.22864950620211 LR: [0.00011018311023500519]\n",
      "Eval MSE: 61.28352699180996\n",
      "Eval Best MSE: 61.28352699180996\n",
      "Epoch:[44/80]\n",
      "Train MSE: 61.2266343866446 Mean loss: 61.22704494070019 LR: [0.00010467395472325493]\n",
      "Eval MSE: 61.28268524350566\n",
      "Eval Best MSE: 61.28268524350566\n",
      "Epoch:[45/80]\n",
      "Train MSE: 61.22623780967597 Mean loss: 61.225415703813 LR: [9.944025698709218e-05]\n",
      "Eval MSE: 61.28252842458936\n",
      "Eval Best MSE: 61.28252842458936\n",
      "Epoch:[46/80]\n",
      "Train MSE: 61.22581563008591 Mean loss: 61.22450205560266 LR: [9.446824413773756e-05]\n",
      "Eval MSE: 61.282142046421406\n",
      "Eval Best MSE: 61.282142046421406\n",
      "Epoch:[47/80]\n",
      "Train MSE: 61.225426692126845 Mean loss: 61.22553731703899 LR: [8.974483193085068e-05]\n",
      "Eval MSE: 61.28165430710398\n",
      "Eval Best MSE: 61.28165430710398\n",
      "Epoch:[48/80]\n",
      "Train MSE: 61.22495423166004 Mean loss: 61.22295215426112 LR: [8.525759033430814e-05]\n",
      "Eval MSE: 61.28079340487024\n",
      "Eval Best MSE: 61.28079340487024\n",
      "Epoch:[49/80]\n",
      "Train MSE: 61.22394832382176 Mean loss: 61.22370984004094 LR: [8.099471081759274e-05]\n",
      "Eval MSE: 61.27741932136855\n",
      "Eval Best MSE: 61.27741932136855\n",
      "Epoch:[50/80]\n",
      "Train MSE: 61.21288221599408 Mean loss: 61.211136123837804 LR: [7.69449752767131e-05]\n",
      "Eval MSE: 61.24443021457459\n",
      "Eval Best MSE: 61.24443021457459\n",
      "Epoch:[51/80]\n",
      "Train MSE: 61.17501870732126 Mean loss: 61.17429663866935 LR: [7.309772651287744e-05]\n",
      "Eval MSE: 61.223880633750404\n",
      "Eval Best MSE: 61.223880633750404\n",
      "Epoch:[52/80]\n",
      "Train MSE: 61.16669685530489 Mean loss: 61.16627168373243 LR: [6.944284018723356e-05]\n",
      "Eval MSE: 61.22041518380366\n",
      "Eval Best MSE: 61.22041518380366\n",
      "Epoch:[53/80]\n",
      "Train MSE: 61.16454092610818 Mean loss: 61.1662845837294 LR: [6.597069817787189e-05]\n",
      "Eval MSE: 61.218639905832894\n",
      "Eval Best MSE: 61.218639905832894\n",
      "Epoch:[54/80]\n",
      "Train MSE: 61.16274918551692 Mean loss: 61.15898315158822 LR: [6.267216326897829e-05]\n",
      "Eval MSE: 61.21708013356019\n",
      "Eval Best MSE: 61.21708013356019\n",
      "Epoch:[55/80]\n",
      "Train MSE: 61.16175018038856 Mean loss: 61.16205768472344 LR: [5.953855510552937e-05]\n",
      "Eval MSE: 61.21646668564334\n",
      "Eval Best MSE: 61.21646668564334\n",
      "Epoch:[56/80]\n",
      "Train MSE: 61.161195097522025 Mean loss: 61.15894710947071 LR: [5.65616273502529e-05]\n",
      "Eval MSE: 61.21603588593963\n",
      "Eval Best MSE: 61.21603588593963\n",
      "Epoch:[57/80]\n",
      "Train MSE: 61.160833722592116 Mean loss: 61.16000256735898 LR: [5.373354598274025e-05]\n",
      "Eval MSE: 61.21569990185601\n",
      "Eval Best MSE: 61.21569990185601\n",
      "Epoch:[58/80]\n",
      "Train MSE: 61.16055733580054 Mean loss: 61.155250165589464 LR: [5.104686868360323e-05]\n",
      "Eval MSE: 61.21538188340176\n",
      "Eval Best MSE: 61.21538188340176\n",
      "Epoch:[59/80]\n",
      "Train MSE: 61.160335252144144 Mean loss: 61.16056463140002 LR: [4.849452524942307e-05]\n",
      "Eval MSE: 61.21528529803311\n",
      "Eval Best MSE: 61.21528529803311\n",
      "Epoch:[60/80]\n",
      "Train MSE: 61.1601429870796 Mean loss: 61.16257282685952 LR: [4.606979898695191e-05]\n",
      "Eval MSE: 61.215127530734804\n",
      "Eval Best MSE: 61.215127530734804\n",
      "Epoch:[61/80]\n",
      "Train MSE: 61.16001077714387 Mean loss: 61.15984994561009 LR: [4.376630903760431e-05]\n",
      "Eval MSE: 61.214969292068055\n",
      "Eval Best MSE: 61.214969292068055\n",
      "Epoch:[62/80]\n",
      "Train MSE: 61.159845975958994 Mean loss: 61.15940946093678 LR: [4.157799358572409e-05]\n",
      "Eval MSE: 61.21477762011303\n",
      "Eval Best MSE: 61.21477762011303\n",
      "Epoch:[63/80]\n",
      "Train MSE: 61.15971769962935 Mean loss: 61.16111853560047 LR: [3.9499093906437885e-05]\n",
      "Eval MSE: 61.214677650488355\n",
      "Eval Best MSE: 61.214677650488355\n",
      "Epoch:[64/80]\n",
      "Train MSE: 61.15957990794778 Mean loss: 61.158541250511036 LR: [3.752413921111599e-05]\n",
      "Eval MSE: 61.21454701933471\n",
      "Eval Best MSE: 61.21454701933471\n",
      "Epoch:[65/80]\n",
      "Train MSE: 61.15946509010296 Mean loss: 61.15830888691738 LR: [3.564793225056019e-05]\n",
      "Eval MSE: 61.214438565078154\n",
      "Eval Best MSE: 61.214438565078154\n",
      "Epoch:[66/80]\n",
      "Train MSE: 61.15930895947048 Mean loss: 61.159089878466006 LR: [3.3865535638032174e-05]\n",
      "Eval MSE: 61.21425569952747\n",
      "Eval Best MSE: 61.21425569952747\n",
      "Epoch:[67/80]\n",
      "Train MSE: 61.159159189489536 Mean loss: 61.16041866279918 LR: [3.2172258856130564e-05]\n",
      "Eval MSE: 61.21413898926684\n",
      "Eval Best MSE: 61.21413898926684\n",
      "Epoch:[68/80]\n",
      "Train MSE: 61.15898851907823 Mean loss: 61.15914950850447 LR: [3.056364591332403e-05]\n",
      "Eval MSE: 61.21390794252317\n",
      "Eval Best MSE: 61.21390794252317\n",
      "Epoch:[69/80]\n",
      "Train MSE: 61.15880960840919 Mean loss: 61.159569745938455 LR: [2.903546361765783e-05]\n",
      "Eval MSE: 61.21381334988576\n",
      "Eval Best MSE: 61.21381334988576\n",
      "Epoch:[70/80]\n",
      "Train MSE: 61.15863720464602 Mean loss: 61.15606249295748 LR: [2.758369043677494e-05]\n",
      "Eval MSE: 61.213551243631386\n",
      "Eval Best MSE: 61.213551243631386\n",
      "Epoch:[71/80]\n",
      "Train MSE: 61.15844247698687 Mean loss: 61.156883414680436 LR: [2.620450591493619e-05]\n",
      "Eval MSE: 61.21342245561301\n",
      "Eval Best MSE: 61.21342245561301\n",
      "Epoch:[72/80]\n",
      "Train MSE: 61.15828149808544 Mean loss: 61.160196558258235 LR: [2.489428061918938e-05]\n",
      "Eval MSE: 61.21322894616785\n",
      "Eval Best MSE: 61.21322894616785\n",
      "Epoch:[73/80]\n",
      "Train MSE: 61.15811737171693 Mean loss: 61.157493343014686 LR: [2.364956658822991e-05]\n",
      "Eval MSE: 61.21303971573198\n",
      "Eval Best MSE: 61.21303971573198\n",
      "Epoch:[74/80]\n",
      "Train MSE: 61.15796717752789 Mean loss: 61.15794388923419 LR: [2.2467088258818413e-05]\n",
      "Eval MSE: 61.21290253340382\n",
      "Eval Best MSE: 61.21290253340382\n",
      "Epoch:[75/80]\n",
      "Train MSE: 61.157843282123785 Mean loss: 61.15871693537785 LR: [2.134373384587749e-05]\n",
      "Eval MSE: 61.21277912801784\n",
      "Eval Best MSE: 61.21277912801784\n",
      "Epoch:[76/80]\n",
      "Train MSE: 61.15771876632967 Mean loss: 61.158273409104204 LR: [2.0276547153583614e-05]\n",
      "Eval MSE: 61.21271128483362\n",
      "Eval Best MSE: 61.21271128483362\n",
      "Epoch:[77/80]\n",
      "Train MSE: 61.1576251424824 Mean loss: 61.15886825358374 LR: [1.9262719795904432e-05]\n",
      "Eval MSE: 61.212665262903236\n",
      "Eval Best MSE: 61.212665262903236\n",
      "Epoch:[78/80]\n",
      "Train MSE: 61.15752498985288 Mean loss: 61.15705384587395 LR: [1.829958380610921e-05]\n",
      "Eval MSE: 61.21251847256213\n",
      "Eval Best MSE: 61.21251847256213\n",
      "Epoch:[79/80]\n",
      "Train MSE: 61.157435966489054 Mean loss: 61.15738641863039 LR: [1.738460461580375e-05]\n",
      "Eval MSE: 61.21238908333731\n",
      "Eval Best MSE: 61.21238908333731\n",
      "Epoch:[80/80]\n",
      "Train MSE: 61.15735305272743 Mean loss: 61.15860830679448 LR: [1.6515374385013564e-05]\n",
      "Eval MSE: 61.21231613130954\n",
      "Eval Best MSE: 61.21231613130954\n",
      "Best Train MSE: 61.15735305272743\n"
     ]
    }
   ],
   "source": [
    "!python us_main.py --config config/us_train_snr.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_device(device无监督判断)\n",
    "\n",
    "best mse：41.98"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters:\n",
      "{'work_dir': './work_dir/us_device', 'config': 'config/us_train_device.yaml', 'phase': 'train', 'save_score': False, 'seed': 1, 'feeder': 'feeder.Us_Feeder_device', 'num_worker': 8, 'train_feeder_args': {'data_path': './data/train.pkl', 'snr': 0}, 'test_feeder_args': {'data_path': './data/test.pkl', 'snr': 0}, 'model': 'net.Us_CNN', 'model_args': {'channels': 13, 'num_classes': 4}, 'weights': None, 'ignore_weights': [], 'base_lr': 0.001, 'step': [10, 50], 'device': 0, 'optimizer': 'Adam', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 80, 'weight_decay': 1e-05}\n",
      "\n",
      "Epoch:[1/80]\n",
      "Train MSE: 56.82647409905504 Mean loss: 56.82267018546045 LR: [0.00095]\n",
      "Eval MSE: 55.95330209340425\n",
      "Eval Best MSE: 55.95330209340425\n",
      "Epoch:[2/80]\n",
      "Train MSE: 43.14583781305552 Mean loss: 43.13709073362097 LR: [0.0009025]\n",
      "Eval MSE: 41.98624329561663\n",
      "Eval Best MSE: 41.98624329561663\n",
      "Epoch:[3/80]\n",
      "Train MSE: 42.13728693003792 Mean loss: 42.13535291958699 LR: [0.000857375]\n",
      "Eval MSE: 41.97163027425717\n",
      "Eval Best MSE: 41.97163027425717\n",
      "Epoch:[4/80]\n",
      "Train MSE: 42.12949336035732 Mean loss: 42.127750987500214 LR: [0.0008145062499999999]\n",
      "Eval MSE: 41.96901567821101\n",
      "Eval Best MSE: 41.96901567821101\n",
      "Epoch:[5/80]\n",
      "Train MSE: 42.12190032413839 Mean loss: 42.12503720173794 LR: [0.0007737809374999998]\n",
      "Eval MSE: 41.94208839492713\n",
      "Eval Best MSE: 41.94208839492713\n",
      "Epoch:[6/80]\n",
      "Train MSE: 42.0629052473446 Mean loss: 42.06308408754062 LR: [0.0007350918906249997]\n",
      "Eval MSE: 41.886628899272615\n",
      "Eval Best MSE: 41.886628899272615\n",
      "Epoch:[7/80]\n",
      "Train MSE: 42.03762058995062 Mean loss: 42.0355035224847 LR: [0.0006983372960937497]\n",
      "Eval MSE: 41.86972084426456\n",
      "Eval Best MSE: 41.86972084426456\n",
      "Epoch:[8/80]\n",
      "Train MSE: 42.02059225875637 Mean loss: 42.027716003688035 LR: [0.0006634204312890621]\n",
      "Eval MSE: 41.85703775065059\n",
      "Eval Best MSE: 41.85703775065059\n",
      "Epoch:[9/80]\n",
      "Train MSE: 42.01423272362113 Mean loss: 42.022633003977546 LR: [0.000630249409724609]\n",
      "Eval MSE: 41.856622668402835\n",
      "Eval Best MSE: 41.856622668402835\n",
      "Epoch:[10/80]\n",
      "Train MSE: 42.013583291722306 Mean loss: 42.008927168044366 LR: [0.0005987369392383785]\n",
      "Eval MSE: 41.855462221406015\n",
      "Eval Best MSE: 41.855462221406015\n",
      "Epoch:[11/80]\n",
      "Train MSE: 42.013183422267254 Mean loss: 42.006062364156264 LR: [0.0005688000922764595]\n",
      "Eval MSE: 41.85545124303752\n",
      "Eval Best MSE: 41.85545124303752\n",
      "Epoch:[12/80]\n",
      "Train MSE: 42.012997115787186 Mean loss: 42.02751166419645 LR: [0.0005403600876626365]\n",
      "Eval MSE: 41.85586823898468\n",
      "Eval Best MSE: 41.85545124303752\n",
      "Epoch:[13/80]\n",
      "Train MSE: 42.01242515254343 Mean loss: 42.00667685112067 LR: [0.0005133420832795047]\n",
      "Eval MSE: 41.85400272500634\n",
      "Eval Best MSE: 41.85400272500634\n",
      "Epoch:[14/80]\n",
      "Train MSE: 42.01099727655755 Mean loss: 42.0109604860829 LR: [0.00048767497911552944]\n",
      "Eval MSE: 41.85205534110455\n",
      "Eval Best MSE: 41.85205534110455\n",
      "Epoch:[15/80]\n",
      "Train MSE: 42.0070106524872 Mean loss: 42.014946439624886 LR: [0.00046329123015975297]\n",
      "Eval MSE: 41.847758908118315\n",
      "Eval Best MSE: 41.847758908118315\n",
      "Epoch:[16/80]\n",
      "Train MSE: 42.00333209373535 Mean loss: 42.012625989660755 LR: [0.0004401266686517653]\n",
      "Eval MSE: 41.8444814565576\n",
      "Eval Best MSE: 41.8444814565576\n",
      "Epoch:[17/80]\n",
      "Train MSE: 42.000995174464855 Mean loss: 41.99508837472021 LR: [0.00041812033521917703]\n",
      "Eval MSE: 41.842024317327535\n",
      "Eval Best MSE: 41.842024317327535\n",
      "Epoch:[18/80]\n",
      "Train MSE: 41.99917571285802 Mean loss: 41.988816286610295 LR: [0.00039721431845821814]\n",
      "Eval MSE: 41.840539303524515\n",
      "Eval Best MSE: 41.840539303524515\n",
      "Epoch:[19/80]\n",
      "Train MSE: 41.99784696766208 Mean loss: 42.00578930947633 LR: [0.0003773536025353072]\n",
      "Eval MSE: 41.839908883521346\n",
      "Eval Best MSE: 41.839908883521346\n",
      "Epoch:[20/80]\n",
      "Train MSE: 41.99755504421587 Mean loss: 41.99127489275637 LR: [0.0003584859224085418]\n",
      "Eval MSE: 41.83955228341936\n",
      "Eval Best MSE: 41.83955228341936\n",
      "Epoch:[21/80]\n",
      "Train MSE: 41.99716482595814 Mean loss: 42.00176767332364 LR: [0.0003405616262881147]\n",
      "Eval MSE: 41.8395853921126\n",
      "Eval Best MSE: 41.83955228341936\n",
      "Epoch:[22/80]\n",
      "Train MSE: 41.99719235343814 Mean loss: 42.00696884425341 LR: [0.00032353354497370894]\n",
      "Eval MSE: 41.83918492510898\n",
      "Eval Best MSE: 41.83918492510898\n",
      "Epoch:[23/80]\n",
      "Train MSE: 41.99693765683262 Mean loss: 41.99347636130004 LR: [0.00030735686772502346]\n",
      "Eval MSE: 41.839343516596415\n",
      "Eval Best MSE: 41.83918492510898\n",
      "Epoch:[24/80]\n",
      "Train MSE: 41.996911959295836 Mean loss: 42.00560038068653 LR: [0.00029198902433877225]\n",
      "Eval MSE: 41.83960879682569\n",
      "Eval Best MSE: 41.83918492510898\n",
      "Epoch:[25/80]\n",
      "Train MSE: 41.99684905714762 Mean loss: 42.00048649205571 LR: [0.00027738957312183364]\n",
      "Eval MSE: 41.83950507601146\n",
      "Eval Best MSE: 41.83918492510898\n",
      "Epoch:[26/80]\n",
      "Train MSE: 41.996832341019825 Mean loss: 41.98944215014973 LR: [0.0002635200944657419]\n",
      "Eval MSE: 41.83916282442116\n",
      "Eval Best MSE: 41.83916282442116\n",
      "Epoch:[27/80]\n",
      "Train MSE: 41.996764797987396 Mean loss: 42.0054971137933 LR: [0.0002503440897424548]\n",
      "Eval MSE: 41.839660983239106\n",
      "Eval Best MSE: 41.83916282442116\n",
      "Epoch:[28/80]\n",
      "Train MSE: 41.996832459840434 Mean loss: 42.00433859360957 LR: [0.00023782688525533205]\n",
      "Eval MSE: 41.83932438807006\n",
      "Eval Best MSE: 41.83916282442116\n",
      "Epoch:[29/80]\n",
      "Train MSE: 41.996569671260374 Mean loss: 41.996914838267635 LR: [0.00022593554099256544]\n",
      "Eval MSE: 41.839055216934256\n",
      "Eval Best MSE: 41.839055216934256\n",
      "Epoch:[30/80]\n",
      "Train MSE: 41.996744234083096 Mean loss: 41.98464901679385 LR: [0.00021463876394293716]\n",
      "Eval MSE: 41.83903311624643\n",
      "Eval Best MSE: 41.83903311624643\n",
      "Epoch:[31/80]\n",
      "Train MSE: 41.996578626735236 Mean loss: 41.99979702772293 LR: [0.0002039068257457903]\n",
      "Eval MSE: 41.839057672566234\n",
      "Eval Best MSE: 41.83903311624643\n",
      "Epoch:[32/80]\n",
      "Train MSE: 41.99654435373783 Mean loss: 42.00045460726307 LR: [0.00019371148445850077]\n",
      "Eval MSE: 41.83896112812479\n",
      "Eval Best MSE: 41.83896112812479\n",
      "Epoch:[33/80]\n",
      "Train MSE: 41.99653387317797 Mean loss: 41.98109115330519 LR: [0.00018402591023557573]\n",
      "Eval MSE: 41.83906463301275\n",
      "Eval Best MSE: 41.83896112812479\n",
      "Epoch:[34/80]\n",
      "Train MSE: 41.99648232249969 Mean loss: 42.004991818318324 LR: [0.00017482461472379692]\n",
      "Eval MSE: 41.83937137108399\n",
      "Eval Best MSE: 41.83896112812479\n",
      "Epoch:[35/80]\n",
      "Train MSE: 41.996481420627454 Mean loss: 42.01135137439829 LR: [0.00016608338398760707]\n",
      "Eval MSE: 41.838901993966395\n",
      "Eval Best MSE: 41.838901993966395\n",
      "Epoch:[36/80]\n",
      "Train MSE: 41.99649208563713 Mean loss: 41.998054318723426 LR: [0.0001577792147882267]\n",
      "Eval MSE: 41.83927370890661\n",
      "Eval Best MSE: 41.838901993966395\n",
      "Epoch:[37/80]\n",
      "Train MSE: 41.996519961904575 Mean loss: 41.99133174187314 LR: [0.00014989025404881537]\n",
      "Eval MSE: 41.83930484039273\n",
      "Eval Best MSE: 41.838901993966395\n",
      "Epoch:[38/80]\n",
      "Train MSE: 41.99640275767972 Mean loss: 41.9971708956018 LR: [0.00014239574134637458]\n",
      "Eval MSE: 41.83872288101654\n",
      "Eval Best MSE: 41.83872288101654\n",
      "Epoch:[39/80]\n",
      "Train MSE: 41.99637240417459 Mean loss: 41.9954891204834 LR: [0.00013527595427905584]\n",
      "Eval MSE: 41.83956100091289\n",
      "Eval Best MSE: 41.83872288101654\n",
      "Epoch:[40/80]\n",
      "Train MSE: 41.996425365351406 Mean loss: 42.01845820604172 LR: [0.00012851215656510304]\n",
      "Eval MSE: 41.838800436648626\n",
      "Eval Best MSE: 41.83872288101654\n",
      "Epoch:[41/80]\n",
      "Train MSE: 41.996352781308346 Mean loss: 41.99429954258741 LR: [0.00012208654873684788]\n",
      "Eval MSE: 41.83868621165691\n",
      "Eval Best MSE: 41.83868621165691\n",
      "Epoch:[42/80]\n",
      "Train MSE: 41.99637009471479 Mean loss: 41.999422157760215 LR: [0.00011598222130000548]\n",
      "Eval MSE: 41.83894227479856\n",
      "Eval Best MSE: 41.83868621165691\n",
      "Epoch:[43/80]\n",
      "Train MSE: 41.9963129218899 Mean loss: 41.99608163074055 LR: [0.00011018311023500519]\n",
      "Eval MSE: 41.83891646949353\n",
      "Eval Best MSE: 41.83868621165691\n",
      "Epoch:[44/80]\n",
      "Train MSE: 41.99632658281965 Mean loss: 41.99069185172562 LR: [0.00010467395472325493]\n",
      "Eval MSE: 41.838910537872145\n",
      "Eval Best MSE: 41.83868621165691\n",
      "Epoch:[45/80]\n",
      "Train MSE: 41.99631517365952 Mean loss: 41.99995196182116 LR: [9.944025698709218e-05]\n",
      "Eval MSE: 41.83884542975389\n",
      "Eval Best MSE: 41.83868621165691\n",
      "Epoch:[46/80]\n",
      "Train MSE: 41.99635767968132 Mean loss: 42.00483256314708 LR: [9.446824413773756e-05]\n",
      "Eval MSE: 41.83884878296169\n",
      "Eval Best MSE: 41.83868621165691\n",
      "Epoch:[47/80]\n",
      "Train MSE: 41.99626844672746 Mean loss: 42.004556841554894 LR: [8.974483193085068e-05]\n",
      "Eval MSE: 41.83861403301209\n",
      "Eval Best MSE: 41.83861403301209\n",
      "Epoch:[48/80]\n",
      "Train MSE: 41.99628325934382 Mean loss: 42.01387783489396 LR: [8.525759033430814e-05]\n",
      "Eval MSE: 41.839040572053186\n",
      "Eval Best MSE: 41.83861403301209\n",
      "Epoch:[49/80]\n",
      "Train MSE: 41.99629908180303 Mean loss: 42.01441985948951 LR: [8.099471081759274e-05]\n",
      "Eval MSE: 41.83880677048559\n",
      "Eval Best MSE: 41.83861403301209\n",
      "Epoch:[50/80]\n",
      "Train MSE: 41.9962029355539 Mean loss: 41.98222616077524 LR: [7.69449752767131e-05]\n",
      "Eval MSE: 41.83875833526171\n",
      "Eval Best MSE: 41.83861403301209\n",
      "Epoch:[51/80]\n",
      "Train MSE: 41.99625651412154 Mean loss: 41.99650266529184 LR: [7.309772651287744e-05]\n",
      "Eval MSE: 41.838755291124826\n",
      "Eval Best MSE: 41.83861403301209\n",
      "Epoch:[52/80]\n",
      "Train MSE: 41.99622884559168 Mean loss: 41.99047640572607 LR: [6.944284018723356e-05]\n",
      "Eval MSE: 41.83869607228947\n",
      "Eval Best MSE: 41.83861403301209\n",
      "Epoch:[53/80]\n",
      "Train MSE: 41.99622322476824 Mean loss: 41.98811434855503 LR: [6.597069817787189e-05]\n",
      "Eval MSE: 41.838721035058704\n",
      "Eval Best MSE: 41.83861403301209\n",
      "Epoch:[54/80]\n",
      "Train MSE: 41.99620923489859 Mean loss: 41.994206960222364 LR: [6.267216326897829e-05]\n",
      "Eval MSE: 41.83867893367179\n",
      "Eval Best MSE: 41.83861403301209\n",
      "Epoch:[55/80]\n",
      "Train MSE: 41.99618328013769 Mean loss: 42.01406573405308 LR: [5.953855510552937e-05]\n",
      "Eval MSE: 41.838639436101545\n",
      "Eval Best MSE: 41.83861403301209\n",
      "Epoch:[56/80]\n",
      "Train MSE: 41.99544443215838 Mean loss: 41.986491599969106 LR: [5.65616273502529e-05]\n",
      "Eval MSE: 41.83682015997985\n",
      "Eval Best MSE: 41.83682015997985\n",
      "Epoch:[57/80]\n",
      "Train MSE: 41.993039323619534 Mean loss: 42.00227663158316 LR: [5.373354598274025e-05]\n",
      "Eval MSE: 41.834618292161814\n",
      "Eval Best MSE: 41.834618292161814\n",
      "Epoch:[58/80]\n",
      "Train MSE: 41.99177356895952 Mean loss: 41.99490739602958 LR: [5.104686868360323e-05]\n",
      "Eval MSE: 41.834212668331034\n",
      "Eval Best MSE: 41.834212668331034\n",
      "Epoch:[59/80]\n",
      "Train MSE: 41.99150202655561 Mean loss: 41.989256124580855 LR: [4.849452524942307e-05]\n",
      "Eval MSE: 41.83408887907615\n",
      "Eval Best MSE: 41.83408887907615\n",
      "Epoch:[60/80]\n",
      "Train MSE: 41.99137499515191 Mean loss: 41.98401169228343 LR: [4.606979898695191e-05]\n",
      "Eval MSE: 41.833912742521605\n",
      "Eval Best MSE: 41.833912742521605\n",
      "Epoch:[61/80]\n",
      "Train MSE: 41.99130615144399 Mean loss: 41.98647191883188 LR: [4.376630903760431e-05]\n",
      "Eval MSE: 41.83392753558736\n",
      "Eval Best MSE: 41.833912742521605\n",
      "Epoch:[62/80]\n",
      "Train MSE: 41.99125657466977 Mean loss: 41.99953707129554 LR: [4.157799358572409e-05]\n",
      "Eval MSE: 41.834130154862656\n",
      "Eval Best MSE: 41.833912742521605\n",
      "Epoch:[63/80]\n",
      "Train MSE: 41.99125052143458 Mean loss: 41.992583485831204 LR: [3.9499093906437885e-05]\n",
      "Eval MSE: 41.83381385676207\n",
      "Eval Best MSE: 41.83381385676207\n",
      "Epoch:[64/80]\n",
      "Train MSE: 41.9911558552827 Mean loss: 41.99532164514592 LR: [3.752413921111599e-05]\n",
      "Eval MSE: 41.833768050757946\n",
      "Eval Best MSE: 41.833768050757946\n",
      "Epoch:[65/80]\n",
      "Train MSE: 41.991137900668384 Mean loss: 41.97491196826496 LR: [3.564793225056019e-05]\n",
      "Eval MSE: 41.83361815136095\n",
      "Eval Best MSE: 41.83361815136095\n",
      "Epoch:[66/80]\n",
      "Train MSE: 41.99108843186478 Mean loss: 41.98729292270357 LR: [3.3865535638032174e-05]\n",
      "Eval MSE: 41.83354804306792\n",
      "Eval Best MSE: 41.83354804306792\n",
      "Epoch:[67/80]\n",
      "Train MSE: 41.991059269476715 Mean loss: 41.99686097676775 LR: [3.2172258856130564e-05]\n",
      "Eval MSE: 41.833643478241136\n",
      "Eval Best MSE: 41.83354804306792\n",
      "Epoch:[68/80]\n",
      "Train MSE: 41.99103093962681 Mean loss: 41.99220932479453 LR: [3.056364591332403e-05]\n",
      "Eval MSE: 41.83370636782291\n",
      "Eval Best MSE: 41.83354804306792\n",
      "Epoch:[69/80]\n",
      "Train MSE: 41.99101989433826 Mean loss: 41.998108349015226 LR: [2.903546361765783e-05]\n",
      "Eval MSE: 41.83361553907659\n",
      "Eval Best MSE: 41.83354804306792\n",
      "Epoch:[70/80]\n",
      "Train MSE: 41.990992467948395 Mean loss: 41.98425314911699 LR: [2.758369043677494e-05]\n",
      "Eval MSE: 41.833508363442206\n",
      "Eval Best MSE: 41.833508363442206\n",
      "Epoch:[71/80]\n",
      "Train MSE: 41.99099914254391 Mean loss: 41.987085443682375 LR: [2.620450591493619e-05]\n",
      "Eval MSE: 41.83348495026143\n",
      "Eval Best MSE: 41.83348495026143\n",
      "Epoch:[72/80]\n",
      "Train MSE: 41.9909878185959 Mean loss: 41.99437178552678 LR: [2.489428061918938e-05]\n",
      "Eval MSE: 41.83355314485505\n",
      "Eval Best MSE: 41.83348495026143\n",
      "Epoch:[73/80]\n",
      "Train MSE: 41.990957995152414 Mean loss: 41.98238838668418 LR: [2.364956658822991e-05]\n",
      "Eval MSE: 41.83349493367558\n",
      "Eval Best MSE: 41.83348495026143\n",
      "Epoch:[74/80]\n",
      "Train MSE: 41.99095202051349 Mean loss: 42.01263539137039 LR: [2.2467088258818413e-05]\n",
      "Eval MSE: 41.83354315720705\n",
      "Eval Best MSE: 41.83348495026143\n",
      "Epoch:[75/80]\n",
      "Train MSE: 41.99094107922605 Mean loss: 41.991746716794715 LR: [2.134373384587749e-05]\n",
      "Eval MSE: 41.833524909321135\n",
      "Eval Best MSE: 41.83348495026143\n",
      "Epoch:[76/80]\n",
      "Train MSE: 41.99092485187701 Mean loss: 41.98256246178551 LR: [2.0276547153583614e-05]\n",
      "Eval MSE: 41.833438195875296\n",
      "Eval Best MSE: 41.833438195875296\n",
      "Epoch:[77/80]\n",
      "Train MSE: 41.9909045901846 Mean loss: 41.99430300282166 LR: [1.9262719795904432e-05]\n",
      "Eval MSE: 41.83347304891402\n",
      "Eval Best MSE: 41.833438195875296\n",
      "Epoch:[78/80]\n",
      "Train MSE: 41.99089616715308 Mean loss: 41.98997441857262 LR: [1.829958380610921e-05]\n",
      "Eval MSE: 41.83346400541418\n",
      "Eval Best MSE: 41.833438195875296\n",
      "Epoch:[79/80]\n",
      "Train MSE: 41.99087321678053 Mean loss: 42.00440918238817 LR: [1.738460461580375e-05]\n",
      "Eval MSE: 41.833405290406766\n",
      "Eval Best MSE: 41.833405290406766\n",
      "Epoch:[80/80]\n",
      "Train MSE: 41.99086152975484 Mean loss: 41.97998443535999 LR: [1.6515374385013564e-05]\n",
      "Eval MSE: 41.833374874441\n",
      "Eval Best MSE: 41.833374874441\n",
      "Best Train MSE: 41.99086152975484\n"
     ]
    }
   ],
   "source": [
    "!python us_main.py --config config/us_train_device.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_label(label无监督判断)\n",
    "\n",
    "best mse：41.98"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters:\n",
      "{'work_dir': './work_dir/us_label', 'config': 'config/us_train_label.yaml', 'phase': 'train', 'save_score': False, 'seed': 1, 'feeder': 'feeder.Us_Feeder_label', 'num_worker': 8, 'train_feeder_args': {'data_path': './data/train.pkl', 'snr': 0}, 'test_feeder_args': {'data_path': './data/test.pkl', 'snr': 0}, 'model': 'net.Us_CNN', 'model_args': {'channels': 13, 'num_classes': 2}, 'weights': None, 'ignore_weights': [], 'base_lr': 0.001, 'step': [10, 50], 'device': 0, 'optimizer': 'Adam', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 80, 'weight_decay': 1e-05}\n",
      "\n",
      "Epoch:[1/80]\n",
      "Train MSE: 56.876233312929 Mean loss: 56.86500397403683 LR: [0.00095]\n",
      "Eval MSE: 56.22747540235784\n",
      "Eval Best MSE: 56.22747540235784\n",
      "Epoch:[2/80]\n",
      "Train MSE: 46.32478200255522 Mean loss: 46.32625221995126 LR: [0.0009025]\n",
      "Eval MSE: 45.77943486458189\n",
      "Eval Best MSE: 45.77943486458189\n",
      "Epoch:[3/80]\n",
      "Train MSE: 45.91111226976641 Mean loss: 45.917716304812814 LR: [0.000857375]\n",
      "Eval MSE: 45.75107919098137\n",
      "Eval Best MSE: 45.75107919098137\n",
      "Epoch:[4/80]\n",
      "Train MSE: 45.90170870280456 Mean loss: 45.90276010901527 LR: [0.0008145062499999999]\n",
      "Eval MSE: 45.74869180440109\n",
      "Eval Best MSE: 45.74869180440109\n",
      "Epoch:[5/80]\n",
      "Train MSE: 45.899917288418656 Mean loss: 45.90349217642725 LR: [0.0007737809374999998]\n",
      "Eval MSE: 45.746963128397915\n",
      "Eval Best MSE: 45.746963128397915\n",
      "Epoch:[6/80]\n",
      "Train MSE: 45.899230791105815 Mean loss: 45.90599262608891 LR: [0.0007350918906249997]\n",
      "Eval MSE: 45.746645699859855\n",
      "Eval Best MSE: 45.746645699859855\n",
      "Epoch:[7/80]\n",
      "Train MSE: 45.89894763418589 Mean loss: 45.90295577260245 LR: [0.0006983372960937497]\n",
      "Eval MSE: 45.74591897674459\n",
      "Eval Best MSE: 45.74591897674459\n",
      "Epoch:[8/80]\n",
      "Train MSE: 45.89861693684938 Mean loss: 45.90442831326375 LR: [0.0006634204312890621]\n",
      "Eval MSE: 45.74662240946068\n",
      "Eval Best MSE: 45.74591897674459\n",
      "Epoch:[9/80]\n",
      "Train MSE: 45.89819316275203 Mean loss: 45.8914850116831 LR: [0.000630249409724609]\n",
      "Eval MSE: 45.7454681100115\n",
      "Eval Best MSE: 45.7454681100115\n",
      "Epoch:[10/80]\n",
      "Train MSE: 45.897445030622585 Mean loss: 45.89816336505181 LR: [0.0005987369392383785]\n",
      "Eval MSE: 45.745165703167\n",
      "Eval Best MSE: 45.745165703167\n",
      "Epoch:[11/80]\n",
      "Train MSE: 45.89728063688566 Mean loss: 45.89409110820399 LR: [0.0005688000922764595]\n",
      "Eval MSE: 45.74507536131322\n",
      "Eval Best MSE: 45.74507536131322\n",
      "Epoch:[12/80]\n",
      "Train MSE: 45.8970520861067 Mean loss: 45.89192859683416 LR: [0.0005403600876626365]\n",
      "Eval MSE: 45.74555064464912\n",
      "Eval Best MSE: 45.74507536131322\n",
      "Epoch:[13/80]\n",
      "Train MSE: 45.89615258790121 Mean loss: 45.889013307284465 LR: [0.0005133420832795047]\n",
      "Eval MSE: 45.74218740262149\n",
      "Eval Best MSE: 45.74218740262149\n",
      "Epoch:[14/80]\n",
      "Train MSE: 45.88972000296729 Mean loss: 45.89942678941035 LR: [0.00048767497911552944]\n",
      "Eval MSE: 45.73281724021649\n",
      "Eval Best MSE: 45.73281724021649\n",
      "Epoch:[15/80]\n",
      "Train MSE: 45.883551194491666 Mean loss: 45.90030938545159 LR: [0.00046329123015975297]\n",
      "Eval MSE: 45.73028928140689\n",
      "Eval Best MSE: 45.73028928140689\n",
      "Epoch:[16/80]\n",
      "Train MSE: 45.88095552124913 Mean loss: 45.88123777271372 LR: [0.0004401266686517653]\n",
      "Eval MSE: 45.72777394793275\n",
      "Eval Best MSE: 45.72777394793275\n",
      "Epoch:[17/80]\n",
      "Train MSE: 45.878572414105776 Mean loss: 45.88425575526415 LR: [0.00041812033521917703]\n",
      "Eval MSE: 45.725940602733345\n",
      "Eval Best MSE: 45.725940602733345\n",
      "Epoch:[18/80]\n",
      "Train MSE: 45.87791683105723 Mean loss: 45.86702058167584 LR: [0.00039721431845821814]\n",
      "Eval MSE: 45.72548773339004\n",
      "Eval Best MSE: 45.72548773339004\n",
      "Epoch:[19/80]\n",
      "Train MSE: 45.87756819445517 Mean loss: 45.8734132884878 LR: [0.0003773536025353072]\n",
      "Eval MSE: 45.72563026589109\n",
      "Eval Best MSE: 45.72548773339004\n",
      "Epoch:[20/80]\n",
      "Train MSE: 45.877299317972884 Mean loss: 45.886965422503714 LR: [0.0003584859224085418]\n",
      "Eval MSE: 45.72497506094032\n",
      "Eval Best MSE: 45.72497506094032\n",
      "Epoch:[21/80]\n",
      "Train MSE: 45.877206854897985 Mean loss: 45.87748043094061 LR: [0.0003405616262881147]\n",
      "Eval MSE: 45.72515067673153\n",
      "Eval Best MSE: 45.72497506094032\n",
      "Epoch:[22/80]\n",
      "Train MSE: 45.87693213000713 Mean loss: 45.88571631169952 LR: [0.00032353354497370894]\n",
      "Eval MSE: 45.724979819785744\n",
      "Eval Best MSE: 45.72497506094032\n",
      "Epoch:[23/80]\n",
      "Train MSE: 45.87682003004039 Mean loss: 45.88390065083462 LR: [0.00030735686772502346]\n",
      "Eval MSE: 45.72448119947833\n",
      "Eval Best MSE: 45.72448119947833\n",
      "Epoch:[24/80]\n",
      "Train MSE: 45.87668994820205 Mean loss: 45.884149838337855 LR: [0.00029198902433877225]\n",
      "Eval MSE: 45.7243008333094\n",
      "Eval Best MSE: 45.7243008333094\n",
      "Epoch:[25/80]\n",
      "Train MSE: 45.87651919690098 Mean loss: 45.875492838631686 LR: [0.00027738957312183364]\n",
      "Eval MSE: 45.72588584214019\n",
      "Eval Best MSE: 45.7243008333094\n",
      "Epoch:[26/80]\n",
      "Train MSE: 45.87650249982682 Mean loss: 45.87389449735658 LR: [0.0002635200944657419]\n",
      "Eval MSE: 45.72452003656826\n",
      "Eval Best MSE: 45.7243008333094\n",
      "Epoch:[27/80]\n",
      "Train MSE: 45.876232857229475 Mean loss: 45.87731494734773 LR: [0.0002503440897424548]\n",
      "Eval MSE: 45.72403469784278\n",
      "Eval Best MSE: 45.72403469784278\n",
      "Epoch:[28/80]\n",
      "Train MSE: 45.87621215942044 Mean loss: 45.86970199314894 LR: [0.00023782688525533205]\n",
      "Eval MSE: 45.7236938603578\n",
      "Eval Best MSE: 45.7236938603578\n",
      "Epoch:[29/80]\n",
      "Train MSE: 45.87605539745975 Mean loss: 45.891979555113124 LR: [0.00022593554099256544]\n",
      "Eval MSE: 45.72474487084527\n",
      "Eval Best MSE: 45.7236938603578\n",
      "Epoch:[30/80]\n",
      "Train MSE: 45.875965383835975 Mean loss: 45.87861830787321 LR: [0.00021463876394293716]\n",
      "Eval MSE: 45.7238551615081\n",
      "Eval Best MSE: 45.7236938603578\n",
      "Epoch:[31/80]\n",
      "Train MSE: 45.87590784528708 Mean loss: 45.88543817638296 LR: [0.0002039068257457903]\n",
      "Eval MSE: 45.72330019291445\n",
      "Eval Best MSE: 45.72330019291445\n",
      "Epoch:[32/80]\n",
      "Train MSE: 45.87568900260171 Mean loss: 45.864625204980904 LR: [0.00019371148445850077]\n",
      "Eval MSE: 45.72350513233858\n",
      "Eval Best MSE: 45.72330019291445\n",
      "Epoch:[33/80]\n",
      "Train MSE: 45.87541000413845 Mean loss: 45.87790249512259 LR: [0.00018402591023557573]\n",
      "Eval MSE: 45.72324173193793\n",
      "Eval Best MSE: 45.72324173193793\n",
      "Epoch:[34/80]\n",
      "Train MSE: 45.87479821455549 Mean loss: 45.865234695704636 LR: [0.00017482461472379692]\n",
      "Eval MSE: 45.72156321433488\n",
      "Eval Best MSE: 45.72156321433488\n",
      "Epoch:[35/80]\n",
      "Train MSE: 45.872733574164975 Mean loss: 45.87801656469835 LR: [0.00016608338398760707]\n",
      "Eval MSE: 45.719754772630836\n",
      "Eval Best MSE: 45.719754772630836\n",
      "Epoch:[36/80]\n",
      "Train MSE: 45.871452232305266 Mean loss: 45.873866984274535 LR: [0.0001577792147882267]\n",
      "Eval MSE: 45.71920204797675\n",
      "Eval Best MSE: 45.71920204797675\n",
      "Epoch:[37/80]\n",
      "Train MSE: 45.87093175622766 Mean loss: 45.88090233254222 LR: [0.00014989025404881537]\n",
      "Eval MSE: 45.71872622270828\n",
      "Eval Best MSE: 45.71872622270828\n",
      "Epoch:[38/80]\n",
      "Train MSE: 45.87068769578672 Mean loss: 45.878608366029454 LR: [0.00014239574134637458]\n",
      "Eval MSE: 45.71861340758803\n",
      "Eval Best MSE: 45.71861340758803\n",
      "Epoch:[39/80]\n",
      "Train MSE: 45.870536086776795 Mean loss: 45.87463932543729 LR: [0.00013527595427905584]\n",
      "Eval MSE: 45.718534133013556\n",
      "Eval Best MSE: 45.718534133013556\n",
      "Epoch:[40/80]\n",
      "Train MSE: 45.870352207783235 Mean loss: 45.87571296016727 LR: [0.00012851215656510304]\n",
      "Eval MSE: 45.71850928455823\n",
      "Eval Best MSE: 45.71850928455823\n",
      "Epoch:[41/80]\n",
      "Train MSE: 45.87031440589315 Mean loss: 45.878859106418304 LR: [0.00012208654873684788]\n",
      "Eval MSE: 45.71826672315862\n",
      "Eval Best MSE: 45.71826672315862\n",
      "Epoch:[42/80]\n",
      "Train MSE: 45.870207743887846 Mean loss: 45.86149286590846 LR: [0.00011598222130000548]\n",
      "Eval MSE: 45.71861847550438\n",
      "Eval Best MSE: 45.71826672315862\n",
      "Epoch:[43/80]\n",
      "Train MSE: 45.87016491739443 Mean loss: 45.862403717716184 LR: [0.00011018311023500519]\n",
      "Eval MSE: 45.718134305321016\n",
      "Eval Best MSE: 45.718134305321016\n",
      "Epoch:[44/80]\n",
      "Train MSE: 45.8701256854229 Mean loss: 45.86884306173409 LR: [0.00010467395472325493]\n",
      "Eval MSE: 45.71842413763624\n",
      "Eval Best MSE: 45.718134305321016\n",
      "Epoch:[45/80]\n",
      "Train MSE: 45.87008318601695 Mean loss: 45.87060421968983 LR: [9.944025698709218e-05]\n",
      "Eval MSE: 45.71810676837205\n",
      "Eval Best MSE: 45.71810676837205\n",
      "Epoch:[46/80]\n",
      "Train MSE: 45.869991287670736 Mean loss: 45.87557314982456 LR: [9.446824413773756e-05]\n",
      "Eval MSE: 45.71802804419785\n",
      "Eval Best MSE: 45.71802804419785\n",
      "Epoch:[47/80]\n",
      "Train MSE: 45.86996005161165 Mean loss: 45.864602266159736 LR: [8.974483193085068e-05]\n",
      "Eval MSE: 45.71808280902486\n",
      "Eval Best MSE: 45.71802804419785\n",
      "Epoch:[48/80]\n",
      "Train MSE: 45.86995544936398 Mean loss: 45.8705902774777 LR: [8.525759033430814e-05]\n",
      "Eval MSE: 45.718240841644324\n",
      "Eval Best MSE: 45.71802804419785\n",
      "Epoch:[49/80]\n",
      "Train MSE: 45.86988556696812 Mean loss: 45.869269362593116 LR: [8.099471081759274e-05]\n",
      "Eval MSE: 45.7182264465603\n",
      "Eval Best MSE: 45.71802804419785\n",
      "Epoch:[50/80]\n",
      "Train MSE: 45.86988361370551 Mean loss: 45.86695372319854 LR: [7.69449752767131e-05]\n",
      "Eval MSE: 45.71805947205335\n",
      "Eval Best MSE: 45.71802804419785\n",
      "Epoch:[51/80]\n",
      "Train MSE: 45.869854805926835 Mean loss: 45.87648827206772 LR: [7.309772651287744e-05]\n",
      "Eval MSE: 45.71803685483604\n",
      "Eval Best MSE: 45.71802804419785\n",
      "Epoch:[52/80]\n",
      "Train MSE: 45.86981549959318 Mean loss: 45.86962779222336 LR: [6.944284018723356e-05]\n",
      "Eval MSE: 45.71818349416989\n",
      "Eval Best MSE: 45.71802804419785\n",
      "Epoch:[53/80]\n",
      "Train MSE: 45.869748247922644 Mean loss: 45.87291006915337 LR: [6.597069817787189e-05]\n",
      "Eval MSE: 45.70991444984631\n",
      "Eval Best MSE: 45.70991444984631\n",
      "Epoch:[54/80]\n",
      "Train MSE: 43.222741124169346 Mean loss: 43.23318847723767 LR: [6.267216326897829e-05]\n",
      "Eval MSE: 41.858435966330816\n",
      "Eval Best MSE: 41.858435966330816\n",
      "Epoch:[55/80]\n",
      "Train MSE: 42.00425920939636 Mean loss: 42.00184101341045 LR: [5.953855510552937e-05]\n",
      "Eval MSE: 41.84199322394605\n",
      "Eval Best MSE: 41.84199322394605\n",
      "Epoch:[56/80]\n",
      "Train MSE: 41.9983473111886 Mean loss: 41.99352490585462 LR: [5.65616273502529e-05]\n",
      "Eval MSE: 41.84025760443176\n",
      "Eval Best MSE: 41.84025760443176\n",
      "Epoch:[57/80]\n",
      "Train MSE: 41.99730095997313 Mean loss: 42.000863809501176 LR: [5.373354598274025e-05]\n",
      "Eval MSE: 41.839574070802406\n",
      "Eval Best MSE: 41.839574070802406\n",
      "Epoch:[58/80]\n",
      "Train MSE: 41.99684253048243 Mean loss: 41.992392886001454 LR: [5.104686868360323e-05]\n",
      "Eval MSE: 41.83922571823679\n",
      "Eval Best MSE: 41.83922571823679\n",
      "Epoch:[59/80]\n",
      "Train MSE: 41.99650376551771 Mean loss: 41.99693647739107 LR: [4.849452524942307e-05]\n",
      "Eval MSE: 41.83901319175661\n",
      "Eval Best MSE: 41.83901319175661\n",
      "Epoch:[60/80]\n",
      "Train MSE: 41.996313642223306 Mean loss: 42.003258899249865 LR: [4.606979898695191e-05]\n",
      "Eval MSE: 41.838853571444055\n",
      "Eval Best MSE: 41.838853571444055\n",
      "Epoch:[61/80]\n",
      "Train MSE: 41.99615124488431 Mean loss: 41.992943451467866 LR: [4.376630903760431e-05]\n",
      "Eval MSE: 41.83868855720884\n",
      "Eval Best MSE: 41.83868855720884\n",
      "Epoch:[62/80]\n",
      "Train MSE: 41.99604797310354 Mean loss: 41.98706218415657 LR: [4.157799358572409e-05]\n",
      "Eval MSE: 41.83873387208657\n",
      "Eval Best MSE: 41.83868855720884\n",
      "Epoch:[63/80]\n",
      "Train MSE: 41.995975879691684 Mean loss: 42.00260513440698 LR: [3.9499093906437885e-05]\n",
      "Eval MSE: 41.838648585447594\n",
      "Eval Best MSE: 41.838648585447594\n",
      "Epoch:[64/80]\n",
      "Train MSE: 41.995878842684945 Mean loss: 42.00020867744378 LR: [3.752413921111599e-05]\n",
      "Eval MSE: 41.83849599755697\n",
      "Eval Best MSE: 41.83849599755697\n",
      "Epoch:[65/80]\n",
      "Train MSE: 41.99580101201074 Mean loss: 41.99180503440114 LR: [3.564793225056019e-05]\n",
      "Eval MSE: 41.83847056483058\n",
      "Eval Best MSE: 41.83847056483058\n",
      "Epoch:[66/80]\n",
      "Train MSE: 41.99573484189883 Mean loss: 41.99714400704983 LR: [3.3865535638032174e-05]\n",
      "Eval MSE: 41.83842877674844\n",
      "Eval Best MSE: 41.83842877674844\n",
      "Epoch:[67/80]\n",
      "Train MSE: 41.99565794961634 Mean loss: 41.997746627942654 LR: [3.2172258856130564e-05]\n",
      "Eval MSE: 41.838304809671925\n",
      "Eval Best MSE: 41.838304809671925\n",
      "Epoch:[68/80]\n",
      "Train MSE: 41.99553389163882 Mean loss: 42.0005604566726 LR: [3.056364591332403e-05]\n",
      "Eval MSE: 41.838160562462335\n",
      "Eval Best MSE: 41.838160562462335\n",
      "Epoch:[69/80]\n",
      "Train MSE: 41.99531449586866 Mean loss: 41.98949255141537 LR: [2.903546361765783e-05]\n",
      "Eval MSE: 41.83803655728119\n",
      "Eval Best MSE: 41.83803655728119\n",
      "Epoch:[70/80]\n",
      "Train MSE: 41.995232581629175 Mean loss: 41.99219158476433 LR: [2.758369043677494e-05]\n",
      "Eval MSE: 41.83803102787539\n",
      "Eval Best MSE: 41.83803102787539\n",
      "Epoch:[71/80]\n",
      "Train MSE: 41.99518337296067 Mean loss: 41.99919420427981 LR: [2.620450591493619e-05]\n",
      "Eval MSE: 41.83792628670374\n",
      "Eval Best MSE: 41.83792628670374\n",
      "Epoch:[72/80]\n",
      "Train MSE: 41.995186307485675 Mean loss: 41.990279121736506 LR: [2.489428061918938e-05]\n",
      "Eval MSE: 41.83799141175739\n",
      "Eval Best MSE: 41.83792628670374\n",
      "Epoch:[73/80]\n",
      "Train MSE: 41.99511328494429 Mean loss: 41.99540374553309 LR: [2.364956658822991e-05]\n",
      "Eval MSE: 41.83789961345982\n",
      "Eval Best MSE: 41.83789961345982\n",
      "Epoch:[74/80]\n",
      "Train MSE: 41.99507021472308 Mean loss: 41.998243635734624 LR: [2.2467088258818413e-05]\n",
      "Eval MSE: 41.83799932058591\n",
      "Eval Best MSE: 41.83789961345982\n",
      "Epoch:[75/80]\n",
      "Train MSE: 41.99505210397478 Mean loss: 41.980691133347236 LR: [2.134373384587749e-05]\n",
      "Eval MSE: 41.83804767113282\n",
      "Eval Best MSE: 41.83789961345982\n",
      "Epoch:[76/80]\n",
      "Train MSE: 41.99500471016536 Mean loss: 41.98948151242416 LR: [2.0276547153583614e-05]\n",
      "Eval MSE: 41.83786069592678\n",
      "Eval Best MSE: 41.83786069592678\n",
      "Epoch:[77/80]\n",
      "Train MSE: 41.995001108498364 Mean loss: 41.992026286842545 LR: [1.9262719795904432e-05]\n",
      "Eval MSE: 41.837773775022384\n",
      "Eval Best MSE: 41.837773775022384\n",
      "Epoch:[78/80]\n",
      "Train MSE: 41.994970535082494 Mean loss: 42.00074791697274 LR: [1.829958380610921e-05]\n",
      "Eval MSE: 41.837814987301165\n",
      "Eval Best MSE: 41.837773775022384\n",
      "Epoch:[79/80]\n",
      "Train MSE: 41.9949514626547 Mean loss: 41.99153744857923 LR: [1.738460461580375e-05]\n",
      "Eval MSE: 41.83782062678702\n",
      "Eval Best MSE: 41.837773775022384\n",
      "Epoch:[80/80]\n",
      "Train MSE: 41.99490319290717 Mean loss: 41.995128108336864 LR: [1.6515374385013564e-05]\n",
      "Eval MSE: 41.83781936933409\n",
      "Eval Best MSE: 41.837773775022384\n",
      "Best Train MSE: 41.99490319290717\n"
     ]
    }
   ],
   "source": [
    "!python us_main.py --config config/us_train_label.yaml"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
