{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://mirrors.bfsu.edu.cn/pypi/web/simple\n",
      "Requirement already satisfied: scikit-learn in /home/wode/公共/wode/.venv/lib/python3.11/site-packages (1.6.0)\n",
      "Requirement already satisfied: pyaml in /home/wode/公共/wode/.venv/lib/python3.11/site-packages (24.9.0)\n",
      "Requirement already satisfied: tensorboardX in /home/wode/公共/wode/.venv/lib/python3.11/site-packages (2.6.2.2)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /home/wode/公共/wode/.venv/lib/python3.11/site-packages (from scikit-learn) (2.2.0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /home/wode/公共/wode/.venv/lib/python3.11/site-packages (from scikit-learn) (1.14.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/wode/公共/wode/.venv/lib/python3.11/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/wode/公共/wode/.venv/lib/python3.11/site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: PyYAML in /home/wode/公共/wode/.venv/lib/python3.11/site-packages (from pyaml) (6.0.2)\n",
      "Requirement already satisfied: packaging in /home/wode/公共/wode/.venv/lib/python3.11/site-packages (from tensorboardX) (24.2)\n",
      "Requirement already satisfied: protobuf>=3.20 in /home/wode/公共/wode/.venv/lib/python3.11/site-packages (from tensorboardX) (5.29.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn pyaml tensorboardX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "split data to train/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 读取数据\n",
    "with open('data/data.pkl', 'rb') as file:\n",
    "    data = pickle.load(file)\n",
    "\n",
    "# 训练集，测试集索引\n",
    "train_idx, test_idx = train_test_split(range(len(data[0])), test_size=0.2, random_state=42)\n",
    "\n",
    "train = [[] for _ in data]\n",
    "test = [[] for _ in data]\n",
    "\n",
    "for i,snr in enumerate(data):\n",
    "    for j in range(len(snr)):\n",
    "        if j in train_idx:\n",
    "            train[i].append(snr[j])\n",
    "        elif j in test_idx:\n",
    "            test[i].append(snr[j])\n",
    "\n",
    "with open('data/train.pkl', 'wb') as f:\n",
    "    pickle.dump(train, f)\n",
    "with open('data/test.pkl', 'wb') as f:\n",
    "    pickle.dump(test, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_snr(模态判断)\n",
    "\n",
    "`BEST ACC@1：99.65`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters:\n",
      "{'work_dir': './work_dir/snr', 'config': 'config/train_snr.yaml', 'phase': 'train', 'save_score': False, 'seed': 1, 'feeder': 'feeder.Feeder_snr', 'num_worker': 8, 'train_feeder_args': {'data_path': './data/train.pkl'}, 'test_feeder_args': {'data_path': './data/test.pkl'}, 'model': 'net.CNN', 'model_args': {'channels': 13, 'num_classes': 3}, 'weights': None, 'ignore_weights': [], 'base_lr': 0.001, 'step': [10, 50], 'device': 0, 'optimizer': 'Adam', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 80, 'weight_decay': 1e-05}\n",
      "\n",
      "Epoch:[1/80]\n",
      "Train Acc@1: 87.50607006854992 Mean loss: 0.325864827183224 LR: [0.00095]\n",
      "Eval Acc@1: 92.43433219522977\n",
      "Eval Best Acc@1: 92.43433219522977\n",
      "Epoch:[2/80]\n",
      "Train Acc@1: 93.99005665571266 Mean loss: 0.16738173133313392 LR: [0.0009025]\n",
      "Eval Acc@1: 94.65408805031447\n",
      "Eval Best Acc@1: 94.65408805031447\n",
      "Epoch:[3/80]\n",
      "Train Acc@1: 95.386749915049 Mean loss: 0.1295156116327326 LR: [0.000857375]\n",
      "Eval Acc@1: 95.56973732889382\n",
      "Eval Best Acc@1: 95.56973732889382\n",
      "Epoch:[4/80]\n",
      "Train Acc@1: 96.12440745388652 Mean loss: 0.10997911921796008 LR: [0.0008145062499999999]\n",
      "Eval Acc@1: 97.57676655567887\n",
      "Eval Best Acc@1: 97.57676655567887\n",
      "Epoch:[5/80]\n",
      "Train Acc@1: 96.7718811502676 Mean loss: 0.09489183195800514 LR: [0.0007737809374999998]\n",
      "Eval Acc@1: 96.45763964552461\n",
      "Eval Best Acc@1: 97.57676655567887\n",
      "Epoch:[6/80]\n",
      "Train Acc@1: 97.09561799845815 Mean loss: 0.08608267114004506 LR: [0.0007350918906249997]\n",
      "Eval Acc@1: 97.41028484043879\n",
      "Eval Best Acc@1: 97.57676655567887\n",
      "Epoch:[7/80]\n",
      "Train Acc@1: 97.46791537387728 Mean loss: 0.07733133856411031 LR: [0.0006983372960937497]\n",
      "Eval Acc@1: 97.54901957961748\n",
      "Eval Best Acc@1: 97.57676655567887\n",
      "Epoch:[8/80]\n",
      "Train Acc@1: 97.7731529683071 Mean loss: 0.06801962940306155 LR: [0.0006634204312890621]\n",
      "Eval Acc@1: 97.68775431879617\n",
      "Eval Best Acc@1: 97.68775431879617\n",
      "Epoch:[9/80]\n",
      "Train Acc@1: 97.98358192580575 Mean loss: 0.06301505352403505 LR: [0.000630249409724609]\n",
      "Eval Acc@1: 97.9929707449893\n",
      "Eval Best Acc@1: 97.9929707449893\n",
      "Epoch:[10/80]\n",
      "Train Acc@1: 98.08070297320602 Mean loss: 0.0593391442740303 LR: [0.0005987369392383785]\n",
      "Eval Acc@1: 98.20569737328894\n",
      "Eval Best Acc@1: 98.20569737328894\n",
      "Epoch:[11/80]\n",
      "Train Acc@1: 98.06682853685498 Mean loss: 0.05867914288489357 LR: [0.0005688000922764595]\n",
      "Eval Acc@1: 98.2981871711824\n",
      "Eval Best Acc@1: 98.2981871711824\n",
      "Epoch:[12/80]\n",
      "Train Acc@1: 98.29806914976228 Mean loss: 0.05360983597829706 LR: [0.0005403600876626365]\n",
      "Eval Acc@1: 98.64039952782318\n",
      "Eval Best Acc@1: 98.64039952782318\n",
      "Epoch:[13/80]\n",
      "Train Acc@1: 98.34200485781695 Mean loss: 0.05077919067185339 LR: [0.0005133420832795047]\n",
      "Eval Acc@1: 98.04846464066077\n",
      "Eval Best Acc@1: 98.64039952782318\n",
      "Epoch:[14/80]\n",
      "Train Acc@1: 98.45068794962353 Mean loss: 0.04881327101456542 LR: [0.00048767497911552944]\n",
      "Eval Acc@1: 98.52941173648023\n",
      "Eval Best Acc@1: 98.64039952782318\n",
      "Epoch:[15/80]\n",
      "Train Acc@1: 98.61255637283669 Mean loss: 0.04401166508915922 LR: [0.00046329123015975297]\n",
      "Eval Acc@1: 97.62301146873844\n",
      "Eval Best Acc@1: 98.64039952782318\n",
      "Epoch:[16/80]\n",
      "Train Acc@1: 98.60099434254417 Mean loss: 0.04482011403750694 LR: [0.0004401266686517653]\n",
      "Eval Acc@1: 99.07510171058307\n",
      "Eval Best Acc@1: 99.07510171058307\n",
      "Epoch:[17/80]\n",
      "Train Acc@1: 98.66111689389048 Mean loss: 0.042222796620376764 LR: [0.00041812033521917703]\n",
      "Eval Acc@1: 98.52941173648023\n",
      "Eval Best Acc@1: 99.07510171058307\n",
      "Epoch:[18/80]\n",
      "Train Acc@1: 98.64493005765574 Mean loss: 0.041714940898288484 LR: [0.00039721431845821814]\n",
      "Eval Acc@1: 98.84387714528526\n",
      "Eval Best Acc@1: 99.07510171058307\n",
      "Epoch:[19/80]\n",
      "Train Acc@1: 98.75823795540455 Mean loss: 0.039387042040057677 LR: [0.0003773536025353072]\n",
      "Eval Acc@1: 99.0196078149116\n",
      "Eval Best Acc@1: 99.07510171058307\n",
      "Epoch:[20/80]\n",
      "Train Acc@1: 98.88310788168164 Mean loss: 0.03638063989732602 LR: [0.0003584859224085418]\n",
      "Eval Acc@1: 99.10284865841881\n",
      "Eval Best Acc@1: 99.10284865841881\n",
      "Epoch:[21/80]\n",
      "Train Acc@1: 98.80217366963402 Mean loss: 0.03672044244322777 LR: [0.0003405616262881147]\n",
      "Eval Acc@1: 98.26119126896042\n",
      "Eval Best Acc@1: 99.10284865841881\n",
      "Epoch:[22/80]\n",
      "Train Acc@1: 98.90391953709029 Mean loss: 0.03514756190679422 LR: [0.00032353354497370894]\n",
      "Eval Acc@1: 98.45541987558492\n",
      "Eval Best Acc@1: 99.10284865841881\n",
      "Epoch:[23/80]\n",
      "Train Acc@1: 98.95710487643588 Mean loss: 0.03314985953648189 LR: [0.00030735686772502346]\n",
      "Eval Acc@1: 98.75138731916613\n",
      "Eval Best Acc@1: 99.10284865841881\n",
      "Epoch:[24/80]\n",
      "Train Acc@1: 98.92704359679323 Mean loss: 0.03350019551222571 LR: [0.00029198902433877225]\n",
      "Eval Acc@1: 99.08435069319499\n",
      "Eval Best Acc@1: 99.10284865841881\n",
      "Epoch:[25/80]\n",
      "Train Acc@1: 99.07734999059598 Mean loss: 0.03141295124525921 LR: [0.00027738957312183364]\n",
      "Eval Acc@1: 98.99186086707586\n",
      "Eval Best Acc@1: 99.10284865841881\n",
      "Epoch:[26/80]\n",
      "Train Acc@1: 99.01491502701637 Mean loss: 0.031296753940398436 LR: [0.0002635200944657419]\n",
      "Eval Acc@1: 99.05660377358491\n",
      "Eval Best Acc@1: 99.10284865841881\n",
      "Epoch:[27/80]\n",
      "Train Acc@1: 99.10509886329801 Mean loss: 0.02899452245106422 LR: [0.0002503440897424548]\n",
      "Eval Acc@1: 99.12134662364264\n",
      "Eval Best Acc@1: 99.12134662364264\n",
      "Epoch:[28/80]\n",
      "Train Acc@1: 99.08197480271298 Mean loss: 0.029364128083200058 LR: [0.00023782688525533205]\n",
      "Eval Acc@1: 98.79763226045135\n",
      "Eval Best Acc@1: 99.12134662364264\n",
      "Epoch:[29/80]\n",
      "Train Acc@1: 99.16290901476061 Mean loss: 0.02769743419888143 LR: [0.00022593554099256544]\n",
      "Eval Acc@1: 99.26933034543325\n",
      "Eval Best Acc@1: 99.26933034543325\n",
      "Epoch:[30/80]\n",
      "Train Acc@1: 99.19759510563817 Mean loss: 0.026696398036076395 LR: [0.00021463876394293716]\n",
      "Eval Acc@1: 99.09359970403256\n",
      "Eval Best Acc@1: 99.26933034543325\n",
      "Epoch:[31/80]\n",
      "Train Acc@1: 99.19990751169668 Mean loss: 0.026244558622652785 LR: [0.0002039068257457903]\n",
      "Eval Acc@1: 98.93636697140438\n",
      "Eval Best Acc@1: 99.26933034543325\n",
      "Epoch:[32/80]\n",
      "Train Acc@1: 99.1513469853502 Mean loss: 0.026650284017097292 LR: [0.00019371148445850077]\n",
      "Eval Acc@1: 98.91786900618057\n",
      "Eval Best Acc@1: 99.26933034543325\n",
      "Epoch:[33/80]\n",
      "Train Acc@1: 99.20221991775519 Mean loss: 0.025721863549534707 LR: [0.00018402591023557573]\n",
      "Eval Acc@1: 99.3155752584928\n",
      "Eval Best Acc@1: 99.3155752584928\n",
      "Epoch:[34/80]\n",
      "Train Acc@1: 99.26234247527628 Mean loss: 0.024824552666967648 LR: [0.00017482461472379692]\n",
      "Eval Acc@1: 99.1583425540903\n",
      "Eval Best Acc@1: 99.3155752584928\n",
      "Epoch:[35/80]\n",
      "Train Acc@1: 99.29471616009533 Mean loss: 0.02387946793255355 LR: [0.00016608338398760707]\n",
      "Eval Acc@1: 98.97336290185204\n",
      "Eval Best Acc@1: 99.3155752584928\n",
      "Epoch:[36/80]\n",
      "Train Acc@1: 99.27852931768581 Mean loss: 0.024236811090056844 LR: [0.0001577792147882267]\n",
      "Eval Acc@1: 99.17684051931411\n",
      "Eval Best Acc@1: 99.3155752584928\n",
      "Epoch:[37/80]\n",
      "Train Acc@1: 99.30396578432935 Mean loss: 0.023628759600780768 LR: [0.00014989025404881537]\n",
      "Eval Acc@1: 99.32482424110472\n",
      "Eval Best Acc@1: 99.32482424110472\n",
      "Epoch:[38/80]\n",
      "Train Acc@1: 99.32246503279738 Mean loss: 0.022827486596692776 LR: [0.00014239574134637458]\n",
      "Eval Acc@1: 99.26933034543325\n",
      "Eval Best Acc@1: 99.32482424110472\n",
      "Epoch:[39/80]\n",
      "Train Acc@1: 99.35252631155794 Mean loss: 0.02190145512801022 LR: [0.00013527595427905584]\n",
      "Eval Acc@1: 99.06585272797116\n",
      "Eval Best Acc@1: 99.32482424110472\n",
      "Epoch:[40/80]\n",
      "Train Acc@1: 99.36871315396746 Mean loss: 0.021306204407740406 LR: [0.00012851215656510304]\n",
      "Eval Acc@1: 99.1675915367022\n",
      "Eval Best Acc@1: 99.32482424110472\n",
      "Epoch:[41/80]\n",
      "Train Acc@1: 99.3918372145525 Mean loss: 0.020558504380245098 LR: [0.00012208654873684788]\n",
      "Eval Acc@1: 99.13059560625456\n",
      "Eval Best Acc@1: 99.32482424110472\n",
      "Epoch:[42/80]\n",
      "Train Acc@1: 99.40108683878651 Mean loss: 0.020985756897847666 LR: [0.00011598222130000548]\n",
      "Eval Acc@1: 99.3155752584928\n",
      "Eval Best Acc@1: 99.32482424110472\n",
      "Epoch:[43/80]\n",
      "Train Acc@1: 99.40339924484502 Mean loss: 0.020001001694544836 LR: [0.00011018311023500519]\n",
      "Eval Acc@1: 99.12134662364264\n",
      "Eval Best Acc@1: 99.32482424110472\n",
      "Epoch:[44/80]\n",
      "Train Acc@1: 99.44502255389808 Mean loss: 0.020011383408443596 LR: [0.00010467395472325493]\n",
      "Eval Acc@1: 99.30632627588089\n",
      "Eval Best Acc@1: 99.32482424110472\n",
      "Epoch:[45/80]\n",
      "Train Acc@1: 99.40802405696202 Mean loss: 0.019381093814057716 LR: [9.944025698709218e-05]\n",
      "Eval Acc@1: 99.0935996758069\n",
      "Eval Best Acc@1: 99.32482424110472\n",
      "Epoch:[46/80]\n",
      "Train Acc@1: 99.45658458419061 Mean loss: 0.019137633139265496 LR: [9.446824413773756e-05]\n",
      "Eval Acc@1: 99.33407322371663\n",
      "Eval Best Acc@1: 99.33407322371663\n",
      "Epoch:[47/80]\n",
      "Train Acc@1: 99.44271014783958 Mean loss: 0.01915882816214456 LR: [8.974483193085068e-05]\n",
      "Eval Acc@1: 99.22308543237368\n",
      "Eval Best Acc@1: 99.33407322371663\n",
      "Epoch:[48/80]\n",
      "Train Acc@1: 99.47739623871713 Mean loss: 0.018906397872213335 LR: [8.525759033430814e-05]\n",
      "Eval Acc@1: 99.34332220632854\n",
      "Eval Best Acc@1: 99.34332220632854\n",
      "Epoch:[49/80]\n",
      "Train Acc@1: 99.5120823295947 Mean loss: 0.017777513313371022 LR: [8.099471081759274e-05]\n",
      "Eval Acc@1: 99.26008136282132\n",
      "Eval Best Acc@1: 99.34332220632854\n",
      "Epoch:[50/80]\n",
      "Train Acc@1: 99.53983120317886 Mean loss: 0.01770958038552915 LR: [7.69449752767131e-05]\n",
      "Eval Acc@1: 99.27857932804515\n",
      "Eval Best Acc@1: 99.34332220632854\n",
      "Epoch:[51/80]\n",
      "Train Acc@1: 99.5167071417117 Mean loss: 0.017646452765560504 LR: [7.309772651287744e-05]\n",
      "Eval Acc@1: 99.23233441498559\n",
      "Eval Best Acc@1: 99.34332220632854\n",
      "Epoch:[52/80]\n",
      "Train Acc@1: 99.50745751747769 Mean loss: 0.01774468571479782 LR: [6.944284018723356e-05]\n",
      "Eval Acc@1: 99.26933034543325\n",
      "Eval Best Acc@1: 99.34332220632854\n",
      "Epoch:[53/80]\n",
      "Train Acc@1: 99.47970864477564 Mean loss: 0.017621501771219628 LR: [6.597069817787189e-05]\n",
      "Eval Acc@1: 99.22308546059934\n",
      "Eval Best Acc@1: 99.34332220632854\n",
      "Epoch:[54/80]\n",
      "Train Acc@1: 99.53520639017974 Mean loss: 0.017156182790034554 LR: [6.267216326897829e-05]\n",
      "Eval Acc@1: 99.25083238020942\n",
      "Eval Best Acc@1: 99.34332220632854\n",
      "Epoch:[55/80]\n",
      "Train Acc@1: 99.54445601441375 Mean loss: 0.016818923962785733 LR: [5.953855510552937e-05]\n",
      "Eval Acc@1: 99.30632627588089\n",
      "Eval Best Acc@1: 99.34332220632854\n",
      "Epoch:[56/80]\n",
      "Train Acc@1: 99.53983120317886 Mean loss: 0.01651055100404922 LR: [5.65616273502529e-05]\n",
      "Eval Acc@1: 99.35257118894046\n",
      "Eval Best Acc@1: 99.35257118894046\n",
      "Epoch:[57/80]\n",
      "Train Acc@1: 99.55601804470628 Mean loss: 0.016544288042216346 LR: [5.373354598274025e-05]\n",
      "Eval Acc@1: 99.26008139104698\n",
      "Eval Best Acc@1: 99.35257118894046\n",
      "Epoch:[58/80]\n",
      "Train Acc@1: 99.58607932346682 Mean loss: 0.01600121824465521 LR: [5.104686868360323e-05]\n",
      "Eval Acc@1: 99.29707729326898\n",
      "Eval Best Acc@1: 99.35257118894046\n",
      "Epoch:[59/80]\n",
      "Train Acc@1: 99.5698924810573 Mean loss: 0.016066098339547755 LR: [4.849452524942307e-05]\n",
      "Eval Acc@1: 99.27857932804515\n",
      "Eval Best Acc@1: 99.35257118894046\n",
      "Epoch:[60/80]\n",
      "Train Acc@1: 99.54676842047226 Mean loss: 0.016067998038867305 LR: [4.606979898695191e-05]\n",
      "Eval Acc@1: 99.3895671193881\n",
      "Eval Best Acc@1: 99.3895671193881\n",
      "Epoch:[61/80]\n",
      "Train Acc@1: 99.57914210529131 Mean loss: 0.01587759923166113 LR: [4.376630903760431e-05]\n",
      "Eval Acc@1: 99.29707729326898\n",
      "Eval Best Acc@1: 99.3895671193881\n",
      "Epoch:[62/80]\n",
      "Train Acc@1: 99.57451729317431 Mean loss: 0.015794165154029382 LR: [4.157799358572409e-05]\n",
      "Eval Acc@1: 99.25083238020942\n",
      "Eval Best Acc@1: 99.3895671193881\n",
      "Epoch:[63/80]\n",
      "Train Acc@1: 99.58839172952533 Mean loss: 0.01545401399400803 LR: [3.9499093906437885e-05]\n",
      "Eval Acc@1: 99.34332220632854\n",
      "Eval Best Acc@1: 99.3895671193881\n",
      "Epoch:[64/80]\n",
      "Train Acc@1: 99.58376691740833 Mean loss: 0.01542536442250891 LR: [3.752413921111599e-05]\n",
      "Eval Acc@1: 99.26933034543325\n",
      "Eval Best Acc@1: 99.3895671193881\n",
      "Epoch:[65/80]\n",
      "Train Acc@1: 99.58145451134982 Mean loss: 0.015555218416006104 LR: [3.564793225056019e-05]\n",
      "Eval Acc@1: 99.33407322371663\n",
      "Eval Best Acc@1: 99.3895671193881\n",
      "Epoch:[66/80]\n",
      "Train Acc@1: 99.61151579011036 Mean loss: 0.015148581509180808 LR: [3.3865535638032174e-05]\n",
      "Eval Acc@1: 99.30632627588089\n",
      "Eval Best Acc@1: 99.3895671193881\n",
      "Epoch:[67/80]\n",
      "Train Acc@1: 99.61382819705098 Mean loss: 0.015185757791638973 LR: [3.2172258856130564e-05]\n",
      "Eval Acc@1: 99.3155752584928\n",
      "Eval Best Acc@1: 99.3895671193881\n",
      "Epoch:[68/80]\n",
      "Train Acc@1: 99.60689097799336 Mean loss: 0.015014084736214187 LR: [3.056364591332403e-05]\n",
      "Eval Acc@1: 99.29707729326898\n",
      "Eval Best Acc@1: 99.3895671193881\n",
      "Epoch:[69/80]\n",
      "Train Acc@1: 99.61382819616887 Mean loss: 0.014791011820506296 LR: [2.903546361765783e-05]\n",
      "Eval Acc@1: 99.35257118894046\n",
      "Eval Best Acc@1: 99.3895671193881\n",
      "Epoch:[70/80]\n",
      "Train Acc@1: 99.6277026325199 Mean loss: 0.014747542393927327 LR: [2.758369043677494e-05]\n",
      "Eval Acc@1: 99.29707729326898\n",
      "Eval Best Acc@1: 99.3895671193881\n",
      "Epoch:[71/80]\n",
      "Train Acc@1: 99.61151579011036 Mean loss: 0.014692556922078255 LR: [2.620450591493619e-05]\n",
      "Eval Acc@1: 99.33407322371663\n",
      "Eval Best Acc@1: 99.3895671193881\n",
      "Epoch:[72/80]\n",
      "Train Acc@1: 99.6277026263451 Mean loss: 0.014648486379151351 LR: [2.489428061918938e-05]\n",
      "Eval Acc@1: 99.30632627588089\n",
      "Eval Best Acc@1: 99.3895671193881\n",
      "Epoch:[73/80]\n",
      "Train Acc@1: 99.64620188098792 Mean loss: 0.01457612830141529 LR: [2.364956658822991e-05]\n",
      "Eval Acc@1: 99.32482424110472\n",
      "Eval Best Acc@1: 99.3895671193881\n",
      "Epoch:[74/80]\n",
      "Train Acc@1: 99.6300150394605 Mean loss: 0.014557391682797464 LR: [2.2467088258818413e-05]\n",
      "Eval Acc@1: 99.32482424110472\n",
      "Eval Best Acc@1: 99.3895671193881\n",
      "Epoch:[75/80]\n",
      "Train Acc@1: 99.65313909916344 Mean loss: 0.014364610688299176 LR: [2.134373384587749e-05]\n",
      "Eval Acc@1: 99.34332220632854\n",
      "Eval Best Acc@1: 99.3895671193881\n",
      "Epoch:[76/80]\n",
      "Train Acc@1: 99.65082669398704 Mean loss: 0.014449276391493595 LR: [2.0276547153583614e-05]\n",
      "Eval Acc@1: 99.33407322371663\n",
      "Eval Best Acc@1: 99.3895671193881\n",
      "Epoch:[77/80]\n",
      "Train Acc@1: 99.65313909916344 Mean loss: 0.014303314040568947 LR: [1.9262719795904432e-05]\n",
      "Eval Acc@1: 99.34332220632854\n",
      "Eval Best Acc@1: 99.3895671193881\n",
      "Epoch:[78/80]\n",
      "Train Acc@1: 99.65545150522193 Mean loss: 0.01412995395427308 LR: [1.829958380610921e-05]\n",
      "Eval Acc@1: 99.33407322371663\n",
      "Eval Best Acc@1: 99.3895671193881\n",
      "Epoch:[79/80]\n",
      "Train Acc@1: 99.63695225675391 Mean loss: 0.014210609624871142 LR: [1.738460461580375e-05]\n",
      "Eval Acc@1: 99.33407322371663\n",
      "Eval Best Acc@1: 99.3895671193881\n",
      "Epoch:[80/80]\n",
      "Train Acc@1: 99.64851428704642 Mean loss: 0.014181032623693047 LR: [1.6515374385013564e-05]\n",
      "Eval Acc@1: 99.34332220632854\n",
      "Eval Best Acc@1: 99.3895671193881\n",
      "Best Train Acc@1: 99.65545150522193\n"
     ]
    }
   ],
   "source": [
    "!python main.py --config config/train_snr.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_device(设备判断)\n",
    "\n",
    "`BEST ACC@1：88.67`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters:\n",
      "{'work_dir': './work_dir/device', 'config': 'config/train_device.yaml', 'phase': 'train', 'save_score': False, 'seed': 1, 'feeder': 'feeder.Feeder_device', 'num_worker': 8, 'train_feeder_args': {'data_path': './data/train.pkl', 'snr': 0}, 'test_feeder_args': {'data_path': './data/test.pkl', 'snr': 0}, 'model': 'net.CNN', 'model_args': {'channels': 13, 'num_classes': 4}, 'weights': None, 'ignore_weights': [], 'base_lr': 0.001, 'step': [10, 50], 'device': 0, 'optimizer': 'Adam', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 80, 'weight_decay': 1e-05}\n",
      "\n",
      "Epoch:[1/80]\n",
      "Train Acc@1: 81.24869926894576 Mean loss: 0.49249914961051094 LR: [0.00095]\n",
      "Eval Acc@1: 81.2708102108768\n",
      "Eval Best Acc@1: 81.2708102108768\n",
      "Epoch:[2/80]\n",
      "Train Acc@1: 81.79673950481117 Mean loss: 0.4623432752832902 LR: [0.0009025]\n",
      "Eval Acc@1: 81.24306326304107\n",
      "Eval Best Acc@1: 81.2708102108768\n",
      "Epoch:[3/80]\n",
      "Train Acc@1: 82.1990981563445 Mean loss: 0.450233753803557 LR: [0.000857375]\n",
      "Eval Acc@1: 81.88124306326304\n",
      "Eval Best Acc@1: 81.88124306326304\n",
      "Epoch:[4/80]\n",
      "Train Acc@1: 83.27436697354881 Mean loss: 0.4380154895835218 LR: [0.0008145062499999999]\n",
      "Eval Acc@1: 83.3795782463929\n",
      "Eval Best Acc@1: 83.3795782463929\n",
      "Epoch:[5/80]\n",
      "Train Acc@1: 84.07214706373264 Mean loss: 0.4192144897131793 LR: [0.0007737809374999998]\n",
      "Eval Acc@1: 84.37846836847947\n",
      "Eval Best Acc@1: 84.37846836847947\n",
      "Epoch:[6/80]\n",
      "Train Acc@1: 84.75893166575463 Mean loss: 0.4070517110217989 LR: [0.0007350918906249997]\n",
      "Eval Acc@1: 84.71143174250832\n",
      "Eval Best Acc@1: 84.71143174250832\n",
      "Epoch:[7/80]\n",
      "Train Acc@1: 85.16822754075616 Mean loss: 0.40029577007599637 LR: [0.0006983372960937497]\n",
      "Eval Acc@1: 84.79467258601554\n",
      "Eval Best Acc@1: 84.79467258601554\n",
      "Epoch:[8/80]\n",
      "Train Acc@1: 85.48040235600784 Mean loss: 0.3939259645026342 LR: [0.0006634204312890621]\n",
      "Eval Acc@1: 84.62819089900111\n",
      "Eval Best Acc@1: 84.79467258601554\n",
      "Epoch:[9/80]\n",
      "Train Acc@1: 85.55671175329213 Mean loss: 0.389473271778727 LR: [0.000630249409724609]\n",
      "Eval Acc@1: 85.29411764705883\n",
      "Eval Best Acc@1: 85.29411764705883\n",
      "Epoch:[10/80]\n",
      "Train Acc@1: 86.07700311910185 Mean loss: 0.3789747799787901 LR: [0.0005987369392383785]\n",
      "Eval Acc@1: 85.65482796892341\n",
      "Eval Best Acc@1: 85.65482796892341\n",
      "Epoch:[11/80]\n",
      "Train Acc@1: 86.20881026179022 Mean loss: 0.37373644364091146 LR: [0.0005688000922764595]\n",
      "Eval Acc@1: 85.76581576026638\n",
      "Eval Best Acc@1: 85.76581576026638\n",
      "Epoch:[12/80]\n",
      "Train Acc@1: 86.47936177328151 Mean loss: 0.37088162550884013 LR: [0.0005403600876626365]\n",
      "Eval Acc@1: 83.65704772475027\n",
      "Eval Best Acc@1: 85.76581576026638\n",
      "Epoch:[13/80]\n",
      "Train Acc@1: 86.37530350064884 Mean loss: 0.3689296378762321 LR: [0.0005133420832795047]\n",
      "Eval Acc@1: 86.04328523862375\n",
      "Eval Best Acc@1: 86.04328523862375\n",
      "Epoch:[14/80]\n",
      "Train Acc@1: 86.75685050294832 Mean loss: 0.36207091102821637 LR: [0.00048767497911552944]\n",
      "Eval Acc@1: 86.18201997780244\n",
      "Eval Best Acc@1: 86.18201997780244\n",
      "Epoch:[15/80]\n",
      "Train Acc@1: 86.8262226820571 Mean loss: 0.3600301302771653 LR: [0.00046329123015975297]\n",
      "Eval Acc@1: 86.12652608213097\n",
      "Eval Best Acc@1: 86.18201997780244\n",
      "Epoch:[16/80]\n",
      "Train Acc@1: 86.9233437391606 Mean loss: 0.3552332042460948 LR: [0.0004401266686517653]\n",
      "Eval Acc@1: 85.96004439511654\n",
      "Eval Best Acc@1: 86.18201997780244\n",
      "Epoch:[17/80]\n",
      "Train Acc@1: 86.8678459937565 Mean loss: 0.3558836665037459 LR: [0.00041812033521917703]\n",
      "Eval Acc@1: 86.26526082130965\n",
      "Eval Best Acc@1: 86.26526082130965\n",
      "Epoch:[18/80]\n",
      "Train Acc@1: 86.98577870009386 Mean loss: 0.3515028209812873 LR: [0.00039721431845821814]\n",
      "Eval Acc@1: 86.26526082130965\n",
      "Eval Best Acc@1: 86.26526082130965\n",
      "Epoch:[19/80]\n",
      "Train Acc@1: 87.11758584542858 Mean loss: 0.3500408199904239 LR: [0.0003773536025353072]\n",
      "Eval Acc@1: 86.04328523862375\n",
      "Eval Best Acc@1: 86.26526082130965\n",
      "Epoch:[20/80]\n",
      "Train Acc@1: 87.15227193895248 Mean loss: 0.3426892404667044 LR: [0.0003584859224085418]\n",
      "Eval Acc@1: 86.34850166481687\n",
      "Eval Best Acc@1: 86.34850166481687\n",
      "Epoch:[21/80]\n",
      "Train Acc@1: 87.27714186346535 Mean loss: 0.3407315723927675 LR: [0.0003405616262881147]\n",
      "Eval Acc@1: 86.32075471698113\n",
      "Eval Best Acc@1: 86.34850166481687\n",
      "Epoch:[22/80]\n",
      "Train Acc@1: 87.25633021158515 Mean loss: 0.3404736766113644 LR: [0.00032353354497370894]\n",
      "Eval Acc@1: 86.04328523862375\n",
      "Eval Best Acc@1: 86.34850166481687\n",
      "Epoch:[23/80]\n",
      "Train Acc@1: 87.32570239069393 Mean loss: 0.3361866291513485 LR: [0.00030735686772502346]\n",
      "Eval Acc@1: 86.26526082130965\n",
      "Eval Best Acc@1: 86.34850166481687\n",
      "Epoch:[24/80]\n",
      "Train Acc@1: 87.58931668136337 Mean loss: 0.33259424204583715 LR: [0.00029198902433877225]\n",
      "Eval Acc@1: 86.3762486126526\n",
      "Eval Best Acc@1: 86.3762486126526\n",
      "Epoch:[25/80]\n",
      "Train Acc@1: 87.5130072787864 Mean loss: 0.33164014469469544 LR: [0.00027738957312183364]\n",
      "Eval Acc@1: 86.43174250832408\n",
      "Eval Best Acc@1: 86.43174250832408\n",
      "Epoch:[26/80]\n",
      "Train Acc@1: 87.58931668400972 Mean loss: 0.3302824046232004 LR: [0.0002635200944657419]\n",
      "Eval Acc@1: 86.3762486126526\n",
      "Eval Best Acc@1: 86.43174250832408\n",
      "Epoch:[27/80]\n",
      "Train Acc@1: 87.41588622697559 Mean loss: 0.3262297802530559 LR: [0.0002503440897424548]\n",
      "Eval Acc@1: 86.18201997780244\n",
      "Eval Best Acc@1: 86.43174250832408\n",
      "Epoch:[28/80]\n",
      "Train Acc@1: 87.55463058783948 Mean loss: 0.32439565513513785 LR: [0.00023782688525533205]\n",
      "Eval Acc@1: 86.45948945615983\n",
      "Eval Best Acc@1: 86.45948945615983\n",
      "Epoch:[29/80]\n",
      "Train Acc@1: 87.66562608394034 Mean loss: 0.32173956099864653 LR: [0.00022593554099256544]\n",
      "Eval Acc@1: 86.57047724750278\n",
      "Eval Best Acc@1: 86.57047724750278\n",
      "Epoch:[30/80]\n",
      "Train Acc@1: 87.65868886311848 Mean loss: 0.32199103695101444 LR: [0.00021463876394293716]\n",
      "Eval Acc@1: 86.29300776914539\n",
      "Eval Best Acc@1: 86.57047724750278\n",
      "Epoch:[31/80]\n",
      "Train Acc@1: 87.49219562425988 Mean loss: 0.32117627270981275 LR: [0.0002039068257457903]\n",
      "Eval Acc@1: 86.70921198668147\n",
      "Eval Best Acc@1: 86.70921198668147\n",
      "Epoch:[32/80]\n",
      "Train Acc@1: 87.58237946318786 Mean loss: 0.31924740970134735 LR: [0.00019371148445850077]\n",
      "Eval Acc@1: 86.43174250832408\n",
      "Eval Best Acc@1: 86.70921198668147\n",
      "Epoch:[33/80]\n",
      "Train Acc@1: 87.59625389689255 Mean loss: 0.31523594741536454 LR: [0.00018402591023557573]\n",
      "Eval Acc@1: 86.59822419533852\n",
      "Eval Best Acc@1: 86.70921198668147\n",
      "Epoch:[34/80]\n",
      "Train Acc@1: 87.83905653568179 Mean loss: 0.31482283616092355 LR: [0.00017482461472379692]\n",
      "Eval Acc@1: 86.48723640399557\n",
      "Eval Best Acc@1: 86.70921198668147\n",
      "Epoch:[35/80]\n",
      "Train Acc@1: 87.82518209668443 Mean loss: 0.3115538881547683 LR: [0.00016608338398760707]\n",
      "Eval Acc@1: 86.98668146503884\n",
      "Eval Best Acc@1: 86.98668146503884\n",
      "Epoch:[36/80]\n",
      "Train Acc@1: 87.90149149661505 Mean loss: 0.3115532455586754 LR: [0.0001577792147882267]\n",
      "Eval Acc@1: 86.98668146503884\n",
      "Eval Best Acc@1: 86.98668146503884\n",
      "Epoch:[37/80]\n",
      "Train Acc@1: 87.67950052029137 Mean loss: 0.3096728954563099 LR: [0.00014989025404881537]\n",
      "Eval Acc@1: 86.62597114317425\n",
      "Eval Best Acc@1: 86.98668146503884\n",
      "Epoch:[38/80]\n",
      "Train Acc@1: 87.97780089919202 Mean loss: 0.3076515038852143 LR: [0.00014239574134637458]\n",
      "Eval Acc@1: 86.76470588235294\n",
      "Eval Best Acc@1: 86.98668146503884\n",
      "Epoch:[39/80]\n",
      "Train Acc@1: 87.99861255107221 Mean loss: 0.30730396561918005 LR: [0.00013527595427905584]\n",
      "Eval Acc@1: 86.9589345172031\n",
      "Eval Best Acc@1: 86.98668146503884\n",
      "Epoch:[40/80]\n",
      "Train Acc@1: 87.9916753328967 Mean loss: 0.30521126836538315 LR: [0.00012851215656510304]\n",
      "Eval Acc@1: 87.04217536071032\n",
      "Eval Best Acc@1: 87.04217536071032\n",
      "Epoch:[41/80]\n",
      "Train Acc@1: 88.01942421089143 Mean loss: 0.3037434926470824 LR: [0.00012208654873684788]\n",
      "Eval Acc@1: 86.7369589345172\n",
      "Eval Best Acc@1: 87.04217536071032\n",
      "Epoch:[42/80]\n",
      "Train Acc@1: 88.00554977189407 Mean loss: 0.30349411927493275 LR: [0.00011598222130000548]\n",
      "Eval Acc@1: 86.93118756936737\n",
      "Eval Best Acc@1: 87.04217536071032\n",
      "Epoch:[43/80]\n",
      "Train Acc@1: 88.06104751465182 Mean loss: 0.30097537547086195 LR: [0.00011018311023500519]\n",
      "Eval Acc@1: 87.06992230854605\n",
      "Eval Best Acc@1: 87.06992230854605\n",
      "Epoch:[44/80]\n",
      "Train Acc@1: 88.15816857440167 Mean loss: 0.3006496446256616 LR: [0.00010467395472325493]\n",
      "Eval Acc@1: 87.12541620421753\n",
      "Eval Best Acc@1: 87.12541620421753\n",
      "Epoch:[45/80]\n",
      "Train Acc@1: 88.23447797168595 Mean loss: 0.2998940736319112 LR: [9.944025698709218e-05]\n",
      "Eval Acc@1: 86.93118756936737\n",
      "Eval Best Acc@1: 87.12541620421753\n",
      "Epoch:[46/80]\n",
      "Train Acc@1: 88.24141518986147 Mean loss: 0.2983624389213798 LR: [9.446824413773756e-05]\n",
      "Eval Acc@1: 87.01442841287458\n",
      "Eval Best Acc@1: 87.12541620421753\n",
      "Epoch:[47/80]\n",
      "Train Acc@1: 88.2414151925078 Mean loss: 0.2974705837205448 LR: [8.974483193085068e-05]\n",
      "Eval Acc@1: 87.20865704772476\n",
      "Eval Best Acc@1: 87.20865704772476\n",
      "Epoch:[48/80]\n",
      "Train Acc@1: 88.24835240803698 Mean loss: 0.2963507944239979 LR: [8.525759033430814e-05]\n",
      "Eval Acc@1: 87.15316315205328\n",
      "Eval Best Acc@1: 87.20865704772476\n",
      "Epoch:[49/80]\n",
      "Train Acc@1: 88.42178285977843 Mean loss: 0.29711760204713955 LR: [8.099471081759274e-05]\n",
      "Eval Acc@1: 87.40288568257492\n",
      "Eval Best Acc@1: 87.40288568257492\n",
      "Epoch:[50/80]\n",
      "Train Acc@1: 88.262226844388 Mean loss: 0.29546299217417177 LR: [7.69449752767131e-05]\n",
      "Eval Acc@1: 87.43063263041066\n",
      "Eval Best Acc@1: 87.43063263041066\n",
      "Epoch:[51/80]\n",
      "Train Acc@1: 88.36628511437434 Mean loss: 0.29429007460058265 LR: [7.309772651287744e-05]\n",
      "Eval Acc@1: 87.12541620421753\n",
      "Eval Best Acc@1: 87.43063263041066\n",
      "Epoch:[52/80]\n",
      "Train Acc@1: 88.51890391688192 Mean loss: 0.2932593568632033 LR: [6.944284018723356e-05]\n",
      "Eval Acc@1: 87.26415094339623\n",
      "Eval Best Acc@1: 87.43063263041066\n",
      "Epoch:[53/80]\n",
      "Train Acc@1: 88.33853624167229 Mean loss: 0.2927842460638654 LR: [6.597069817787189e-05]\n",
      "Eval Acc@1: 86.93118756936737\n",
      "Eval Best Acc@1: 87.43063263041066\n",
      "Epoch:[54/80]\n",
      "Train Acc@1: 88.38709676890088 Mean loss: 0.2922097249368651 LR: [6.267216326897829e-05]\n",
      "Eval Acc@1: 87.29189789123197\n",
      "Eval Best Acc@1: 87.43063263041066\n",
      "Epoch:[55/80]\n",
      "Train Acc@1: 88.36628511966701 Mean loss: 0.29161644113802276 LR: [5.953855510552937e-05]\n",
      "Eval Acc@1: 86.9589345172031\n",
      "Eval Best Acc@1: 87.43063263041066\n",
      "Epoch:[56/80]\n",
      "Train Acc@1: 88.33159902614311 Mean loss: 0.2919152935851464 LR: [5.65616273502529e-05]\n",
      "Eval Acc@1: 87.09766925638179\n",
      "Eval Best Acc@1: 87.43063263041066\n",
      "Epoch:[57/80]\n",
      "Train Acc@1: 88.49809226500173 Mean loss: 0.2913007118401274 LR: [5.373354598274025e-05]\n",
      "Eval Acc@1: 87.43063263041066\n",
      "Eval Best Acc@1: 87.43063263041066\n",
      "Epoch:[58/80]\n",
      "Train Acc@1: 88.42178286242476 Mean loss: 0.2899326603628893 LR: [5.104686868360323e-05]\n",
      "Eval Acc@1: 87.18091009988902\n",
      "Eval Best Acc@1: 87.43063263041066\n",
      "Epoch:[59/80]\n",
      "Train Acc@1: 88.56052722858134 Mean loss: 0.290094612347605 LR: [4.849452524942307e-05]\n",
      "Eval Acc@1: 87.15316315205328\n",
      "Eval Best Acc@1: 87.43063263041066\n",
      "Epoch:[60/80]\n",
      "Train Acc@1: 88.48421782865071 Mean loss: 0.28889861333686695 LR: [4.606979898695191e-05]\n",
      "Eval Acc@1: 87.34739178690344\n",
      "Eval Best Acc@1: 87.43063263041066\n",
      "Epoch:[61/80]\n",
      "Train Acc@1: 88.44953173512681 Mean loss: 0.28900184785634014 LR: [4.376630903760431e-05]\n",
      "Eval Acc@1: 87.2364039955605\n",
      "Eval Best Acc@1: 87.43063263041066\n",
      "Epoch:[62/80]\n",
      "Train Acc@1: 88.54665279223032 Mean loss: 0.28818530108021423 LR: [4.157799358572409e-05]\n",
      "Eval Acc@1: 87.2364039955605\n",
      "Eval Best Acc@1: 87.43063263041066\n",
      "Epoch:[63/80]\n",
      "Train Acc@1: 88.51196670135276 Mean loss: 0.28732663271042097 LR: [3.9499093906437885e-05]\n",
      "Eval Acc@1: 87.34739178690344\n",
      "Eval Best Acc@1: 87.43063263041066\n",
      "Epoch:[64/80]\n",
      "Train Acc@1: 88.53971557405481 Mean loss: 0.28813681856984585 LR: [3.752413921111599e-05]\n",
      "Eval Acc@1: 87.20865704772476\n",
      "Eval Best Acc@1: 87.43063263041066\n",
      "Epoch:[65/80]\n",
      "Train Acc@1: 88.56746444146417 Mean loss: 0.28787060352289573 LR: [3.564793225056019e-05]\n",
      "Eval Acc@1: 87.20865704772476\n",
      "Eval Best Acc@1: 87.43063263041066\n",
      "Epoch:[66/80]\n",
      "Train Acc@1: 88.56052722858134 Mean loss: 0.28738452461177266 LR: [3.3865535638032174e-05]\n",
      "Eval Acc@1: 87.2364039955605\n",
      "Eval Best Acc@1: 87.43063263041066\n",
      "Epoch:[67/80]\n",
      "Train Acc@1: 88.5258411324111 Mean loss: 0.28647833004330114 LR: [3.2172258856130564e-05]\n",
      "Eval Acc@1: 87.40288568257492\n",
      "Eval Best Acc@1: 87.43063263041066\n",
      "Epoch:[68/80]\n",
      "Train Acc@1: 88.57440165963969 Mean loss: 0.28599908545745156 LR: [3.056364591332403e-05]\n",
      "Eval Acc@1: 87.43063263041066\n",
      "Eval Best Acc@1: 87.43063263041066\n",
      "Epoch:[69/80]\n",
      "Train Acc@1: 88.61602496869276 Mean loss: 0.2855192784187013 LR: [2.903546361765783e-05]\n",
      "Eval Acc@1: 87.26415094339623\n",
      "Eval Best Acc@1: 87.43063263041066\n",
      "Epoch:[70/80]\n",
      "Train Acc@1: 88.53277835323296 Mean loss: 0.2858111640784593 LR: [2.758369043677494e-05]\n",
      "Eval Acc@1: 87.37513873473918\n",
      "Eval Best Acc@1: 87.43063263041066\n",
      "Epoch:[71/80]\n",
      "Train Acc@1: 88.50502947788456 Mean loss: 0.2849824201084871 LR: [2.620450591493619e-05]\n",
      "Eval Acc@1: 87.29189789123197\n",
      "Eval Best Acc@1: 87.43063263041066\n",
      "Epoch:[72/80]\n",
      "Train Acc@1: 88.58133888310788 Mean loss: 0.2853736501615659 LR: [2.489428061918938e-05]\n",
      "Eval Acc@1: 87.3196448390677\n",
      "Eval Best Acc@1: 87.43063263041066\n",
      "Epoch:[73/80]\n",
      "Train Acc@1: 88.55359000775948 Mean loss: 0.2849678529047333 LR: [2.364956658822991e-05]\n",
      "Eval Acc@1: 87.34739178690344\n",
      "Eval Best Acc@1: 87.43063263041066\n",
      "Epoch:[74/80]\n",
      "Train Acc@1: 88.56746444146417 Mean loss: 0.28408644453877896 LR: [2.2467088258818413e-05]\n",
      "Eval Acc@1: 87.34739178690344\n",
      "Eval Best Acc@1: 87.43063263041066\n",
      "Epoch:[75/80]\n",
      "Train Acc@1: 88.67152271938953 Mean loss: 0.28344475688923776 LR: [2.134373384587749e-05]\n",
      "Eval Acc@1: 87.3196448390677\n",
      "Eval Best Acc@1: 87.43063263041066\n",
      "Epoch:[76/80]\n",
      "Train Acc@1: 88.67152271674318 Mean loss: 0.28375859571769174 LR: [2.0276547153583614e-05]\n",
      "Eval Acc@1: 87.40288568257492\n",
      "Eval Best Acc@1: 87.43063263041066\n",
      "Epoch:[77/80]\n",
      "Train Acc@1: 88.65764827774582 Mean loss: 0.28369737100020975 LR: [1.9262719795904432e-05]\n",
      "Eval Acc@1: 87.4583795782464\n",
      "Eval Best Acc@1: 87.4583795782464\n",
      "Epoch:[78/80]\n",
      "Train Acc@1: 88.59521331416622 Mean loss: 0.283546256412447 LR: [1.829958380610921e-05]\n",
      "Eval Acc@1: 87.2364039955605\n",
      "Eval Best Acc@1: 87.4583795782464\n",
      "Epoch:[79/80]\n",
      "Train Acc@1: 88.61602497398543 Mean loss: 0.28291802170925434 LR: [1.738460461580375e-05]\n",
      "Eval Acc@1: 87.37513873473918\n",
      "Eval Best Acc@1: 87.4583795782464\n",
      "Epoch:[80/80]\n",
      "Train Acc@1: 88.58827609863705 Mean loss: 0.2830694711775379 LR: [1.6515374385013564e-05]\n",
      "Eval Acc@1: 87.3196448390677\n",
      "Eval Best Acc@1: 87.4583795782464\n",
      "Best Train Acc@1: 88.67152271938953\n"
     ]
    }
   ],
   "source": [
    "!python main.py --config config/train_device.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_label(label判断)\n",
    "\n",
    "`BEST ACC@1：88.82`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters:\n",
      "{'work_dir': './work_dir/label', 'config': 'config/train_label.yaml', 'phase': 'train', 'save_score': False, 'seed': 1, 'feeder': 'feeder.Feeder_label', 'num_worker': 8, 'train_feeder_args': {'data_path': './data/train.pkl', 'snr': 0}, 'test_feeder_args': {'data_path': './data/test.pkl', 'snr': 0}, 'model': 'net.CNN', 'model_args': {'channels': 13, 'num_classes': 2}, 'weights': None, 'ignore_weights': [], 'base_lr': 0.001, 'step': [10, 50], 'device': 0, 'optimizer': 'Adam', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 80, 'weight_decay': 1e-05}\n",
      "\n",
      "Epoch:[1/80]\n",
      "Train Acc@1: 81.51231355696885 Mean loss: 0.47089475037249845 LR: [0.00095]\n",
      "Eval Acc@1: 81.2708102108768\n",
      "Eval Best Acc@1: 81.2708102108768\n",
      "Epoch:[2/80]\n",
      "Train Acc@1: 81.81755116198404 Mean loss: 0.45791645704117495 LR: [0.0009025]\n",
      "Eval Acc@1: 81.52053274139844\n",
      "Eval Best Acc@1: 81.52053274139844\n",
      "Epoch:[3/80]\n",
      "Train Acc@1: 83.35067637347943 Mean loss: 0.4349096530174787 LR: [0.000857375]\n",
      "Eval Acc@1: 84.07325194228635\n",
      "Eval Best Acc@1: 84.07325194228635\n",
      "Epoch:[4/80]\n",
      "Train Acc@1: 84.38432188163067 Mean loss: 0.4165718596329731 LR: [0.0008145062499999999]\n",
      "Eval Acc@1: 84.15649278579356\n",
      "Eval Best Acc@1: 84.15649278579356\n",
      "Epoch:[5/80]\n",
      "Train Acc@1: 84.66874783211932 Mean loss: 0.41065890941999655 LR: [0.0007737809374999998]\n",
      "Eval Acc@1: 84.73917869034406\n",
      "Eval Best Acc@1: 84.73917869034406\n",
      "Epoch:[6/80]\n",
      "Train Acc@1: 84.98785986290018 Mean loss: 0.4023784818375005 LR: [0.0007350918906249997]\n",
      "Eval Acc@1: 84.82241953385127\n",
      "Eval Best Acc@1: 84.82241953385127\n",
      "Epoch:[7/80]\n",
      "Train Acc@1: 85.20985084451655 Mean loss: 0.39854820705620586 LR: [0.0006983372960937497]\n",
      "Eval Acc@1: 84.82241953385127\n",
      "Eval Best Acc@1: 84.82241953385127\n",
      "Epoch:[8/80]\n",
      "Train Acc@1: 85.52896288323642 Mean loss: 0.3925992945390465 LR: [0.0006634204312890621]\n",
      "Eval Acc@1: 85.3496115427303\n",
      "Eval Best Acc@1: 85.3496115427303\n",
      "Epoch:[9/80]\n",
      "Train Acc@1: 85.79257717390587 Mean loss: 0.3878356276360233 LR: [0.000630249409724609]\n",
      "Eval Acc@1: 84.68368479467259\n",
      "Eval Best Acc@1: 85.3496115427303\n",
      "Epoch:[10/80]\n",
      "Train Acc@1: 86.08394033727735 Mean loss: 0.38405109170527585 LR: [0.0005987369392383785]\n",
      "Eval Acc@1: 85.68257491675915\n",
      "Eval Best Acc@1: 85.68257491675915\n",
      "Epoch:[11/80]\n",
      "Train Acc@1: 86.24349635531412 Mean loss: 0.37889836214284983 LR: [0.0005688000922764595]\n",
      "Eval Acc@1: 85.71032186459489\n",
      "Eval Best Acc@1: 85.71032186459489\n",
      "Epoch:[12/80]\n",
      "Train Acc@1: 86.47936177063518 Mean loss: 0.37631402909755707 LR: [0.0005403600876626365]\n",
      "Eval Acc@1: 85.87680355160933\n",
      "Eval Best Acc@1: 85.87680355160933\n",
      "Epoch:[13/80]\n",
      "Train Acc@1: 86.42386402523108 Mean loss: 0.3737244319863024 LR: [0.0005133420832795047]\n",
      "Eval Acc@1: 85.79356270810212\n",
      "Eval Best Acc@1: 85.87680355160933\n",
      "Epoch:[14/80]\n",
      "Train Acc@1: 86.65279223031564 Mean loss: 0.3719493558844634 LR: [0.00048767497911552944]\n",
      "Eval Acc@1: 86.07103218645949\n",
      "Eval Best Acc@1: 86.07103218645949\n",
      "Epoch:[15/80]\n",
      "Train Acc@1: 86.54873395768297 Mean loss: 0.36808262818155035 LR: [0.00046329123015975297]\n",
      "Eval Acc@1: 85.90455049944507\n",
      "Eval Best Acc@1: 86.07103218645949\n",
      "Epoch:[16/80]\n",
      "Train Acc@1: 86.87478320663934 Mean loss: 0.3628053264280336 LR: [0.0004401266686517653]\n",
      "Eval Acc@1: 86.40399556048834\n",
      "Eval Best Acc@1: 86.40399556048834\n",
      "Epoch:[17/80]\n",
      "Train Acc@1: 87.02740200914693 Mean loss: 0.3607013636326368 LR: [0.00041812033521917703]\n",
      "Eval Acc@1: 86.09877913429523\n",
      "Eval Best Acc@1: 86.40399556048834\n",
      "Epoch:[18/80]\n",
      "Train Acc@1: 87.13146027913326 Mean loss: 0.35659388070349146 LR: [0.00039721431845821814]\n",
      "Eval Acc@1: 86.32075471698113\n",
      "Eval Best Acc@1: 86.40399556048834\n",
      "Epoch:[19/80]\n",
      "Train Acc@1: 87.20083246618105 Mean loss: 0.3542911026593858 LR: [0.0003773536025353072]\n",
      "Eval Acc@1: 86.43174250832408\n",
      "Eval Best Acc@1: 86.43174250832408\n",
      "Epoch:[20/80]\n",
      "Train Acc@1: 87.35345126604231 Mean loss: 0.3525277396614573 LR: [0.0003584859224085418]\n",
      "Eval Acc@1: 86.54273029966704\n",
      "Eval Best Acc@1: 86.54273029966704\n",
      "Epoch:[21/80]\n",
      "Train Acc@1: 87.31876516987208 Mean loss: 0.3490910420639325 LR: [0.0003405616262881147]\n",
      "Eval Acc@1: 86.23751387347392\n",
      "Eval Best Acc@1: 86.54273029966704\n",
      "Epoch:[22/80]\n",
      "Train Acc@1: 87.5130072787864 Mean loss: 0.34618833456682946 LR: [0.00032353354497370894]\n",
      "Eval Acc@1: 86.93118756936737\n",
      "Eval Best Acc@1: 86.93118756936737\n",
      "Epoch:[23/80]\n",
      "Train Acc@1: 87.33263960886944 Mean loss: 0.34718208456725147 LR: [0.00030735686772502346]\n",
      "Eval Acc@1: 86.70921198668147\n",
      "Eval Best Acc@1: 86.93118756936737\n",
      "Epoch:[24/80]\n",
      "Train Acc@1: 87.5130072787864 Mean loss: 0.3448230709913558 LR: [0.00029198902433877225]\n",
      "Eval Acc@1: 86.59822419533852\n",
      "Eval Best Acc@1: 86.93118756936737\n",
      "Epoch:[25/80]\n",
      "Train Acc@1: 87.56850502683683 Mean loss: 0.3410566776859022 LR: [0.00027738957312183364]\n",
      "Eval Acc@1: 86.48723640399557\n",
      "Eval Best Acc@1: 86.93118756936737\n",
      "Epoch:[26/80]\n",
      "Train Acc@1: 87.65175164494298 Mean loss: 0.33720119917287233 LR: [0.0002635200944657419]\n",
      "Eval Acc@1: 86.87569367369589\n",
      "Eval Best Acc@1: 86.93118756936737\n",
      "Epoch:[27/80]\n",
      "Train Acc@1: 87.74887269940014 Mean loss: 0.33464672854911964 LR: [0.0002503440897424548]\n",
      "Eval Acc@1: 87.09766925638179\n",
      "Eval Best Acc@1: 87.09766925638179\n",
      "Epoch:[28/80]\n",
      "Train Acc@1: 87.88067984208853 Mean loss: 0.33228472415852334 LR: [0.00023782688525533205]\n",
      "Eval Acc@1: 87.04217536071032\n",
      "Eval Best Acc@1: 87.09766925638179\n",
      "Epoch:[29/80]\n",
      "Train Acc@1: 87.97086368101651 Mean loss: 0.3322091812053613 LR: [0.00022593554099256544]\n",
      "Eval Acc@1: 87.04217536071032\n",
      "Eval Best Acc@1: 87.09766925638179\n",
      "Epoch:[30/80]\n",
      "Train Acc@1: 87.83905653832814 Mean loss: 0.32892893874539736 LR: [0.00021463876394293716]\n",
      "Eval Acc@1: 86.93118756936737\n",
      "Eval Best Acc@1: 87.09766925638179\n",
      "Epoch:[31/80]\n",
      "Train Acc@1: 87.95005202384364 Mean loss: 0.32831778733339984 LR: [0.0002039068257457903]\n",
      "Eval Acc@1: 87.26415094339623\n",
      "Eval Best Acc@1: 87.26415094339623\n",
      "Epoch:[32/80]\n",
      "Train Acc@1: 87.99861255371856 Mean loss: 0.32639683697339705 LR: [0.00019371148445850077]\n",
      "Eval Acc@1: 87.29189789123197\n",
      "Eval Best Acc@1: 87.29189789123197\n",
      "Epoch:[33/80]\n",
      "Train Acc@1: 88.00554976924774 Mean loss: 0.3239582149987727 LR: [0.00018402591023557573]\n",
      "Eval Acc@1: 87.65260821309656\n",
      "Eval Best Acc@1: 87.65260821309656\n",
      "Epoch:[34/80]\n",
      "Train Acc@1: 88.19979187816206 Mean loss: 0.32200886856401917 LR: [0.00017482461472379692]\n",
      "Eval Acc@1: 87.01442841287458\n",
      "Eval Best Acc@1: 87.65260821309656\n",
      "Epoch:[35/80]\n",
      "Train Acc@1: 88.13735691722879 Mean loss: 0.3211795842621179 LR: [0.00016608338398760707]\n",
      "Eval Acc@1: 87.48612652608213\n",
      "Eval Best Acc@1: 87.65260821309656\n",
      "Epoch:[36/80]\n",
      "Train Acc@1: 88.1234824835241 Mean loss: 0.31924319432108805 LR: [0.0001577792147882267]\n",
      "Eval Acc@1: 87.62486126526082\n",
      "Eval Best Acc@1: 87.65260821309656\n",
      "Epoch:[37/80]\n",
      "Train Acc@1: 88.23447796903962 Mean loss: 0.31976750928216274 LR: [0.00014989025404881537]\n",
      "Eval Acc@1: 87.59711431742508\n",
      "Eval Best Acc@1: 87.65260821309656\n",
      "Epoch:[38/80]\n",
      "Train Acc@1: 88.11654526534859 Mean loss: 0.3183726005058373 LR: [0.00014239574134637458]\n",
      "Eval Acc@1: 87.34739178690344\n",
      "Eval Best Acc@1: 87.65260821309656\n",
      "Epoch:[39/80]\n",
      "Train Acc@1: 88.17204301075269 Mean loss: 0.3152671486666772 LR: [0.00013527595427905584]\n",
      "Eval Acc@1: 87.51387347391787\n",
      "Eval Best Acc@1: 87.65260821309656\n",
      "Epoch:[40/80]\n",
      "Train Acc@1: 88.31772458714576 Mean loss: 0.3142395535137801 LR: [0.00012851215656510304]\n",
      "Eval Acc@1: 87.20865704772476\n",
      "Eval Best Acc@1: 87.65260821309656\n",
      "Epoch:[41/80]\n",
      "Train Acc@1: 88.30385015344108 Mean loss: 0.3138983389445111 LR: [0.00012208654873684788]\n",
      "Eval Acc@1: 87.79134295227524\n",
      "Eval Best Acc@1: 87.79134295227524\n",
      "Epoch:[42/80]\n",
      "Train Acc@1: 88.26222684174166 Mean loss: 0.31323036492134615 LR: [0.00011598222130000548]\n",
      "Eval Acc@1: 87.51387347391787\n",
      "Eval Best Acc@1: 87.79134295227524\n",
      "Epoch:[43/80]\n",
      "Train Acc@1: 88.31078737161658 Mean loss: 0.3115014462212546 LR: [0.00011018311023500519]\n",
      "Eval Acc@1: 87.40288568257492\n",
      "Eval Best Acc@1: 87.79134295227524\n",
      "Epoch:[44/80]\n",
      "Train Acc@1: 88.42178286507111 Mean loss: 0.31002375523073483 LR: [0.00010467395472325493]\n",
      "Eval Acc@1: 87.51387347391787\n",
      "Eval Best Acc@1: 87.79134295227524\n",
      "Epoch:[45/80]\n",
      "Train Acc@1: 88.32466181061395 Mean loss: 0.30951773348899014 LR: [9.944025698709218e-05]\n",
      "Eval Acc@1: 87.59711431742508\n",
      "Eval Best Acc@1: 87.79134295227524\n",
      "Epoch:[46/80]\n",
      "Train Acc@1: 88.3870967715472 Mean loss: 0.309294335675978 LR: [9.446824413773756e-05]\n",
      "Eval Acc@1: 87.5416204217536\n",
      "Eval Best Acc@1: 87.79134295227524\n",
      "Epoch:[47/80]\n",
      "Train Acc@1: 88.49115504153355 Mean loss: 0.30834857064538296 LR: [8.974483193085068e-05]\n",
      "Eval Acc@1: 87.93007769145395\n",
      "Eval Best Acc@1: 87.93007769145395\n",
      "Epoch:[48/80]\n",
      "Train Acc@1: 88.50502947788456 Mean loss: 0.3068401272845479 LR: [8.525759033430814e-05]\n",
      "Eval Acc@1: 87.84683684794672\n",
      "Eval Best Acc@1: 87.93007769145395\n",
      "Epoch:[49/80]\n",
      "Train Acc@1: 88.51890391952827 Mean loss: 0.30569108651406995 LR: [8.099471081759274e-05]\n",
      "Eval Acc@1: 87.73584905660377\n",
      "Eval Best Acc@1: 87.93007769145395\n",
      "Epoch:[50/80]\n",
      "Train Acc@1: 88.48421782600437 Mean loss: 0.30644841439428583 LR: [7.69449752767131e-05]\n",
      "Eval Acc@1: 87.87458379578247\n",
      "Eval Best Acc@1: 87.93007769145395\n",
      "Epoch:[51/80]\n",
      "Train Acc@1: 88.61602497133909 Mean loss: 0.30461068352503057 LR: [7.309772651287744e-05]\n",
      "Eval Acc@1: 87.56936736958934\n",
      "Eval Best Acc@1: 87.93007769145395\n",
      "Epoch:[52/80]\n",
      "Train Acc@1: 88.62296219216094 Mean loss: 0.30402752051574994 LR: [6.944284018723356e-05]\n",
      "Eval Acc@1: 87.6803551609323\n",
      "Eval Best Acc@1: 87.93007769145395\n",
      "Epoch:[53/80]\n",
      "Train Acc@1: 88.42178286242476 Mean loss: 0.30418491719570834 LR: [6.597069817787189e-05]\n",
      "Eval Acc@1: 88.06881243063263\n",
      "Eval Best Acc@1: 88.06881243063263\n",
      "Epoch:[54/80]\n",
      "Train Acc@1: 88.51890391688192 Mean loss: 0.30323103360370196 LR: [6.267216326897829e-05]\n",
      "Eval Acc@1: 87.6803551609323\n",
      "Eval Best Acc@1: 88.06881243063263\n",
      "Epoch:[55/80]\n",
      "Train Acc@1: 88.58133888310788 Mean loss: 0.30275552640710257 LR: [5.953855510552937e-05]\n",
      "Eval Acc@1: 87.65260821309656\n",
      "Eval Best Acc@1: 88.06881243063263\n",
      "Epoch:[56/80]\n",
      "Train Acc@1: 88.59521331945889 Mean loss: 0.30199982245675233 LR: [5.65616273502529e-05]\n",
      "Eval Acc@1: 87.79134295227524\n",
      "Eval Best Acc@1: 88.06881243063263\n",
      "Epoch:[57/80]\n",
      "Train Acc@1: 88.69233436862338 Mean loss: 0.30117787882290054 LR: [5.373354598274025e-05]\n",
      "Eval Acc@1: 87.93007769145395\n",
      "Eval Best Acc@1: 88.06881243063263\n",
      "Epoch:[58/80]\n",
      "Train Acc@1: 88.65764828039217 Mean loss: 0.30059717760413096 LR: [5.104686868360323e-05]\n",
      "Eval Acc@1: 87.65260821309656\n",
      "Eval Best Acc@1: 88.06881243063263\n",
      "Epoch:[59/80]\n",
      "Train Acc@1: 88.68539715044787 Mean loss: 0.3002235083057817 LR: [4.849452524942307e-05]\n",
      "Eval Acc@1: 87.95782463928968\n",
      "Eval Best Acc@1: 88.06881243063263\n",
      "Epoch:[60/80]\n",
      "Train Acc@1: 88.65071106221666 Mean loss: 0.2999025875356345 LR: [4.606979898695191e-05]\n",
      "Eval Acc@1: 87.70810210876803\n",
      "Eval Best Acc@1: 88.06881243063263\n",
      "Epoch:[61/80]\n",
      "Train Acc@1: 88.60908775580992 Mean loss: 0.2985945793643462 LR: [4.376630903760431e-05]\n",
      "Eval Acc@1: 87.87458379578247\n",
      "Eval Best Acc@1: 88.06881243063263\n",
      "Epoch:[62/80]\n",
      "Train Acc@1: 88.62989941033645 Mean loss: 0.29949165353205354 LR: [4.157799358572409e-05]\n",
      "Eval Acc@1: 88.12430632630411\n",
      "Eval Best Acc@1: 88.12430632630411\n",
      "Epoch:[63/80]\n",
      "Train Acc@1: 88.74783211932015 Mean loss: 0.2978821423860778 LR: [3.9499093906437885e-05]\n",
      "Eval Acc@1: 87.93007769145395\n",
      "Eval Best Acc@1: 88.12430632630411\n",
      "Epoch:[64/80]\n",
      "Train Acc@1: 88.62989940769012 Mean loss: 0.29895933341663494 LR: [3.752413921111599e-05]\n",
      "Eval Acc@1: 88.01331853496116\n",
      "Eval Best Acc@1: 88.12430632630411\n",
      "Epoch:[65/80]\n",
      "Train Acc@1: 88.75476933484933 Mean loss: 0.2979261354930633 LR: [3.564793225056019e-05]\n",
      "Eval Acc@1: 87.93007769145395\n",
      "Eval Best Acc@1: 88.12430632630411\n",
      "Epoch:[66/80]\n",
      "Train Acc@1: 88.78251820755138 Mean loss: 0.29753451880100557 LR: [3.3865535638032174e-05]\n",
      "Eval Acc@1: 88.09655937846837\n",
      "Eval Best Acc@1: 88.12430632630411\n",
      "Epoch:[67/80]\n",
      "Train Acc@1: 88.76864376855401 Mean loss: 0.2969698342865547 LR: [3.2172258856130564e-05]\n",
      "Eval Acc@1: 88.01331853496116\n",
      "Eval Best Acc@1: 88.12430632630411\n",
      "Epoch:[68/80]\n",
      "Train Acc@1: 88.75476933749566 Mean loss: 0.29793762283778824 LR: [3.056364591332403e-05]\n",
      "Eval Acc@1: 88.09655937846837\n",
      "Eval Best Acc@1: 88.12430632630411\n",
      "Epoch:[69/80]\n",
      "Train Acc@1: 88.82414151925079 Mean loss: 0.2967143919220013 LR: [2.903546361765783e-05]\n",
      "Eval Acc@1: 87.95782463928968\n",
      "Eval Best Acc@1: 88.12430632630411\n",
      "Epoch:[70/80]\n",
      "Train Acc@1: 88.81026708025342 Mean loss: 0.29635530960770834 LR: [2.758369043677494e-05]\n",
      "Eval Acc@1: 88.06881243063263\n",
      "Eval Best Acc@1: 88.12430632630411\n",
      "Epoch:[71/80]\n",
      "Train Acc@1: 88.71314602314992 Mean loss: 0.295754608986652 LR: [2.620450591493619e-05]\n",
      "Eval Acc@1: 87.95782463928968\n",
      "Eval Best Acc@1: 88.12430632630411\n",
      "Epoch:[72/80]\n",
      "Train Acc@1: 88.8033298620779 Mean loss: 0.2959142732145512 LR: [2.489428061918938e-05]\n",
      "Eval Acc@1: 87.87458379578247\n",
      "Eval Best Acc@1: 88.12430632630411\n",
      "Epoch:[73/80]\n",
      "Train Acc@1: 88.80332986472425 Mean loss: 0.2959802630728325 LR: [2.364956658822991e-05]\n",
      "Eval Acc@1: 88.12430632630411\n",
      "Eval Best Acc@1: 88.12430632630411\n",
      "Epoch:[74/80]\n",
      "Train Acc@1: 88.76170655037849 Mean loss: 0.2949933041777231 LR: [2.2467088258818413e-05]\n",
      "Eval Acc@1: 87.95782463928968\n",
      "Eval Best Acc@1: 88.12430632630411\n",
      "Epoch:[75/80]\n",
      "Train Acc@1: 88.77558098672952 Mean loss: 0.29458089060751735 LR: [2.134373384587749e-05]\n",
      "Eval Acc@1: 88.01331853496116\n",
      "Eval Best Acc@1: 88.12430632630411\n",
      "Epoch:[76/80]\n",
      "Train Acc@1: 88.72702046214728 Mean loss: 0.2946125359925549 LR: [2.0276547153583614e-05]\n",
      "Eval Acc@1: 88.09655937846837\n",
      "Eval Best Acc@1: 88.12430632630411\n",
      "Epoch:[77/80]\n",
      "Train Acc@1: 88.81026707760708 Mean loss: 0.2947311458730065 LR: [1.9262719795904432e-05]\n",
      "Eval Acc@1: 87.84683684794672\n",
      "Eval Best Acc@1: 88.12430632630411\n",
      "Epoch:[78/80]\n",
      "Train Acc@1: 88.78945542308054 Mean loss: 0.29425890265708476 LR: [1.829958380610921e-05]\n",
      "Eval Acc@1: 88.17980022197558\n",
      "Eval Best Acc@1: 88.17980022197558\n",
      "Epoch:[79/80]\n",
      "Train Acc@1: 88.81026707760708 Mean loss: 0.2942250377572743 LR: [1.738460461580375e-05]\n",
      "Eval Acc@1: 88.01331853496116\n",
      "Eval Best Acc@1: 88.17980022197558\n",
      "Epoch:[80/80]\n",
      "Train Acc@1: 88.80332985943157 Mean loss: 0.2940367449042016 LR: [1.6515374385013564e-05]\n",
      "Eval Acc@1: 88.0410654827969\n",
      "Eval Best Acc@1: 88.17980022197558\n",
      "Best Train Acc@1: 88.82414151925079\n"
     ]
    }
   ],
   "source": [
    "!python main.py --config config/train_label.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_snr(snr无监督判断)\n",
    "\n",
    "best mse：61.24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters:\n",
      "{'work_dir': './work_dir/us_snr', 'config': 'config/us_train_snr.yaml', 'phase': 'train', 'save_score': False, 'seed': 1, 'feeder': 'feeder.Us_Feeder_snr', 'num_worker': 8, 'train_feeder_args': {'data_path': './data/train.pkl'}, 'test_feeder_args': {'data_path': './data/test.pkl'}, 'model': 'net.Us_CNN', 'model_args': {'channels': 13, 'num_classes': 3}, 'weights': None, 'ignore_weights': [], 'base_lr': 0.001, 'step': [10, 50], 'device': 0, 'optimizer': 'Adam', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 80, 'weight_decay': 1e-05}\n",
      "\n",
      "Epoch:[1/80]\n",
      "Train MSE: 62.84735278331251 Mean loss: 62.84687868377866 LR: [0.00095]\n",
      "Eval MSE: 61.577377852800815\n",
      "Eval Best MSE: 61.577377852800815\n",
      "Epoch:[2/80]\n",
      "Train MSE: 61.505526935049446 Mean loss: 61.50491733663886 LR: [0.0009025]\n",
      "Eval MSE: 61.542467086966994\n",
      "Eval Best MSE: 61.542467086966994\n",
      "Epoch:[3/80]\n",
      "Train MSE: 61.457828059589566 Mean loss: 61.45694557167369 LR: [0.000857375]\n",
      "Eval MSE: 61.4944236859806\n",
      "Eval Best MSE: 61.4944236859806\n",
      "Epoch:[4/80]\n",
      "Train MSE: 61.37635618464108 Mean loss: 61.37721083714412 LR: [0.0008145062499999999]\n",
      "Eval MSE: 61.35747022554692\n",
      "Eval Best MSE: 61.35747022554692\n",
      "Epoch:[5/80]\n",
      "Train MSE: 61.30117381697156 Mean loss: 61.301031518970014 LR: [0.0007737809374999998]\n",
      "Eval MSE: 61.35075054105194\n",
      "Eval Best MSE: 61.35075054105194\n",
      "Epoch:[6/80]\n",
      "Train MSE: 61.290578917186785 Mean loss: 61.287984910095936 LR: [0.0007350918906249997]\n",
      "Eval MSE: 61.34432110943443\n",
      "Eval Best MSE: 61.34432110943443\n",
      "Epoch:[7/80]\n",
      "Train MSE: 61.28864936612496 Mean loss: 61.29105174612011 LR: [0.0006983372960937497]\n",
      "Eval MSE: 61.34471894439573\n",
      "Eval Best MSE: 61.34432110943443\n",
      "Epoch:[8/80]\n",
      "Train MSE: 61.27759215881651 Mean loss: 61.28043634087376 LR: [0.0006634204312890621]\n",
      "Eval MSE: 61.318522121303836\n",
      "Eval Best MSE: 61.318522121303836\n",
      "Epoch:[9/80]\n",
      "Train MSE: 61.26167341918804 Mean loss: 61.26186256295831 LR: [0.000630249409724609]\n",
      "Eval MSE: 61.318168843361434\n",
      "Eval Best MSE: 61.318168843361434\n",
      "Epoch:[10/80]\n",
      "Train MSE: 61.26161682494101 Mean loss: 61.262469551267 LR: [0.0005987369392383785]\n",
      "Eval MSE: 61.31744810126245\n",
      "Eval Best MSE: 61.31744810126245\n",
      "Epoch:[11/80]\n",
      "Train MSE: 61.26144903709825 Mean loss: 61.2611748622014 LR: [0.0005688000922764595]\n",
      "Eval MSE: 61.31849658555381\n",
      "Eval Best MSE: 61.31744810126245\n",
      "Epoch:[12/80]\n",
      "Train MSE: 61.261447921049005 Mean loss: 61.25973204889241 LR: [0.0005403600876626365]\n",
      "Eval MSE: 61.31715633831243\n",
      "Eval Best MSE: 61.31715633831243\n",
      "Epoch:[13/80]\n",
      "Train MSE: 61.26123758034426 Mean loss: 61.26380849307811 LR: [0.0005133420832795047]\n",
      "Eval MSE: 61.31791359029609\n",
      "Eval Best MSE: 61.31715633831243\n",
      "Epoch:[14/80]\n",
      "Train MSE: 61.261232793470356 Mean loss: 61.2645453842434 LR: [0.00048767497911552944]\n",
      "Eval MSE: 61.31748190712938\n",
      "Eval Best MSE: 61.31715633831243\n",
      "Epoch:[15/80]\n",
      "Train MSE: 61.26121966154372 Mean loss: 61.261662906443576 LR: [0.00046329123015975297]\n",
      "Eval MSE: 61.31704954372439\n",
      "Eval Best MSE: 61.31704954372439\n",
      "Epoch:[16/80]\n",
      "Train MSE: 61.26113919176412 Mean loss: 61.26185317857731 LR: [0.0004401266686517653]\n",
      "Eval MSE: 61.31719375424062\n",
      "Eval Best MSE: 61.31704954372439\n",
      "Epoch:[17/80]\n",
      "Train MSE: 61.261097431921634 Mean loss: 61.26019293881027 LR: [0.00041812033521917703]\n",
      "Eval MSE: 61.317055564256584\n",
      "Eval Best MSE: 61.31704954372439\n",
      "Epoch:[18/80]\n",
      "Train MSE: 61.2610426783796 Mean loss: 61.260433552533215 LR: [0.00039721431845821814]\n",
      "Eval MSE: 61.317245855977085\n",
      "Eval Best MSE: 61.31704954372439\n",
      "Epoch:[19/80]\n",
      "Train MSE: 61.26106954930297 Mean loss: 61.26231500524035 LR: [0.0003773536025353072]\n",
      "Eval MSE: 61.31703529541377\n",
      "Eval Best MSE: 61.31703529541377\n",
      "Epoch:[20/80]\n",
      "Train MSE: 61.26098861764905 Mean loss: 61.259409430464345 LR: [0.0003584859224085418]\n",
      "Eval MSE: 61.317067139597675\n",
      "Eval Best MSE: 61.31703529541377\n",
      "Epoch:[21/80]\n",
      "Train MSE: 61.26103725920717 Mean loss: 61.262330551824626 LR: [0.0003405616262881147]\n",
      "Eval MSE: 61.31692942944977\n",
      "Eval Best MSE: 61.31692942944977\n",
      "Epoch:[22/80]\n",
      "Train MSE: 61.260943615071305 Mean loss: 61.26125942884818 LR: [0.00032353354497370894]\n",
      "Eval MSE: 61.317282188040124\n",
      "Eval Best MSE: 61.31692942944977\n",
      "Epoch:[23/80]\n",
      "Train MSE: 61.260923222032275 Mean loss: 61.25991112522825 LR: [0.00030735686772502346]\n",
      "Eval MSE: 61.316892196988334\n",
      "Eval Best MSE: 61.316892196988334\n",
      "Epoch:[24/80]\n",
      "Train MSE: 61.26090196125879 Mean loss: 61.262779687283306 LR: [0.00029198902433877225]\n",
      "Eval MSE: 61.31682848039487\n",
      "Eval Best MSE: 61.31682848039487\n",
      "Epoch:[25/80]\n",
      "Train MSE: 61.26086540120725 Mean loss: 61.26132232620871 LR: [0.00027738957312183364]\n",
      "Eval MSE: 61.31703152728883\n",
      "Eval Best MSE: 61.31682848039487\n",
      "Epoch:[26/80]\n",
      "Train MSE: 61.26086355256323 Mean loss: 61.256711852621045 LR: [0.0002635200944657419]\n",
      "Eval MSE: 61.31681452563106\n",
      "Eval Best MSE: 61.31681452563106\n",
      "Epoch:[27/80]\n",
      "Train MSE: 61.26085072902327 Mean loss: 61.263851024695406 LR: [0.0002503440897424548]\n",
      "Eval MSE: 61.316904856194576\n",
      "Eval Best MSE: 61.31681452563106\n",
      "Epoch:[28/80]\n",
      "Train MSE: 61.26083857544806 Mean loss: 61.2592069693571 LR: [0.00023782688525533205]\n",
      "Eval MSE: 61.31730612904065\n",
      "Eval Best MSE: 61.31681452563106\n",
      "Epoch:[29/80]\n",
      "Train MSE: 61.26087383535339 Mean loss: 61.261201587654426 LR: [0.00022593554099256544]\n",
      "Eval MSE: 61.316709780225565\n",
      "Eval Best MSE: 61.316709780225565\n",
      "Epoch:[30/80]\n",
      "Train MSE: 61.26080723221226 Mean loss: 61.260182375033224 LR: [0.00021463876394293716]\n",
      "Eval MSE: 61.317076250839094\n",
      "Eval Best MSE: 61.316709780225565\n",
      "Epoch:[31/80]\n",
      "Train MSE: 61.26074677078224 Mean loss: 61.262320213769314 LR: [0.0002039068257457903]\n",
      "Eval MSE: 61.316772356502575\n",
      "Eval Best MSE: 61.316709780225565\n",
      "Epoch:[32/80]\n",
      "Train MSE: 61.260728215625456 Mean loss: 61.26033582630947 LR: [0.00019371148445850077]\n",
      "Eval MSE: 61.316975112672296\n",
      "Eval Best MSE: 61.316709780225565\n",
      "Epoch:[33/80]\n",
      "Train MSE: 61.26070495139713 Mean loss: 61.26039613351314 LR: [0.00018402591023557573]\n",
      "Eval MSE: 61.317022957979994\n",
      "Eval Best MSE: 61.316709780225565\n",
      "Epoch:[34/80]\n",
      "Train MSE: 61.260705151107494 Mean loss: 61.262307477420606 LR: [0.00017482461472379692]\n",
      "Eval MSE: 61.31681477119426\n",
      "Eval Best MSE: 61.316709780225565\n",
      "Epoch:[35/80]\n",
      "Train MSE: 61.26069376602905 Mean loss: 61.262376587771804 LR: [0.00016608338398760707]\n",
      "Eval MSE: 61.31666067040853\n",
      "Eval Best MSE: 61.31666067040853\n",
      "Epoch:[36/80]\n",
      "Train MSE: 61.26066116366528 Mean loss: 61.25993518716485 LR: [0.0001577792147882267]\n",
      "Eval MSE: 61.31705776585767\n",
      "Eval Best MSE: 61.31666067040853\n",
      "Epoch:[37/80]\n",
      "Train MSE: 61.26066950942371 Mean loss: 61.25664840224226 LR: [0.00014989025404881537]\n",
      "Eval MSE: 61.31700750161134\n",
      "Eval Best MSE: 61.31666067040853\n",
      "Epoch:[38/80]\n",
      "Train MSE: 61.260624693942106 Mean loss: 61.262071107266216 LR: [0.00014239574134637458]\n",
      "Eval MSE: 61.3166789549878\n",
      "Eval Best MSE: 61.31666067040853\n",
      "Epoch:[39/80]\n",
      "Train MSE: 61.26061119726179 Mean loss: 61.262271898032644 LR: [0.00013527595427905584]\n",
      "Eval MSE: 61.31703148212779\n",
      "Eval Best MSE: 61.31666067040853\n",
      "Epoch:[40/80]\n",
      "Train MSE: 61.26062516313796 Mean loss: 61.260422142299674 LR: [0.00012851215656510304]\n",
      "Eval MSE: 61.316914311788985\n",
      "Eval Best MSE: 61.31666067040853\n",
      "Epoch:[41/80]\n",
      "Train MSE: 61.26060863587054 Mean loss: 61.259904861450195 LR: [0.00012208654873684788]\n",
      "Eval MSE: 61.31674947678668\n",
      "Eval Best MSE: 61.31666067040853\n",
      "Epoch:[42/80]\n",
      "Train MSE: 61.260601745774835 Mean loss: 61.26149286462005 LR: [0.00011598222130000548]\n",
      "Eval MSE: 61.31666800907882\n",
      "Eval Best MSE: 61.31666067040853\n",
      "Epoch:[43/80]\n",
      "Train MSE: 61.26057559536129 Mean loss: 61.25992500711475 LR: [0.00011018311023500519]\n",
      "Eval MSE: 61.31667376711243\n",
      "Eval Best MSE: 61.31666067040853\n",
      "Epoch:[44/80]\n",
      "Train MSE: 61.260564536311776 Mean loss: 61.264001682665224 LR: [0.00010467395472325493]\n",
      "Eval MSE: 61.316647031772064\n",
      "Eval Best MSE: 61.316647031772064\n",
      "Epoch:[45/80]\n",
      "Train MSE: 61.26054810775279 Mean loss: 61.25970699378019 LR: [9.944025698709218e-05]\n",
      "Eval MSE: 61.31702952044477\n",
      "Eval Best MSE: 61.316647031772064\n",
      "Epoch:[46/80]\n",
      "Train MSE: 61.2603308844503 Mean loss: 61.26086970899232 LR: [9.446824413773756e-05]\n",
      "Eval MSE: 61.31419200099842\n",
      "Eval Best MSE: 61.31419200099842\n",
      "Epoch:[47/80]\n",
      "Train MSE: 61.25652067122921 Mean loss: 61.255748630275384 LR: [8.974483193085068e-05]\n",
      "Eval MSE: 61.31229122612064\n",
      "Eval Best MSE: 61.31229122612064\n",
      "Epoch:[48/80]\n",
      "Train MSE: 61.25604136847722 Mean loss: 61.257973558098605 LR: [8.525759033430814e-05]\n",
      "Eval MSE: 61.31207168415393\n",
      "Eval Best MSE: 61.31207168415393\n",
      "Epoch:[49/80]\n",
      "Train MSE: 61.255906678833895 Mean loss: 61.25561448949328 LR: [8.099471081759274e-05]\n",
      "Eval MSE: 61.31192924903139\n",
      "Eval Best MSE: 61.31192924903139\n",
      "Epoch:[50/80]\n",
      "Train MSE: 61.255805305889375 Mean loss: 61.25615564041589 LR: [7.69449752767131e-05]\n",
      "Eval MSE: 61.311844780936404\n",
      "Eval Best MSE: 61.311844780936404\n",
      "Epoch:[51/80]\n",
      "Train MSE: 61.255738212646314 Mean loss: 61.2550604498598 LR: [7.309772651287744e-05]\n",
      "Eval MSE: 61.31175006975124\n",
      "Eval Best MSE: 61.31175006975124\n",
      "Epoch:[52/80]\n",
      "Train MSE: 61.25565651178994 Mean loss: 61.25703056042011 LR: [6.944284018723356e-05]\n",
      "Eval MSE: 61.311668147610334\n",
      "Eval Best MSE: 61.311668147610334\n",
      "Epoch:[53/80]\n",
      "Train MSE: 61.25553506371988 Mean loss: 61.258718851755354 LR: [6.597069817787189e-05]\n",
      "Eval MSE: 61.311511043614914\n",
      "Eval Best MSE: 61.311511043614914\n",
      "Epoch:[54/80]\n",
      "Train MSE: 61.25535855142763 Mean loss: 61.255665767827686 LR: [6.267216326897829e-05]\n",
      "Eval MSE: 61.31145378222873\n",
      "Eval Best MSE: 61.31145378222873\n",
      "Epoch:[55/80]\n",
      "Train MSE: 61.25507972083046 Mean loss: 61.25382945946688 LR: [5.953855510552937e-05]\n",
      "Eval MSE: 61.31092675844476\n",
      "Eval Best MSE: 61.31092675844476\n",
      "Epoch:[56/80]\n",
      "Train MSE: 61.25419305966126 Mean loss: 61.25600782653989 LR: [5.65616273502529e-05]\n",
      "Eval MSE: 61.308831991463116\n",
      "Eval Best MSE: 61.308831991463116\n",
      "Epoch:[57/80]\n",
      "Train MSE: 61.250490345570626 Mean loss: 61.25273154896392 LR: [5.373354598274025e-05]\n",
      "Eval MSE: 61.30533181549309\n",
      "Eval Best MSE: 61.30533181549309\n",
      "Epoch:[58/80]\n",
      "Train MSE: 61.24893046818051 Mean loss: 61.245853520004005 LR: [5.104686868360323e-05]\n",
      "Eval MSE: 61.30462460477309\n",
      "Eval Best MSE: 61.30462460477309\n",
      "Epoch:[59/80]\n",
      "Train MSE: 61.24837057259417 Mean loss: 61.24485086971486 LR: [4.849452524942307e-05]\n",
      "Eval MSE: 61.3041843635878\n",
      "Eval Best MSE: 61.3041843635878\n",
      "Epoch:[60/80]\n",
      "Train MSE: 61.24807161050445 Mean loss: 61.25006329801661 LR: [4.606979898695191e-05]\n",
      "Eval MSE: 61.303972699401385\n",
      "Eval Best MSE: 61.303972699401385\n",
      "Epoch:[61/80]\n",
      "Train MSE: 61.247871294483616 Mean loss: 61.24795133263402 LR: [4.376630903760431e-05]\n",
      "Eval MSE: 61.303815852259426\n",
      "Eval Best MSE: 61.303815852259426\n",
      "Epoch:[62/80]\n",
      "Train MSE: 61.24775383929763 Mean loss: 61.24724020196136 LR: [4.157799358572409e-05]\n",
      "Eval MSE: 61.30368894406967\n",
      "Eval Best MSE: 61.30368894406967\n",
      "Epoch:[63/80]\n",
      "Train MSE: 61.24765555771779 Mean loss: 61.249208766327804 LR: [3.9499093906437885e-05]\n",
      "Eval MSE: 61.30370434680957\n",
      "Eval Best MSE: 61.30368894406967\n",
      "Epoch:[64/80]\n",
      "Train MSE: 61.247591629142995 Mean loss: 61.24757033692309 LR: [3.752413921111599e-05]\n",
      "Eval MSE: 61.30360747071667\n",
      "Eval Best MSE: 61.30360747071667\n",
      "Epoch:[65/80]\n",
      "Train MSE: 61.24752809055032 Mean loss: 61.24541839057877 LR: [3.564793225056019e-05]\n",
      "Eval MSE: 61.30352542438288\n",
      "Eval Best MSE: 61.30352542438288\n",
      "Epoch:[66/80]\n",
      "Train MSE: 61.247485569797234 Mean loss: 61.24882269187792 LR: [3.3865535638032174e-05]\n",
      "Eval MSE: 61.30346022311996\n",
      "Eval Best MSE: 61.30346022311996\n",
      "Epoch:[67/80]\n",
      "Train MSE: 61.24743307199433 Mean loss: 61.24861801305466 LR: [3.2172258856130564e-05]\n",
      "Eval MSE: 61.303460527957036\n",
      "Eval Best MSE: 61.30346022311996\n",
      "Epoch:[68/80]\n",
      "Train MSE: 61.247407995376825 Mean loss: 61.24678581282937 LR: [3.056364591332403e-05]\n",
      "Eval MSE: 61.30349545720503\n",
      "Eval Best MSE: 61.30346022311996\n",
      "Epoch:[69/80]\n",
      "Train MSE: 61.24740647434954 Mean loss: 61.247317635801416 LR: [2.903546361765783e-05]\n",
      "Eval MSE: 61.3034820443738\n",
      "Eval Best MSE: 61.30346022311996\n",
      "Epoch:[70/80]\n",
      "Train MSE: 61.247375949449875 Mean loss: 61.24825196576542 LR: [2.758369043677494e-05]\n",
      "Eval MSE: 61.30343982161657\n",
      "Eval Best MSE: 61.30343982161657\n",
      "Epoch:[71/80]\n",
      "Train MSE: 61.24735497959722 Mean loss: 61.245306680893755 LR: [2.620450591493619e-05]\n",
      "Eval MSE: 61.30343353576321\n",
      "Eval Best MSE: 61.30343353576321\n",
      "Epoch:[72/80]\n",
      "Train MSE: 61.247340017815574 Mean loss: 61.24708681840163 LR: [2.489428061918938e-05]\n",
      "Eval MSE: 61.303371594563444\n",
      "Eval Best MSE: 61.303371594563444\n",
      "Epoch:[73/80]\n",
      "Train MSE: 61.24733384796506 Mean loss: 61.247684783484104 LR: [2.364956658822991e-05]\n",
      "Eval MSE: 61.30336011236701\n",
      "Eval Best MSE: 61.30336011236701\n",
      "Epoch:[74/80]\n",
      "Train MSE: 61.24732555522162 Mean loss: 61.24871505647016 LR: [2.2467088258818413e-05]\n",
      "Eval MSE: 61.303441628058486\n",
      "Eval Best MSE: 61.30336011236701\n",
      "Epoch:[75/80]\n",
      "Train MSE: 61.24732127379842 Mean loss: 61.24644088180813 LR: [2.134373384587749e-05]\n",
      "Eval MSE: 61.303384270705074\n",
      "Eval Best MSE: 61.30336011236701\n",
      "Epoch:[76/80]\n",
      "Train MSE: 61.247301212257426 Mean loss: 61.24740802042583 LR: [2.0276547153583614e-05]\n",
      "Eval MSE: 61.3033382149039\n",
      "Eval Best MSE: 61.3033382149039\n",
      "Epoch:[77/80]\n",
      "Train MSE: 61.24729605692496 Mean loss: 61.24719096640863 LR: [1.9262719795904432e-05]\n",
      "Eval MSE: 61.3033213726556\n",
      "Eval Best MSE: 61.3033213726556\n",
      "Epoch:[78/80]\n",
      "Train MSE: 61.247289157037805 Mean loss: 61.24752224126511 LR: [1.829958380610921e-05]\n",
      "Eval MSE: 61.30339863756344\n",
      "Eval Best MSE: 61.3033213726556\n",
      "Epoch:[79/80]\n",
      "Train MSE: 61.247282432691115 Mean loss: 61.246452404902534 LR: [1.738460461580375e-05]\n",
      "Eval MSE: 61.30332917987176\n",
      "Eval Best MSE: 61.3033213726556\n",
      "Epoch:[80/80]\n",
      "Train MSE: 61.24727419005169 Mean loss: 61.24727883987878 LR: [1.6515374385013564e-05]\n",
      "Eval MSE: 61.30340844597853\n",
      "Eval Best MSE: 61.3033213726556\n",
      "Best Train MSE: 61.24727419005169\n"
     ]
    }
   ],
   "source": [
    "!python us_main.py --config config/us_train_snr.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_device(device无监督判断)\n",
    "\n",
    "best mse：41.98"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters:\n",
      "{'work_dir': './work_dir/us_device', 'config': 'config/us_train_device.yaml', 'phase': 'train', 'save_score': False, 'seed': 1, 'feeder': 'feeder.Us_Feeder_device', 'num_worker': 8, 'train_feeder_args': {'data_path': './data/train.pkl', 'snr': 0}, 'test_feeder_args': {'data_path': './data/test.pkl', 'snr': 0}, 'model': 'net.Us_CNN', 'model_args': {'channels': 13, 'num_classes': 4}, 'weights': None, 'ignore_weights': [], 'base_lr': 0.001, 'step': [10, 50], 'device': 0, 'optimizer': 'Adam', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 80, 'weight_decay': 1e-05}\n",
      "\n",
      "Epoch:[1/80]\n",
      "Train MSE: 43.244207212704154 Mean loss: 43.246308520831896 LR: [0.00095]\n",
      "Eval MSE: 41.96519481222849\n",
      "Eval Best MSE: 41.96519481222849\n",
      "Epoch:[2/80]\n",
      "Train MSE: 42.1242630256285 Mean loss: 42.11351062133249 LR: [0.0009025]\n",
      "Eval MSE: 41.96457368128837\n",
      "Eval Best MSE: 41.96457368128837\n",
      "Epoch:[3/80]\n",
      "Train MSE: 42.08172354061406 Mean loss: 42.086075723698706 LR: [0.000857375]\n",
      "Eval MSE: 41.89122369154444\n",
      "Eval Best MSE: 41.89122369154444\n",
      "Epoch:[4/80]\n",
      "Train MSE: 42.04156850972938 Mean loss: 42.048132466003956 LR: [0.0008145062499999999]\n",
      "Eval MSE: 41.88155967890224\n",
      "Eval Best MSE: 41.88155967890224\n",
      "Epoch:[5/80]\n",
      "Train MSE: 42.03751479594442 Mean loss: 42.04114318104972 LR: [0.0007737809374999998]\n",
      "Eval MSE: 41.880573285406626\n",
      "Eval Best MSE: 41.880573285406626\n",
      "Epoch:[6/80]\n",
      "Train MSE: 42.03622622217026 Mean loss: 42.04716196313368 LR: [0.0007350918906249997]\n",
      "Eval MSE: 41.8810988202873\n",
      "Eval Best MSE: 41.880573285406626\n",
      "Epoch:[7/80]\n",
      "Train MSE: 42.0361918605205 Mean loss: 42.044669919309364 LR: [0.0006983372960937497]\n",
      "Eval MSE: 41.88073553070509\n",
      "Eval Best MSE: 41.880573285406626\n",
      "Epoch:[8/80]\n",
      "Train MSE: 42.03634903319296 Mean loss: 42.031424277651624 LR: [0.0006634204312890621]\n",
      "Eval MSE: 41.87922736198603\n",
      "Eval Best MSE: 41.87922736198603\n",
      "Epoch:[9/80]\n",
      "Train MSE: 42.03573916088241 Mean loss: 42.032123633190594 LR: [0.000630249409724609]\n",
      "Eval MSE: 41.87881748737161\n",
      "Eval Best MSE: 41.87881748737161\n",
      "Epoch:[10/80]\n",
      "Train MSE: 42.03542825286685 Mean loss: 42.03736551673011 LR: [0.0005987369392383785]\n",
      "Eval MSE: 41.87825521538975\n",
      "Eval Best MSE: 41.87825521538975\n",
      "Epoch:[11/80]\n",
      "Train MSE: 42.03540637717246 Mean loss: 42.03935817279647 LR: [0.0005688000922764595]\n",
      "Eval MSE: 41.882958271394955\n",
      "Eval Best MSE: 41.87825521538975\n",
      "Epoch:[12/80]\n",
      "Train MSE: 42.03558101382803 Mean loss: 42.03183812166737 LR: [0.0005403600876626365]\n",
      "Eval MSE: 41.87964454422251\n",
      "Eval Best MSE: 41.87825521538975\n",
      "Epoch:[13/80]\n",
      "Train MSE: 42.03533531001075 Mean loss: 42.02463588883391 LR: [0.0005133420832795047]\n",
      "Eval MSE: 41.878866227432574\n",
      "Eval Best MSE: 41.87825521538975\n",
      "Epoch:[14/80]\n",
      "Train MSE: 42.0352628963919 Mean loss: 42.03508073249749 LR: [0.00048767497911552944]\n",
      "Eval MSE: 41.87861373765884\n",
      "Eval Best MSE: 41.87825521538975\n",
      "Epoch:[15/80]\n",
      "Train MSE: 42.035200032880226 Mean loss: 42.023600198526296 LR: [0.00046329123015975297]\n",
      "Eval MSE: 41.87835844507757\n",
      "Eval Best MSE: 41.87825521538975\n",
      "Epoch:[16/80]\n",
      "Train MSE: 42.03523939399309 Mean loss: 42.047174386218586 LR: [0.0004401266686517653]\n",
      "Eval MSE: 41.878742061365195\n",
      "Eval Best MSE: 41.87825521538975\n",
      "Epoch:[17/80]\n",
      "Train MSE: 42.035009897148036 Mean loss: 42.03488466380972 LR: [0.00041812033521917703]\n",
      "Eval MSE: 41.87934804359631\n",
      "Eval Best MSE: 41.87825521538975\n",
      "Epoch:[18/80]\n",
      "Train MSE: 42.03472909864518 Mean loss: 42.036762811441335 LR: [0.00039721431845821814]\n",
      "Eval MSE: 41.87865373905703\n",
      "Eval Best MSE: 41.87825521538975\n",
      "Epoch:[19/80]\n",
      "Train MSE: 42.03485741087682 Mean loss: 42.032095444940886 LR: [0.0003773536025353072]\n",
      "Eval MSE: 41.87893916817008\n",
      "Eval Best MSE: 41.87825521538975\n",
      "Epoch:[20/80]\n",
      "Train MSE: 42.03483790868361 Mean loss: 42.02755951670419 LR: [0.0003584859224085418]\n",
      "Eval MSE: 41.87787364405083\n",
      "Eval Best MSE: 41.87787364405083\n",
      "Epoch:[21/80]\n",
      "Train MSE: 42.03488810284866 Mean loss: 42.035906681972264 LR: [0.0003405616262881147]\n",
      "Eval MSE: 41.87862030859131\n",
      "Eval Best MSE: 41.87787364405083\n",
      "Epoch:[22/80]\n",
      "Train MSE: 42.034936753668966 Mean loss: 42.02761982605521 LR: [0.00032353354497370894]\n",
      "Eval MSE: 41.87839332351938\n",
      "Eval Best MSE: 41.87787364405083\n",
      "Epoch:[23/80]\n",
      "Train MSE: 42.03473699373212 Mean loss: 42.025802224083286 LR: [0.00030735686772502346]\n",
      "Eval MSE: 41.8782844543457\n",
      "Eval Best MSE: 41.87787364405083\n",
      "Epoch:[24/80]\n",
      "Train MSE: 42.034832931185115 Mean loss: 42.03750114103334 LR: [0.00029198902433877225]\n",
      "Eval MSE: 41.88052514231827\n",
      "Eval Best MSE: 41.87787364405083\n",
      "Epoch:[25/80]\n",
      "Train MSE: 42.03458014047274 Mean loss: 42.043839783795114 LR: [0.00027738957312183364]\n",
      "Eval MSE: 41.87845084881545\n",
      "Eval Best MSE: 41.87787364405083\n",
      "Epoch:[26/80]\n",
      "Train MSE: 42.03437092305057 Mean loss: 42.0476235921404 LR: [0.0002635200944657419]\n",
      "Eval MSE: 41.87757397650614\n",
      "Eval Best MSE: 41.87757397650614\n",
      "Epoch:[27/80]\n",
      "Train MSE: 42.034510679374 Mean loss: 42.04324060625735 LR: [0.0002503440897424548]\n",
      "Eval MSE: 41.87758240186414\n",
      "Eval Best MSE: 41.87757397650614\n",
      "Epoch:[28/80]\n",
      "Train MSE: 42.034302617343315 Mean loss: 42.03126495496362 LR: [0.00023782688525533205]\n",
      "Eval MSE: 41.87759186874881\n",
      "Eval Best MSE: 41.87757397650614\n",
      "Epoch:[29/80]\n",
      "Train MSE: 42.03421622920359 Mean loss: 42.026712366964965 LR: [0.00022593554099256544]\n",
      "Eval MSE: 41.8775214640864\n",
      "Eval Best MSE: 41.8775214640864\n",
      "Epoch:[30/80]\n",
      "Train MSE: 42.033938475842696 Mean loss: 42.04417611856376 LR: [0.00021463876394293716]\n",
      "Eval MSE: 41.877345590030444\n",
      "Eval Best MSE: 41.877345590030444\n",
      "Epoch:[31/80]\n",
      "Train MSE: 42.032729285878936 Mean loss: 42.034644574190665 LR: [0.0002039068257457903]\n",
      "Eval MSE: 41.8737806305372\n",
      "Eval Best MSE: 41.8737806305372\n",
      "Epoch:[32/80]\n",
      "Train MSE: 42.0288381642035 Mean loss: 42.036176580243406 LR: [0.00019371148445850077]\n",
      "Eval MSE: 41.87096468960405\n",
      "Eval Best MSE: 41.87096468960405\n",
      "Epoch:[33/80]\n",
      "Train MSE: 42.02679846317372 Mean loss: 42.03211684775563 LR: [0.00018402591023557573]\n",
      "Eval MSE: 41.870723872549924\n",
      "Eval Best MSE: 41.870723872549924\n",
      "Epoch:[34/80]\n",
      "Train MSE: 42.02570020428888 Mean loss: 42.028164888905216 LR: [0.00017482461472379692]\n",
      "Eval MSE: 41.86869876366212\n",
      "Eval Best MSE: 41.86869876366212\n",
      "Epoch:[35/80]\n",
      "Train MSE: 42.025242321002494 Mean loss: 42.02438550290808 LR: [0.00016608338398760707]\n",
      "Eval MSE: 41.86844931802527\n",
      "Eval Best MSE: 41.86844931802527\n",
      "Epoch:[36/80]\n",
      "Train MSE: 42.02494037084351 Mean loss: 42.01741586533268 LR: [0.0001577792147882267]\n",
      "Eval MSE: 41.869171239956636\n",
      "Eval Best MSE: 41.86844931802527\n",
      "Epoch:[37/80]\n",
      "Train MSE: 42.024884103331104 Mean loss: 42.045991863824625 LR: [0.00014989025404881537]\n",
      "Eval MSE: 41.867721053789246\n",
      "Eval Best MSE: 41.867721053789246\n",
      "Epoch:[38/80]\n",
      "Train MSE: 42.02451533788283 Mean loss: 42.030880463861784 LR: [0.00014239574134637458]\n",
      "Eval MSE: 41.868426074198425\n",
      "Eval Best MSE: 41.867721053789246\n",
      "Epoch:[39/80]\n",
      "Train MSE: 42.02438197061497 Mean loss: 42.017740688492765 LR: [0.00013527595427905584]\n",
      "Eval MSE: 41.86769208156573\n",
      "Eval Best MSE: 41.86769208156573\n",
      "Epoch:[40/80]\n",
      "Train MSE: 42.0243437844765 Mean loss: 42.01572686592034 LR: [0.00012851215656510304]\n",
      "Eval MSE: 41.86744803831924\n",
      "Eval Best MSE: 41.86744803831924\n",
      "Epoch:[41/80]\n",
      "Train MSE: 42.0242915827989 Mean loss: 42.041130876119155 LR: [0.00012208654873684788]\n",
      "Eval MSE: 41.86797285767956\n",
      "Eval Best MSE: 41.86744803831924\n",
      "Epoch:[42/80]\n",
      "Train MSE: 42.02414182834314 Mean loss: 42.02755921287874 LR: [0.00011598222130000548]\n",
      "Eval MSE: 41.86779052700504\n",
      "Eval Best MSE: 41.86744803831924\n",
      "Epoch:[43/80]\n",
      "Train MSE: 42.02409314497287 Mean loss: 42.019607695858035 LR: [0.00011018311023500519]\n",
      "Eval MSE: 41.86728084365218\n",
      "Eval Best MSE: 41.86728084365218\n",
      "Epoch:[44/80]\n",
      "Train MSE: 42.02409802402757 Mean loss: 42.03012861403744 LR: [0.00010467395472325493]\n",
      "Eval MSE: 41.867442678267366\n",
      "Eval Best MSE: 41.86728084365218\n",
      "Epoch:[45/80]\n",
      "Train MSE: 42.023978994093625 Mean loss: 42.022379124059086 LR: [9.944025698709218e-05]\n",
      "Eval MSE: 41.86730888019524\n",
      "Eval Best MSE: 41.86728084365218\n",
      "Epoch:[46/80]\n",
      "Train MSE: 42.02386090863797 Mean loss: 42.02840641325554 LR: [9.446824413773756e-05]\n",
      "Eval MSE: 41.86725340408173\n",
      "Eval Best MSE: 41.86725340408173\n",
      "Epoch:[47/80]\n",
      "Train MSE: 42.02388509141047 Mean loss: 42.03043093723534 LR: [8.974483193085068e-05]\n",
      "Eval MSE: 41.86720960492167\n",
      "Eval Best MSE: 41.86720960492167\n",
      "Epoch:[48/80]\n",
      "Train MSE: 42.023839482027256 Mean loss: 42.023599455841875 LR: [8.525759033430814e-05]\n",
      "Eval MSE: 41.8673816854496\n",
      "Eval Best MSE: 41.86720960492167\n",
      "Epoch:[49/80]\n",
      "Train MSE: 42.02372858323366 Mean loss: 42.03076735639994 LR: [8.099471081759274e-05]\n",
      "Eval MSE: 41.86713604604232\n",
      "Eval Best MSE: 41.86713604604232\n",
      "Epoch:[50/80]\n",
      "Train MSE: 42.02370076095152 Mean loss: 42.03351653782667 LR: [7.69449752767131e-05]\n",
      "Eval MSE: 41.866995156274385\n",
      "Eval Best MSE: 41.866995156274385\n",
      "Epoch:[51/80]\n",
      "Train MSE: 42.02368628891896 Mean loss: 42.03537564573035 LR: [7.309772651287744e-05]\n",
      "Eval MSE: 41.867399124670506\n",
      "Eval Best MSE: 41.866995156274385\n",
      "Epoch:[52/80]\n",
      "Train MSE: 42.02365224086035 Mean loss: 42.03268560899043 LR: [6.944284018723356e-05]\n",
      "Eval MSE: 41.86701756179928\n",
      "Eval Best MSE: 41.866995156274385\n",
      "Epoch:[53/80]\n",
      "Train MSE: 42.0236071734473 Mean loss: 42.024706680162815 LR: [6.597069817787189e-05]\n",
      "Eval MSE: 41.86738822251128\n",
      "Eval Best MSE: 41.866995156274385\n",
      "Epoch:[54/80]\n",
      "Train MSE: 42.02362691037075 Mean loss: 42.022533889365405 LR: [6.267216326897829e-05]\n",
      "Eval MSE: 41.86717825327544\n",
      "Eval Best MSE: 41.866995156274385\n",
      "Epoch:[55/80]\n",
      "Train MSE: 42.023498204628545 Mean loss: 42.01336958556049 LR: [5.953855510552937e-05]\n",
      "Eval MSE: 41.86738757896635\n",
      "Eval Best MSE: 41.866995156274385\n",
      "Epoch:[56/80]\n",
      "Train MSE: 42.0235251520311 Mean loss: 42.026059597994376 LR: [5.65616273502529e-05]\n",
      "Eval MSE: 41.866904780549824\n",
      "Eval Best MSE: 41.866904780549824\n",
      "Epoch:[57/80]\n",
      "Train MSE: 42.023511404301445 Mean loss: 42.036109164752794 LR: [5.373354598274025e-05]\n",
      "Eval MSE: 41.86732235230034\n",
      "Eval Best MSE: 41.866904780549824\n",
      "Epoch:[58/80]\n",
      "Train MSE: 42.02347189843386 Mean loss: 42.01680198601917 LR: [5.104686868360323e-05]\n",
      "Eval MSE: 41.86682870253077\n",
      "Eval Best MSE: 41.86682870253077\n",
      "Epoch:[59/80]\n",
      "Train MSE: 42.023452789221956 Mean loss: 42.021528547844 LR: [4.849452524942307e-05]\n",
      "Eval MSE: 41.86688950059152\n",
      "Eval Best MSE: 41.86682870253077\n",
      "Epoch:[60/80]\n",
      "Train MSE: 42.023407721279646 Mean loss: 42.02142386309868 LR: [4.606979898695191e-05]\n",
      "Eval MSE: 41.86689175723263\n",
      "Eval Best MSE: 41.86682870253077\n",
      "Epoch:[61/80]\n",
      "Train MSE: 42.02338736378977 Mean loss: 42.04164118471399 LR: [4.376630903760431e-05]\n",
      "Eval MSE: 41.86709058721375\n",
      "Eval Best MSE: 41.86682870253077\n",
      "Epoch:[62/80]\n",
      "Train MSE: 42.02335313974963 Mean loss: 42.01787005061597 LR: [4.157799358572409e-05]\n",
      "Eval MSE: 41.86673522762929\n",
      "Eval Best MSE: 41.86673522762929\n",
      "Epoch:[63/80]\n",
      "Train MSE: 42.02335470532362 Mean loss: 42.021512883954344 LR: [3.9499093906437885e-05]\n",
      "Eval MSE: 41.866813638498726\n",
      "Eval Best MSE: 41.86673522762929\n",
      "Epoch:[64/80]\n",
      "Train MSE: 42.02330943308396 Mean loss: 42.01421410214584 LR: [3.752413921111599e-05]\n",
      "Eval MSE: 41.86671744970053\n",
      "Eval Best MSE: 41.86671744970053\n",
      "Epoch:[65/80]\n",
      "Train MSE: 42.023351534215934 Mean loss: 42.02272551882584 LR: [3.564793225056019e-05]\n",
      "Eval MSE: 41.86673742499653\n",
      "Eval Best MSE: 41.86671744970053\n",
      "Epoch:[66/80]\n",
      "Train MSE: 42.02329016085759 Mean loss: 42.01912463027819 LR: [3.3865535638032174e-05]\n",
      "Eval MSE: 41.866667934845346\n",
      "Eval Best MSE: 41.866667934845346\n",
      "Epoch:[67/80]\n",
      "Train MSE: 42.02321358613574 Mean loss: 42.03636284212096 LR: [3.2172258856130564e-05]\n",
      "Eval MSE: 41.866718160987034\n",
      "Eval Best MSE: 41.866667934845346\n",
      "Epoch:[68/80]\n",
      "Train MSE: 42.023238918742415 Mean loss: 42.02435366875302 LR: [3.056364591332403e-05]\n",
      "Eval MSE: 41.866671114465376\n",
      "Eval Best MSE: 41.866667934845346\n",
      "Epoch:[69/80]\n",
      "Train MSE: 42.02322208670498 Mean loss: 42.03666376434596 LR: [2.903546361765783e-05]\n",
      "Eval MSE: 41.86663943681283\n",
      "Eval Best MSE: 41.86663943681283\n",
      "Epoch:[70/80]\n",
      "Train MSE: 42.02313348675535 Mean loss: 42.02442216451189 LR: [2.758369043677494e-05]\n",
      "Eval MSE: 41.866251451193826\n",
      "Eval Best MSE: 41.866251451193826\n",
      "Epoch:[71/80]\n",
      "Train MSE: 42.02277606033923 Mean loss: 42.02180312165117 LR: [2.620450591493619e-05]\n",
      "Eval MSE: 41.86622136546822\n",
      "Eval Best MSE: 41.86622136546822\n",
      "Epoch:[72/80]\n",
      "Train MSE: 42.02274758229436 Mean loss: 42.03123463993579 LR: [2.489428061918938e-05]\n",
      "Eval MSE: 41.86616821797124\n",
      "Eval Best MSE: 41.86616821797124\n",
      "Epoch:[73/80]\n",
      "Train MSE: 42.01055172388644 Mean loss: 42.00722912138542 LR: [2.364956658822991e-05]\n",
      "Eval MSE: 41.840298211270245\n",
      "Eval Best MSE: 41.840298211270245\n",
      "Epoch:[74/80]\n",
      "Train MSE: 41.99595541767143 Mean loss: 41.98791949516904 LR: [2.2467088258818413e-05]\n",
      "Eval MSE: 41.83755551591168\n",
      "Eval Best MSE: 41.83755551591168\n",
      "Epoch:[75/80]\n",
      "Train MSE: 41.99445308562248 Mean loss: 41.990913053529454 LR: [2.134373384587749e-05]\n",
      "Eval MSE: 41.835207745449395\n",
      "Eval Best MSE: 41.835207745449395\n",
      "Epoch:[76/80]\n",
      "Train MSE: 41.99114925928344 Mean loss: 41.99426608802998 LR: [2.0276547153583614e-05]\n",
      "Eval MSE: 41.83290060722867\n",
      "Eval Best MSE: 41.83290060722867\n",
      "Epoch:[77/80]\n",
      "Train MSE: 41.98929394931376 Mean loss: 41.98935076620727 LR: [1.9262719795904432e-05]\n",
      "Eval MSE: 41.831376265209336\n",
      "Eval Best MSE: 41.831376265209336\n",
      "Epoch:[78/80]\n",
      "Train MSE: 41.9878814723729 Mean loss: 42.000496552053804 LR: [1.829958380610921e-05]\n",
      "Eval MSE: 41.83015606167843\n",
      "Eval Best MSE: 41.83015606167843\n",
      "Epoch:[79/80]\n",
      "Train MSE: 41.98667116168469 Mean loss: 41.98322069961413 LR: [1.738460461580375e-05]\n",
      "Eval MSE: 41.82910347196556\n",
      "Eval Best MSE: 41.82910347196556\n",
      "Epoch:[80/80]\n",
      "Train MSE: 41.985730119666165 Mean loss: 41.98117413141031 LR: [1.6515374385013564e-05]\n",
      "Eval MSE: 41.82829634383833\n",
      "Eval Best MSE: 41.82829634383833\n",
      "Best Train MSE: 41.985730119666165\n"
     ]
    }
   ],
   "source": [
    "!python us_main.py --config config/us_train_device.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_label(label无监督判断)\n",
    "\n",
    "best mse：41.98"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters:\n",
      "{'work_dir': './work_dir/us_label', 'config': 'config/us_train_label.yaml', 'phase': 'train', 'save_score': False, 'seed': 1, 'feeder': 'feeder.Us_Feeder_label', 'num_worker': 8, 'train_feeder_args': {'data_path': './data/train.pkl', 'snr': 0}, 'test_feeder_args': {'data_path': './data/test.pkl', 'snr': 0}, 'model': 'net.Us_CNN', 'model_args': {'channels': 13, 'num_classes': 2}, 'weights': None, 'ignore_weights': [], 'base_lr': 0.001, 'step': [10, 50], 'device': 0, 'optimizer': 'Adam', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 80, 'weight_decay': 1e-05}\n",
      "\n",
      "Epoch:[1/80]\n",
      "Train MSE: 43.3857529612742 Mean loss: 43.3786804570561 LR: [0.00095]\n",
      "Eval MSE: 42.02955143512552\n",
      "Eval Best MSE: 42.02955143512552\n",
      "Epoch:[2/80]\n",
      "Train MSE: 42.17110498661884 Mean loss: 42.174083675958414 LR: [0.0009025]\n",
      "Eval MSE: 42.005923682920944\n",
      "Eval Best MSE: 42.005923682920944\n",
      "Epoch:[3/80]\n",
      "Train MSE: 42.15197153425531 Mean loss: 42.14416912382683 LR: [0.000857375]\n",
      "Eval MSE: 41.986672891496156\n",
      "Eval Best MSE: 41.986672891496156\n",
      "Epoch:[4/80]\n",
      "Train MSE: 42.146656184042655 Mean loss: 42.152496844266366 LR: [0.0008145062499999999]\n",
      "Eval MSE: 41.99481362481493\n",
      "Eval Best MSE: 41.986672891496156\n",
      "Epoch:[5/80]\n",
      "Train MSE: 42.14204491156487 Mean loss: 42.149051649380574 LR: [0.0007737809374999998]\n",
      "Eval MSE: 41.94243480839025\n",
      "Eval Best MSE: 41.94243480839025\n",
      "Epoch:[6/80]\n",
      "Train MSE: 42.075592123052125 Mean loss: 42.076524785134644 LR: [0.0007350918906249997]\n",
      "Eval MSE: 41.9079208162331\n",
      "Eval Best MSE: 41.9079208162331\n",
      "Epoch:[7/80]\n",
      "Train MSE: 42.06001142831962 Mean loss: 42.05708047984976 LR: [0.0006983372960937497]\n",
      "Eval MSE: 41.90307756481107\n",
      "Eval Best MSE: 41.90307756481107\n",
      "Epoch:[8/80]\n",
      "Train MSE: 42.05529970188253 Mean loss: 42.046282658534764 LR: [0.0006634204312890621]\n",
      "Eval MSE: 41.892994219137485\n",
      "Eval Best MSE: 41.892994219137485\n",
      "Epoch:[9/80]\n",
      "Train MSE: 42.04636878345396 Mean loss: 42.04491108919667 LR: [0.000630249409724609]\n",
      "Eval MSE: 41.88935883381258\n",
      "Eval Best MSE: 41.88935883381258\n",
      "Epoch:[10/80]\n",
      "Train MSE: 42.045723785231026 Mean loss: 42.047966087813926 LR: [0.0005987369392383785]\n",
      "Eval MSE: 41.88918267185495\n",
      "Eval Best MSE: 41.88918267185495\n",
      "Epoch:[11/80]\n",
      "Train MSE: 42.0452156148931 Mean loss: 42.05167078338893 LR: [0.0005688000922764595]\n",
      "Eval MSE: 41.88969507333838\n",
      "Eval Best MSE: 41.88918267185495\n",
      "Epoch:[12/80]\n",
      "Train MSE: 42.04504322868397 Mean loss: 42.03943919291538 LR: [0.0005403600876626365]\n",
      "Eval MSE: 41.887807094561275\n",
      "Eval Best MSE: 41.887807094561275\n",
      "Epoch:[13/80]\n",
      "Train MSE: 42.044578619992365 Mean loss: 42.05062953982733 LR: [0.0005133420832795047]\n",
      "Eval MSE: 41.88893591047789\n",
      "Eval Best MSE: 41.887807094561275\n",
      "Epoch:[14/80]\n",
      "Train MSE: 42.0447713959767 Mean loss: 42.02959548477578 LR: [0.00048767497911552944]\n",
      "Eval MSE: 41.88931977656255\n",
      "Eval Best MSE: 41.887807094561275\n",
      "Epoch:[15/80]\n",
      "Train MSE: 42.044384436949734 Mean loss: 42.05938032032114 LR: [0.00046329123015975297]\n",
      "Eval MSE: 41.89117518857899\n",
      "Eval Best MSE: 41.887807094561275\n",
      "Epoch:[16/80]\n",
      "Train MSE: 42.04413332348684 Mean loss: 42.03757878531397 LR: [0.0004401266686517653]\n",
      "Eval MSE: 41.888282813983544\n",
      "Eval Best MSE: 41.887807094561275\n",
      "Epoch:[17/80]\n",
      "Train MSE: 42.04398470880917 Mean loss: 42.040031247434364 LR: [0.00041812033521917703]\n",
      "Eval MSE: 41.88744942329568\n",
      "Eval Best MSE: 41.88744942329568\n",
      "Epoch:[18/80]\n",
      "Train MSE: 42.04359686669896 Mean loss: 42.03982641844623 LR: [0.00039721431845821814]\n",
      "Eval MSE: 41.88784378932398\n",
      "Eval Best MSE: 41.88744942329568\n",
      "Epoch:[19/80]\n",
      "Train MSE: 42.04350484582727 Mean loss: 42.039931153829116 LR: [0.0003773536025353072]\n",
      "Eval MSE: 41.88776218189913\n",
      "Eval Best MSE: 41.88744942329568\n",
      "Epoch:[20/80]\n",
      "Train MSE: 42.04314971563926 Mean loss: 42.045306619289704 LR: [0.0003584859224085418]\n",
      "Eval MSE: 41.88747587214564\n",
      "Eval Best MSE: 41.88744942329568\n",
      "Epoch:[21/80]\n",
      "Train MSE: 42.04158740432321 Mean loss: 42.02793219237201 LR: [0.0003405616262881147]\n",
      "Eval MSE: 41.88562062524929\n",
      "Eval Best MSE: 41.88562062524929\n",
      "Epoch:[22/80]\n",
      "Train MSE: 42.040577242054376 Mean loss: 42.04271078531721 LR: [0.00032353354497370894]\n",
      "Eval MSE: 41.884795401654685\n",
      "Eval Best MSE: 41.884795401654685\n",
      "Epoch:[23/80]\n",
      "Train MSE: 42.040069648882934 Mean loss: 42.04067915519782 LR: [0.00030735686772502346]\n",
      "Eval MSE: 41.8847936827123\n",
      "Eval Best MSE: 41.8847936827123\n",
      "Epoch:[24/80]\n",
      "Train MSE: 42.03955801422299 Mean loss: 42.04561712889545 LR: [0.00029198902433877225]\n",
      "Eval MSE: 41.88314605103216\n",
      "Eval Best MSE: 41.88314605103216\n",
      "Epoch:[25/80]\n",
      "Train MSE: 42.03930179782514 Mean loss: 42.05770016560513 LR: [0.00027738957312183364]\n",
      "Eval MSE: 41.88353969307242\n",
      "Eval Best MSE: 41.88314605103216\n",
      "Epoch:[26/80]\n",
      "Train MSE: 42.0391388860379 Mean loss: 42.040211247131886 LR: [0.0002635200944657419]\n",
      "Eval MSE: 41.883118531018596\n",
      "Eval Best MSE: 41.883118531018596\n",
      "Epoch:[27/80]\n",
      "Train MSE: 42.03889452497288 Mean loss: 42.040888474050874 LR: [0.0002503440897424548]\n",
      "Eval MSE: 41.88221520562548\n",
      "Eval Best MSE: 41.88221520562548\n",
      "Epoch:[28/80]\n",
      "Train MSE: 42.03843153663448 Mean loss: 42.03022614200558 LR: [0.00023782688525533205]\n",
      "Eval MSE: 41.88294827104541\n",
      "Eval Best MSE: 41.88221520562548\n",
      "Epoch:[29/80]\n",
      "Train MSE: 42.03826194151879 Mean loss: 42.038961714347906 LR: [0.00022593554099256544]\n",
      "Eval MSE: 41.8823562351104\n",
      "Eval Best MSE: 41.88221520562548\n",
      "Epoch:[30/80]\n",
      "Train MSE: 42.03757482125781 Mean loss: 42.029582420281606 LR: [0.00021463876394293716]\n",
      "Eval MSE: 41.880932523196066\n",
      "Eval Best MSE: 41.880932523196066\n",
      "Epoch:[31/80]\n",
      "Train MSE: 42.037153002540144 Mean loss: 42.039988965059806 LR: [0.0002039068257457903]\n",
      "Eval MSE: 41.88079824669909\n",
      "Eval Best MSE: 41.88079824669909\n",
      "Epoch:[32/80]\n",
      "Train MSE: 42.03706705289874 Mean loss: 42.03446984080087 LR: [0.00019371148445850077]\n",
      "Eval MSE: 41.88117188804025\n",
      "Eval Best MSE: 41.88079824669909\n",
      "Epoch:[33/80]\n",
      "Train MSE: 42.03713958666137 Mean loss: 42.03840341821181 LR: [0.00018402591023557573]\n",
      "Eval MSE: 41.880891238941864\n",
      "Eval Best MSE: 41.88079824669909\n",
      "Epoch:[34/80]\n",
      "Train MSE: 42.03699632579156 Mean loss: 42.042407145542384 LR: [0.00017482461472379692]\n",
      "Eval MSE: 41.88157334999821\n",
      "Eval Best MSE: 41.88079824669909\n",
      "Epoch:[35/80]\n",
      "Train MSE: 42.03692755829821 Mean loss: 42.03644901039326 LR: [0.00016608338398760707]\n",
      "Eval MSE: 41.8805834381747\n",
      "Eval Best MSE: 41.8805834381747\n",
      "Epoch:[36/80]\n",
      "Train MSE: 42.036964995522816 Mean loss: 42.03422885658467 LR: [0.0001577792147882267]\n",
      "Eval MSE: 41.880658953091945\n",
      "Eval Best MSE: 41.8805834381747\n",
      "Epoch:[37/80]\n",
      "Train MSE: 42.036908853182226 Mean loss: 42.0367861553631 LR: [0.00014989025404881537]\n",
      "Eval MSE: 41.88078110384756\n",
      "Eval Best MSE: 41.8805834381747\n",
      "Epoch:[38/80]\n",
      "Train MSE: 42.03687120081028 Mean loss: 42.0265750378634 LR: [0.00014239574134637458]\n",
      "Eval MSE: 41.88068300981765\n",
      "Eval Best MSE: 41.8805834381747\n",
      "Epoch:[39/80]\n",
      "Train MSE: 42.03685666817656 Mean loss: 42.03567834027046 LR: [0.00013527595427905584]\n",
      "Eval MSE: 41.88066064663124\n",
      "Eval Best MSE: 41.8805834381747\n",
      "Epoch:[40/80]\n",
      "Train MSE: 42.036775045828236 Mean loss: 42.030427780826535 LR: [0.00012851215656510304]\n",
      "Eval MSE: 41.88066979174344\n",
      "Eval Best MSE: 41.8805834381747\n",
      "Epoch:[41/80]\n",
      "Train MSE: 42.03683098678245 Mean loss: 42.02816566534802 LR: [0.00012208654873684788]\n",
      "Eval MSE: 41.880620738377715\n",
      "Eval Best MSE: 41.8805834381747\n",
      "Epoch:[42/80]\n",
      "Train MSE: 42.036819872159825 Mean loss: 42.03970331850305 LR: [0.00011598222130000548]\n",
      "Eval MSE: 41.88064350377971\n",
      "Eval Best MSE: 41.8805834381747\n",
      "Epoch:[43/80]\n",
      "Train MSE: 42.03678931726832 Mean loss: 42.03899575967704 LR: [0.00011018311023500519]\n",
      "Eval MSE: 41.880693793429124\n",
      "Eval Best MSE: 41.8805834381747\n",
      "Epoch:[44/80]\n",
      "Train MSE: 42.03671860471601 Mean loss: 42.027858447184606 LR: [0.00010467395472325493]\n",
      "Eval MSE: 41.88059371372439\n",
      "Eval Best MSE: 41.8805834381747\n",
      "Epoch:[45/80]\n",
      "Train MSE: 42.03674906910272 Mean loss: 42.03610297008953 LR: [9.944025698709218e-05]\n",
      "Eval MSE: 41.881261552478314\n",
      "Eval Best MSE: 41.8805834381747\n",
      "Epoch:[46/80]\n",
      "Train MSE: 42.0367990322424 Mean loss: 42.044506056118855 LR: [9.446824413773756e-05]\n",
      "Eval MSE: 41.88041057015101\n",
      "Eval Best MSE: 41.88041057015101\n",
      "Epoch:[47/80]\n",
      "Train MSE: 42.03660828732303 Mean loss: 42.04229152308101 LR: [8.974483193085068e-05]\n",
      "Eval MSE: 41.88042004550337\n",
      "Eval Best MSE: 41.88041057015101\n",
      "Epoch:[48/80]\n",
      "Train MSE: 42.03668386119958 Mean loss: 42.0353830388162 LR: [8.525759033430814e-05]\n",
      "Eval MSE: 41.88042567652153\n",
      "Eval Best MSE: 41.88041057015101\n",
      "Epoch:[49/80]\n",
      "Train MSE: 42.03666088145266 Mean loss: 42.05001750034569 LR: [8.099471081759274e-05]\n",
      "Eval MSE: 41.880406073804174\n",
      "Eval Best MSE: 41.880406073804174\n",
      "Epoch:[50/80]\n",
      "Train MSE: 42.036583733533845 Mean loss: 42.031942401312094 LR: [7.69449752767131e-05]\n",
      "Eval MSE: 41.88048318064835\n",
      "Eval Best MSE: 41.880406073804174\n",
      "Epoch:[51/80]\n",
      "Train MSE: 42.03663247353577 Mean loss: 42.03481996586893 LR: [7.309772651287744e-05]\n",
      "Eval MSE: 41.88069442003866\n",
      "Eval Best MSE: 41.880406073804174\n",
      "Epoch:[52/80]\n",
      "Train MSE: 42.036585462651566 Mean loss: 42.029576529443794 LR: [6.944284018723356e-05]\n",
      "Eval MSE: 41.88046317994925\n",
      "Eval Best MSE: 41.880406073804174\n",
      "Epoch:[53/80]\n",
      "Train MSE: 42.03657887882546 Mean loss: 42.04872141475171 LR: [6.597069817787189e-05]\n",
      "Eval MSE: 41.88045192638063\n",
      "Eval Best MSE: 41.880406073804174\n",
      "Epoch:[54/80]\n",
      "Train MSE: 42.03659430168753 Mean loss: 42.024401909482165 LR: [6.267216326897829e-05]\n",
      "Eval MSE: 41.880498113431095\n",
      "Eval Best MSE: 41.880406073804174\n",
      "Epoch:[55/80]\n",
      "Train MSE: 42.03654992126401 Mean loss: 42.03108898939285 LR: [5.953855510552937e-05]\n",
      "Eval MSE: 41.880525506429215\n",
      "Eval Best MSE: 41.880406073804174\n",
      "Epoch:[56/80]\n",
      "Train MSE: 42.03654784626982 Mean loss: 42.03402617125385 LR: [5.65616273502529e-05]\n",
      "Eval MSE: 41.88039514624186\n",
      "Eval Best MSE: 41.88039514624186\n",
      "Epoch:[57/80]\n",
      "Train MSE: 42.03652416233218 Mean loss: 42.03956273171754 LR: [5.373354598274025e-05]\n",
      "Eval MSE: 41.88044252300368\n",
      "Eval Best MSE: 41.88039514624186\n",
      "Epoch:[58/80]\n",
      "Train MSE: 42.03654679593799 Mean loss: 42.05256352382423 LR: [5.104686868360323e-05]\n",
      "Eval MSE: 41.880395954906874\n",
      "Eval Best MSE: 41.88039514624186\n",
      "Epoch:[59/80]\n",
      "Train MSE: 42.036481059561 Mean loss: 42.04471069943588 LR: [4.849452524942307e-05]\n",
      "Eval MSE: 41.87705845467655\n",
      "Eval Best MSE: 41.87705845467655\n",
      "Epoch:[60/80]\n",
      "Train MSE: 42.026260024807414 Mean loss: 42.02323248534076 LR: [4.606979898695191e-05]\n",
      "Eval MSE: 41.86866794124692\n",
      "Eval Best MSE: 41.86866794124692\n",
      "Epoch:[61/80]\n",
      "Train MSE: 42.017811552187325 Mean loss: 42.03507239417692 LR: [4.376630903760431e-05]\n",
      "Eval MSE: 41.85637058507854\n",
      "Eval Best MSE: 41.85637058507854\n",
      "Epoch:[62/80]\n",
      "Train MSE: 42.003586543702106 Mean loss: 42.00790141958051 LR: [4.157799358572409e-05]\n",
      "Eval MSE: 41.844457675032025\n",
      "Eval Best MSE: 41.844457675032025\n",
      "Epoch:[63/80]\n",
      "Train MSE: 42.00064447742347 Mean loss: 42.00663021391472 LR: [3.9499093906437885e-05]\n",
      "Eval MSE: 41.842760981518474\n",
      "Eval Best MSE: 41.842760981518474\n",
      "Epoch:[64/80]\n",
      "Train MSE: 42.000005222814096 Mean loss: 41.987210788558016 LR: [3.752413921111599e-05]\n",
      "Eval MSE: 41.84255736728884\n",
      "Eval Best MSE: 41.84255736728884\n",
      "Epoch:[65/80]\n",
      "Train MSE: 41.99969320307165 Mean loss: 42.01013445221217 LR: [3.564793225056019e-05]\n",
      "Eval MSE: 41.842177836664774\n",
      "Eval Best MSE: 41.842177836664774\n",
      "Epoch:[66/80]\n",
      "Train MSE: 41.9993758284628 Mean loss: 42.003004884297866 LR: [3.3865535638032174e-05]\n",
      "Eval MSE: 41.84203827632519\n",
      "Eval Best MSE: 41.84203827632519\n",
      "Epoch:[67/80]\n",
      "Train MSE: 41.999315629549585 Mean loss: 41.99547004699707 LR: [3.2172258856130564e-05]\n",
      "Eval MSE: 41.84173553077283\n",
      "Eval Best MSE: 41.84173553077283\n",
      "Epoch:[68/80]\n",
      "Train MSE: 41.99881103732625 Mean loss: 41.99231146078194 LR: [3.056364591332403e-05]\n",
      "Eval MSE: 41.841002423014416\n",
      "Eval Best MSE: 41.841002423014416\n",
      "Epoch:[69/80]\n",
      "Train MSE: 41.998237760969225 Mean loss: 41.99678650577511 LR: [2.903546361765783e-05]\n",
      "Eval MSE: 41.84074542842615\n",
      "Eval Best MSE: 41.84074542842615\n",
      "Epoch:[70/80]\n",
      "Train MSE: 41.99815575834202 Mean loss: 41.993986788049206 LR: [2.758369043677494e-05]\n",
      "Eval MSE: 41.84072118964497\n",
      "Eval Best MSE: 41.84072118964497\n",
      "Epoch:[71/80]\n",
      "Train MSE: 41.9981165623607 Mean loss: 41.99883972438036 LR: [2.620450591493619e-05]\n",
      "Eval MSE: 41.84070816632778\n",
      "Eval Best MSE: 41.84070816632778\n",
      "Epoch:[72/80]\n",
      "Train MSE: 41.99809571344572 Mean loss: 42.001683952534094 LR: [2.489428061918938e-05]\n",
      "Eval MSE: 41.84075958218082\n",
      "Eval Best MSE: 41.84070816632778\n",
      "Epoch:[73/80]\n",
      "Train MSE: 41.998076937407866 Mean loss: 41.990894469539676 LR: [2.364956658822991e-05]\n",
      "Eval MSE: 41.840710676999784\n",
      "Eval Best MSE: 41.84070816632778\n",
      "Epoch:[74/80]\n",
      "Train MSE: 41.99803911011293 Mean loss: 41.996532170118485 LR: [2.2467088258818413e-05]\n",
      "Eval MSE: 41.84067208123921\n",
      "Eval Best MSE: 41.84067208123921\n",
      "Epoch:[75/80]\n",
      "Train MSE: 41.99799961430143 Mean loss: 41.99666213989258 LR: [2.134373384587749e-05]\n",
      "Eval MSE: 41.840592709286234\n",
      "Eval Best MSE: 41.840592709286234\n",
      "Epoch:[76/80]\n",
      "Train MSE: 41.99799615659525 Mean loss: 42.01120509932527 LR: [2.0276547153583614e-05]\n",
      "Eval MSE: 41.840554011913305\n",
      "Eval Best MSE: 41.840554011913305\n",
      "Epoch:[77/80]\n",
      "Train MSE: 41.99797839833927 Mean loss: 42.00266166281911 LR: [1.9262719795904432e-05]\n",
      "Eval MSE: 41.8405960413248\n",
      "Eval Best MSE: 41.840554011913305\n",
      "Epoch:[78/80]\n",
      "Train MSE: 41.997972404117434 Mean loss: 42.00181179553007 LR: [1.829958380610921e-05]\n",
      "Eval MSE: 41.840516068165364\n",
      "Eval Best MSE: 41.840516068165364\n",
      "Epoch:[79/80]\n",
      "Train MSE: 41.9979387223121 Mean loss: 42.00152179414192 LR: [1.738460461580375e-05]\n",
      "Eval MSE: 41.84060006348063\n",
      "Eval Best MSE: 41.840516068165364\n",
      "Epoch:[80/80]\n",
      "Train MSE: 41.9979418177345 Mean loss: 41.9930563901378 LR: [1.6515374385013564e-05]\n",
      "Eval MSE: 41.840568940462205\n",
      "Eval Best MSE: 41.840516068165364\n",
      "Best Train MSE: 41.9979387223121\n"
     ]
    }
   ],
   "source": [
    "!python us_main.py --config config/us_train_label.yaml"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
